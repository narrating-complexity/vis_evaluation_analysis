Pool No.,No,ID,Title,Author,VIS Presenting Year,Year,Keywords,Abstract,DOI,Location,application-focused,user-involved,evaluation-included,evaluation,case study related,design study,Assignment,Manual filtering,"Final Check: Keep-1,Drop-0",A1-Domain (Primary),A1-Domain (Secondary),A1-Domain (Manual labelling),A2-Data-Driven,C-Evaluation mentioned in Contribution,D-Separate section to describe evaluation practices ,D1-Study Protocol included,E-Domain requirements & tasks mentioned,E1- Domain experts involvement in shaping the requirements & tasks,F-Application implementation described,G-Domain integration,AI-related: VIS application for AI,AI-related: AI enhancing VIS tools,AR/VR/XR-related,N.O.Sessions,Total No. of participant,Participant type (a),Number (a),Participant type (b),Number (b),UWP : Understand environments and work prctices,VDAR: Visual data analysis and reasoning,CTV: Evaluate communication through visualization,CDA: Evaluate collaborative data analysis,UP: User performance,UE: User experience,AP: Algorithm performance,QRI: Qualitative result inspection,*ESG: Evaluate Scalibility and Generalizability,*EUV: Extened User Validation,Observation,Workshop,Focus group,Think-aloud protocol,Interview,Survey & Questionnaire,Task-based evaluation (Ql),User Interaction with the tool,Content analysis,Expert/user feedback,Case study,Controlled experiments,A/B testing,Performance evaluation,Task-based evaluation (Qn),User behavior analysis,At which stage,Iterative refinement,Others,Comments
853,314,2018J001,TPFlow: Progressive Partition and Multidimensional Pattern Extraction for Large-Scale Spatio-Temporal Data Analysis,"Liu, Dongyu and Xu, Panpan and Ren, Liu",2018,2019,Data visualization;Tensile stress;Partitioning algorithms;Data mining;Visualization;Data models;Data analysis;Spatio-temporal data;tensor decomposition;interactive exploration;automatic pattern discoveries,"Consider a multi-dimensional spatio-temporal (ST) dataset where each entry is a numerical measure defined by the corresponding temporal, spatial and other domain-specific dimensions. A typical approach to explore such data utilizes interactive visualizations with multiple coordinated views. Each view displays the aggregated measures along one or two dimensions. By brushing on the views, analysts can obtain detailed information. However, this approach often cannot provide sufficient guidance for analysts to identify patterns hidden within subsets of data. Without a priori hypotheses, analysts need to manually select and iterate through different slices to search for patterns, which can be a tedious and lengthy process. In this work, we model multidimensional ST data as tensors and propose a novel piecewise rank-one tensor decomposition algorithm which supports automatically slicing the data into homogeneous partitions and extracting the latent patterns in each partition for comparison and visual summarization. The algorithm optimizes a quantitative measure about how faithfully the extracted patterns visually represent the original data. Based on the algorithm we further propose a visual analytics framework that supports a top-down, progressive partitioning workflow for level-of-detail multidimensional ST data exploration. We demonstrate the general applicability and effectiveness of our technique on three datasets from different application domains: regional sales trend analysis, customer traffic analysis in department stores, and taxi trip analysis with origin-destination (OD) data. We further interview domain experts to verify the usability of the prototype.",10.1109/TVCG.2018.2865018,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
859,315,2018J003,Futzing and Moseying: Interviews with Professional Data Analysts on Exploration Practices,"Alspaugh, Sara and Zokaei, Nava and Liu, Andrea and Jin, Cindy and Hearst, Marti A.",2018,2019,Interviews;Tools;Data science;Python;Business intelligence;Data visualization;EDA;exploratory data analysis;interview study;visual analytics tools,"We report the results of interviewing thirty professional data analysts working in a range of industrial, academic, and regulatory environments. This study focuses on participants' descriptions of exploratory activities and tool usage in these activities. Highlights of the findings include: distinctions between exploration as a precursor to more directed analysis versus truly open-ended exploration; confirmation that some analysts see â€œfinding something interestingâ€ as a valid goal of data exploration while others explicitly disavow this goal; conflicting views about the role of intelligent tools in data exploration; and pervasive use of visualization for exploration, but with only a subset using direct manipulation interfaces. These findings provide guidelines for future tool development, as well as a better understanding of the meaning of the term â€œdata explorationâ€ based on the words of practitioners â€œin the wild.â€",10.1109/TVCG.2018.2865040,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,1,2018J005,Visual Abstraction of Large Scale Geospatial Origin-Destination Movement Data,"Zhou, Zhiguang and Meng, Linhao and Tang, Cheng and Zhao, Ying and Guo, Zhiyong and Hu, Miaoxin and Chen, Wei",2018,2019,Visualization;Data visualization;Clutter;Geospatial analysis;Semantics;Mobile handsets;Correlation;Visual abstraction;human mobility;origin-destination;flow map;representation learning,"A variety of human movement datasets are represented in an Origin-Destination(OD) form, such as taxi trips, mobile phone locations, etc. As a commonly-used method to visualize OD data, flow map always fails to discover patterns of human mobility, due to massive intersections and occlusions of lines on a 2D geographical map. A large number of techniques have been proposed to reduce visual clutter of flow maps, such as filtering, clustering and edge bundling, but the correlations of OD flows are often neglected, which makes the simplified OD flow map present little semantic information. In this paper, a characterization of OD flows is established based on an analogy between OD flows and natural language processing (NPL) terms. Then, an iterative multi-objective sampling scheme is designed to select OD flows in a vectorized representation space. To enhance the readability of sampled OD flows, a set of meaningful visual encodings are designed to present the interactions of OD flows. We design and implement a visual exploration system that supports visual inspection and quantitative evaluation from a variety of perspectives. Case studies based on real-world datasets and interviews with domain experts have demonstrated the effectiveness of our system in reducing the visual clutter and enhancing correlations of OD flows.",10.1109/TVCG.2018.2864503,,TRUE,TRUE,TRUE,T,T,F,C1,KEEP,1,18. Transportation and mobility,,,1,1,1,0,1,1,1,1,0,1,0,2,2,1. domain expert,2,,,0,1,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,1,1,0,1,0,0,4. After the deployment,0,,
,,2018J005,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,5. no participant,0,,,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,4. After the deployment,0,,
5,2,2018J007,ForVizor: Visualizing Spatio-Temporal Team Formations in Soccer,"Wu, Yingcai and Xie, Xiao and Wang, Jiachen and Deng, Dazhen and Liang, Hongye and Zhang, Hui and Cheng, Shoubin and Chen, Wei",2018,2019,Games;Data visualization;Videos;Visual analytics;Tools;Soccer data;formation analysis;spatio-temporal visualization,"Regarded as a high-level tactic in soccer, a team formation assigns players different tasks and indicates their active regions on the pitch, thereby influencing the team performance significantly. Analysis of formations in soccer has become particularly indispensable for soccer analysts. However, formations of a team are intrinsically time-varying and contain inherent spatial information. The spatio-temporal nature of formations and other characteristics of soccer data, such as multivariate features, make analysis of formations in soccer a challenging problem. In this study, we closely worked with domain experts to characterize domain problems of formation analysis in soccer and formulated several design goals. We design a novel spatio-temporal visual representation of changes in team formation, allowing analysts to visually analyze the evolution of formations and track the spatial flow of players within formations over time. Based on the new design, we further design and develop ForVizor, a visual analytics system, which empowers users to track the spatio-temporal changes in formation and understand how and why such changes occur. With ForVizor, domain experts conduct formation analysis of two games. Analysis results with insights and useful feedback are summarized in two case studies.",10.1109/TVCG.2018.2865041,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,17. Sports and entertainment,,,0,1,1,1,1,1,1,1,0,0,0,2,4,1. domain expert,4,,,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,0,1,1,0,0,0,0,0,4. After the deployment,0,,
,,2018J007,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,5. no participant,0,,,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,4. After the deployment,0,,
869,316,2018J010,Visual Analysis of the Temporal Evolution of Ensemble Forecast Sensitivities,"Kumpf, Alexander and Rautenhaus, Marc and Riemer, Michael and Westermann, RÃ¼diger",2018,2019,Correlation;Sensitivity;Atmospheric modeling;Weather forecasting;Visualization;Computational modeling;Correlation;clustering;tracking;ensemble visualization,"Ensemble sensitivity analysis (ESA) has been established in the atmospheric sciences as a correlation-based approach to determine the sensitivity of a scalar forecast quantity computed by a numerical weather prediction model to changes in another model variable at a different model state. Its applications include determining the origin of forecast errors and placing targeted observations to improve future forecasts. Weâ€”a team of visualization scientists and meteorologistsâ€”present a visual analysis framework to improve upon current practice of ESA. We support the user in selecting regions to compute a meaningful target forecast quantity by embedding correlation-based grid-point clustering to obtain statistically coherent regions. The evolution of sensitivity features computed via ESA are then traced through time, by integrating a quantitative measure of feature matching into optical-flow-based feature assignment, and displayed by means of a swipe-path showing the geo-spatial evolution of the sensitivities. Visualization of the internal correlation structure of computed features guides the user towards those features robustly predicting a certain weather event. We demonstrate the use of our method by application to real-world 2D and 3D cases that occurred during the 2016 NAWDEX field campaign, showing the interactive generation of hypothesis chains to explore how atmospheric processes sensitive to each other are interrelated.",10.1109/TVCG.2018.2864901,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
10,3,2018J011,EnsembleLens: Ensemble-based Visual Exploration of Anomaly Detection Algorithms with Multidimensional Data,"Xu, Ke and Xia, Meng and Mu, Xing and Wang, Yun and Cao, Nan",2018,2019,Anomaly detection;Correlation;Data visualization;Detectors;Visual analytics;Feature extraction;Algorithm Evaluation;Ensemble Analysis;Anomaly Detection;Visual Analysis;Multidimensional Data,"The results of anomaly detection are sensitive to the choice of detection algorithms as they are specialized for different properties of data, especially for multidimensional data. Thus, it is vital to select the algorithm appropriately. To systematically select the algorithms, ensemble analysis techniques have been developed to support the assembly and comparison of heterogeneous algorithms. However, challenges remain due to the absence of the ground truth, interpretation, or evaluation of these anomaly detectors. In this paper, we present a visual analytics system named EnsembleLens that evaluates anomaly detection algorithms based on the ensemble analysis process. The system visualizes the ensemble processes and results by a set of novel visual designs and multiple coordinated contextual views to meet the requirements of correlation analysis, assessment and reasoning of anomaly detection algorithms. We also introduce an interactive analysis workflow that dynamically produces contextualized and interpretable data summaries that allow further refinements of exploration results based on user feedback. We demonstrate the effectiveness of EnsembleLens through a quantitative evaluation, three case studies with real-world data and interviews with two domain experts.",10.1109/TVCG.2018.2864825,,TRUE,TRUE,TRUE,T,T,F,C1,KEEP,1,10. Healthcare and medical imaging,,Healthcare,1,1,1,0,1,1,1,1,0,1,0,2,2,1. domain expert,2,,,0,0,0,0,0,1,0,0,1,0,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,4. After the deployment,0,,
,,2018J011,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,5. no participant,0,,,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1,1,0,1,0,0,4. After the deployment,0,,
,,2018J012,KnowledgePearls: Provenance-Based Visualization Retrieval,"Stitz, Holger and Gratzl, Samuel and Piringer, Harald and Zichner, Thomas and Streit, Marc",2018,2019,Data visualization;Visualization;Indexes;History;Database languages;Knowledge based systems;Grammar;Visualization provenance;interaction provenance;retrieval,"Storing analytical provenance generates a knowledge base with a large potential for recalling previous results and guiding users in future analyses. However, without extensive manual creation of meta information and annotations by the users, search and retrieval of analysis states can become tedious. We present KnowledgePearls, a solution for efficient retrieval of analysis states that are structured as provenance graphs containing automatically recorded user interactions and visualizations. As a core component, we describe a visual interface for querying and exploring analysis states based on their similarity to a partial definition of a requested analysis state. Depending on the use case, this definition may be provided explicitly by the user by formulating a search query or inferred from given reference states. We explain our approach using the example of efficient retrieval of demographic analyses by Hans Rosling and discuss our implementation for a fast look-up of previous states. Our approach is independent of the underlying visualization framework. We discuss the applicability for visualizations which are based on the declarative grammar Vega and we use a Vega-based implementation of Gapminder as guiding example. We additionally present a biomedical case study to illustrate how KnowledgePearls facilitates the exploration process by recalling states from earlier analyses.",10.1109/TVCG.2018.2865024,,TRUE,TRUE,TRUE,,T,F,C1,DROP-tool extension,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
871,317,2018J013,Enhancing Web-based Analytics Applications through Provenance,"Camisetty, Akhilesh and Chandurkar, Chaitanya and Sun, Maoyuan and Koop, David",2018,2019,Collaboration;History;Tools;Browsers;Libraries;Servers;Visualization;Collaboration;provenance;streaming data;history;web,"Visual analytics systems continue to integrate new technologies and leverage modern environments for exploration and collaboration, making tools and techniques available to a wide audience through web browsers. Many of these systems have been developed with rich interactions, offering users the opportunity to examine details and explore hypotheses that have not been directly encoded by a designer. Understanding is enhanced when users can replay and revisit the steps in the sensemaking process, and in collaborative settings, it is especially important to be able to review not only the current state but also what decisions were made along the way. Unfortunately, many web-based systems lack the ability to capture such reasoning, and the path to a result is transient, forgotten when a user moves to a new view. This paper explores the requirements to augment existing client-side web applications with support for capturing, reviewing, sharing, and reusing steps in the reasoning process. Furthermore, it considers situations where decisions are made with streaming data, and the insights gained from revisiting those choices when more data is available. It presents a proof of concept, the Shareable Interactive Manipulation Provenance framework (SIMProv.js), that addresses these requirements in a modern, client-side JavaScript library, and describes how it can be integrated with existing frameworks.",10.1109/TVCG.2018.2865039,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
11,4,2018J014,Doccurate: A Curation-Based Approach for Clinical Text Visualization,"Sultanum, Nicole and Singh, Devin and Brudno, Michael and Chevalier, Fanny",2018,2019,Medical services;Visualization;Automation;Data visualization;Tools;Task analysis;Medical diagnostic imaging;Visual Curation;Clinical Text;Text Visualization;Medical Narrative,"Before seeing a patient, physicians seek to obtain an overview of the patient's medical history. Text plays a major role in this activity since it represents the bulk of the clinical documentation, but reviewing it quickly becomes onerous when patient charts grow too large. Text visualization methods have been widely explored to manage this large scale through visual summaries that rely on information retrieval algorithms to structure text and make it amenable to visualization. However, the integration with such automated approaches comes with a number of limitations, including significant error rates and the need for healthcare providers to fine-tune algorithms without expert knowledge of their inner mechanics. In addition, several of these approaches obscure or substitute the original clinical text and therefore fail to leverage qualitative and rhetorical flavours of the clinical notes. These drawbacks have limited the adoption of text visualization and other summarization technologies in clinical practice. In this work we present Doccurate, a novel system embodying a curation-based approach for the visualization of large clinical text datasets. Our approach offers automation auditing and customizability to physicians while also preserving and extensively linking to the original text. We discuss findings of a formal qualitative evaluation conducted with 6 domain experts, shedding light onto physicians' information needs, perceived strengths and limitations of automated tools, and the importance of customization while balancing efficiency. We also present use case scenarios to showcase Doccurate's envisioned usage in practice.",10.1109/TVCG.2018.2864905,,TRUE,TRUE,TRUE,T,T,F,C1,KEEP,1,10. Healthcare and medical imaging,,"healthcare, medical NLP",0,1,1,1,1,1,1,1,0,0,0,1,6,1. domain expert,1,2. domain user,5,1,1,0,0,0,1,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,3. Before the deployment (During the development and refinement phrase ONLY),0,,
874,318,2018J015,VIS Author Profiles: Interactive Descriptions of Publication Records Combining Text and Visualization,"Latif, Shahid and Beck, Fabian",2018,2019,Data visualization;Collaboration;Libraries;Computer science;Natural languages;Visual analytics;Natural language generation;document visualization;interactive documents;sparklines;digital libraries,"Publication records and collaboration networks are important for assessing the expertise and experience of researchers. Existing digital libraries show the raw publication lists in author profiles, whereas visualization techniques focus on specific subproblems. Instead, we look at publication records from various perspectives mixing low-level publication data with high-level abstractions and background information. This work presents VIS Author Profiles, a novel approach to generate integrated textual and visual descriptions to highlight patterns in publication records. We leverage template-based natural language generation to summarize notable publication statistics, evolution of research topics, and collaboration relationships. Seamlessly integrated visualizations augment the textual description and are interactively connected with each other and the text. The underlying publication data and detailed explanations of the analysis are available on demand. We compare our approach to existing systems by taking into account information needs of users and demonstrate its usefulness in two realistic application examples.",10.1109/TVCG.2018.2865022,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
14,5,2018J016,BitExTract: Interactive Visualization for Extracting Bitcoin Exchange Intelligence,"Yue, Xuanwu and Shu, Xinhuan and Zhu, Xinyu and Du, Xinnan and Yu, Zheqing and Papadopoulos, Dimitrios and Liu, Siyuan",2018,2019,Bitcoin;Data visualization;Visualization;Task analysis;Tools;Bitcoin exchange;transaction data;comparative analysis;visual analytics;FinTech,"The emerging prosperity of cryptocurrencies, such as Bitcoin, has come into the spotlight during the past few years. Cryptocurrency exchanges, which act as the gateway to this world, now play a dominant role in the circulation of Bitcoin. Thus, delving into the analysis of the transaction patterns of exchanges can shed light on the evolution and trends in the Bitcoin market, and participants can gain hints for identifying credible exchanges as well. Not only Bitcoin practitioners but also researchers in the financial domains are interested in the business intelligence behind the curtain. However, the task of multiple exchanges exploration and comparisons has been limited owing to the lack of efficient tools. Previous methods of visualizing Bitcoin data have mainly concentrated on tracking suspicious transaction logs, but it is cumbersome to analyze exchanges and their relationships with existing tools and methods. In this paper, we present BitExTract, an interactive visual analytics system, which, to the best of our knowledge, is the first attempt to explore the evolutionary transaction patterns of Bitcoin exchanges from two perspectives, namely, exchange versus exchange and exchange versus client. In particular, BitExTract summarizes the evolution of the Bitcoin market by observing the transactions between exchanges over time via a massive sequence view. A node-link diagram with ego-centered views depicts the trading network of exchanges and their temporal transaction distribution. Moreover, BitExTract embeds multiple parallel bars on a timeline to examine and compare the evolution patterns of transactions between different exchanges. Three case studies with novel insights demonstrate the effectiveness and usability of our system.",10.1109/TVCG.2018.2864814,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,3. Business and finance,,,0,1,1,0,1,1,1,1,0,0,0,1,5,1. domain expert,5,,,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,4. After the deployment,0,,
18,6,2018J018,Vulnus: Visual Vulnerability Analysis for Network Security,"Angelini, Marco and Blasilli, Graziano and Catarci, Tiziana and Lenti, Simone and Santucci, Giuseppe",2018,2019,Security;Bars;Measurement;Visual analytics;Organizations;Visual Analytics;Network security;Vulnerability analysis;CVE;CVSS;Attack Graph;Vulnerability triage and management,"Vulnerabilities represent one of the main weaknesses of IT systems and the availability of consolidated official data, like CVE (Common Vulnerabilities and Exposures), allows for using them to compute the paths an attacker is likely to follow. However, even if patches are available, business constraints or lack of resources create obstacles to their straightforward application. As a consequence, the security manager of a network needs to deal with a large number of vulnerabilities, making decisions on how to cope with them. This paper presents VULNUS (VULNerabilities visUal aSsessment), a visual analytics solution for dynamically inspecting the vulnerabilities spread on networks, allowing for a quick understanding of the network status and visually classifying nodes according to their vulnerabilities. Moreover, VULNUS computes the approximated optimal sequence of patches able to eliminate all the attack paths and allows for exploring sub-optimal patching strategies, simulating the effect of removing one or more vulnerabilities. VULNUS has been evaluated by domain experts using a lab-test experiment, investigating the effectiveness and efficiency of the proposed solution.",10.1109/TVCG.2018.2865028,,TRUE,TRUE,TRUE,T,,F,C1,KEEP,1,4. Computer networks and security,,,0,1,1,1,1,1,1,1,0,0,0,1,20,1. domain expert,20,,,0,1,0,0,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,0,1,1,4. After the deployment,0,,
26,7,2018J020,Situ: Identifying and Explaining Suspicious Behavior in Networks,"Goodall, John R. and Ragan, Eric D. and Steed, Chad A. and Reed, Joel W. and Richardson, G. David and Huffer, Kelly M.T. and Bridges, Robert A. and Laska, Jason A.",2018,2019,Data visualization;Network security;Machine learning;Anomaly detection;Visual analytics;Network security;situational awareness;privacy and security;streaming data;machine learning;visualization,"Despite the best efforts of cyber security analysts, networked computing assets are routinely compromised, resulting in the loss of intellectual property, the disclosure of state secrets, and major financial damages. Anomaly detection methods are beneficial for detecting new types of attacks and abnormal network activity, but such algorithms can be difficult to understand and trust. Network operators and cyber analysts need fast and scalable tools to help identify suspicious behavior that bypasses automated security systems, but operators do not want another automated tool with algorithms they do not trust. Experts need tools to augment their own domain expertise and to provide a contextual understanding of suspicious behavior to help them make decisions. In this paper we present Situ, a visual analytics system for discovering suspicious behavior in streaming network data. Situ provides a scalable solution that combines anomaly detection with information visualization. The system's visualizations enable operators to identify and investigate the most anomalous events and IP addresses, and the tool provides context to help operators understand why they are anomalous. Finally, operators need tools that can be integrated into their workflow and with their existing tools. This paper describes the Situ platform and its deployment in an operational network setting. We discuss how operators are currently using the tool in a large organization's security operations center and present the results of expert reviews with professionals.",10.1109/TVCG.2018.2865029,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,4. Computer networks and security,,,0,1,1,0,1,1,1,1,0,0,0,2,5,1. domain expert,5,,,0,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,4. After the deployment,0,,
,,2018J020,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,5. no participant,0,,,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,4. After the deployment,0,,
27,8,2018J021,A Visual Analytics Framework for the Detection of Anomalous Call Stack Trees in High Performance Computing Applications,"Xie, Cong and Xu, Wei and Mueller, Klaus",2018,2019,Vegetation;Anomaly detection;Labeling;Runtime;Forestry;Visualization;Kernel;Call Stack;Performance Visualization;Representation Learning;Active Learning;Anomaly Detection,"Anomalous runtime behavior detection is one of the most important tasks for performance diagnosis in High Performance Computing (HPC). Most of the existing methods find anomalous executions based on the properties of individual functions, such as execution time. However, it is insufficient to identify abnormal behavior without taking into account the context of the executions, such as the invocations of children functions and the communications with other HPC nodes. We improve upon the existing anomaly detection approaches by utilizing the call stack structures of the executions, which record rich temporal and contextual information. With our call stack tree (CSTree) representation of the executions, we formulate the anomaly detection problem as finding anomalous tree structures in a call stack forest. The CSTrees are converted to vector representations using our proposed stack2vec embedding. Structural and temporal visualizations of CSTrees are provided to support users in the identification and verification of the anomalies during an active anomaly detection process. Three case studies of real-world HPC applications demonstrate the capabilities of our approach.",10.1109/TVCG.2018.2865026,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,,,HPC,1,1,1,0,1,1,1,1,0,1,0,2,3,2. domain user,3,,,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,0,1,1,0,0,0,0,0,4. After the deployment,0,,
,,2018J021,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,5. no participant,0,,,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,4. After the deployment,0,,
30,9,2018J024,RegressionExplorer: Interactive Exploration of Logistic Regression Models with Subgroup Analysis,"Dingen, Dennis and van't Veer, Marcel and Houthuizen, Patrick and Mestrom, Eveline H. J. and Korsten, Erik H.H.M. and Bouwman, Arthur R.A. and van Wijk, Jarke",2018,2019,Analytical models;Logistics;Visual analytics;Biological system modeling;Mathematical model;Data models;Visual analytics;Predictive visual analytics;Exploratory data analysis;Multivariate statistics;Regression analysis;Variable selection;Subgroup analysis,"We present RegressionExplorer, a Visual Analytics tool for the interactive exploration of logistic regression models. Our application domain is Clinical Biostatistics, where models are derived from patient data with the aim to obtain clinically meaningful insights and consequences. Development and interpretation of a proper model requires domain expertise and insight into model characteristics. Because of time constraints, often a limited number of candidate models is evaluated. RegressionExplorer enables experts to quickly generate, evaluate, and compare many different models, taking the workflow for model development as starting point. Global patterns in parameter values of candidate models can be explored effectively. In addition, experts are enabled to compare candidate models across multiple subpopulations. The insights obtained can be used to formulate new hypotheses or to steer model development. The effectiveness of the tool is demonstrated for two uses cases: prediction of a cardiac conduction disorder in patients after receiving a heart valve implant and prediction of hypernatremia in critically ill patients.",10.1109/TVCG.2018.2865043,,TRUE,TRUE,TRUE,T,,F,C1,KEEP,1,10. Healthcare and medical imaging,,clinical biostatistics,0,1,1,0,1,1,1,1,0,0,0,1,3,2. domain user,3,,,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,4. After the deployment,0,,
880,319,2018J025,Drag and Track: A Direct Manipulation Interface for Contextualizing Data Instances within a Continuous Parameter Space,"Orban, Daniel and Keefe, Daniel F. and Biswas, Ayan and Ahrens, James and Rogers, David",2018,2019,Data visualization;Visualization;Electric shock;Physics;Navigation;Data models;Uncertainty;Visual Parameter Space Analysis;Ensemble Visualization;Semantic Interaction;Direct Manipulation;Shock Physics,"We present a direct manipulation technique that allows material scientists to interactively highlight relevant parameterized simulation instances located in dimensionally reduced spaces, enabling a user-defined understanding of a continuous parameter space. Our goals are two-fold: first, to build a user-directed intuition of dimensionally reduced data, and second, to provide a mechanism for creatively exploring parameter relationships in parameterized simulation sets, called ensembles. We start by visualizing ensemble data instances in dimensionally reduced scatter plots. To understand these abstract views, we employ user-defined virtual data instances that, through direct manipulation, search an ensemble for similar instances. Users can create multiple of these direct manipulation queries to visually annotate the spaces with sets of highlighted ensemble data instances. User-defined goals are therefore translated into custom illustrations that are projected onto the dimensionally reduced spaces. Combined forward and inverse searches of the parameter space follow naturally allowing for continuous parameter space prediction and visual query comparison in the context of an ensemble. The potential for this visualization technique is confirmed via expert user feedback for a shock physics application and synthetic model analysis.",10.1109/TVCG.2018.2865051,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
39,10,2018J026,Clustrophile 2: Guided Visual Clustering Analysis,"Cavallo, Marco and Demiralp, Ã‡aÄŸatay",2018,2019,Tools;Data visualization;Visualization;Clustering algorithms;Data analysis;Space exploration;Dimensionality reduction;Clustering tour;Guided data analysis;Exploratory data analysis;Interactive clustering analysis;Interpretability;Explainability;Visual data exploration recommendation;Dimensionality reduction;What-if analysis;Clustrophile;Unsupervised learning,"Data clustering is a common unsupervised learning method frequently used in exploratory data analysis. However, identifying relevant structures in unlabeled, high-dimensional data is nontrivial, requiring iterative experimentation with clustering parameters as well as data features and instances. The number of possible clusterings for a typical dataset is vast, and navigating in this vast space is also challenging. The absence of ground-truth labels makes it impossible to define an optimal solution, thus requiring user judgment to establish what can be considered a satisfiable clustering result. Data scientists need adequate interactive tools to effectively explore and navigate the large clustering space so as to improve the effectiveness of exploratory clustering analysis. We introduce Clustrophile 2, a new interactive tool for guided clustering analysis. Clustrophile 2 guides users in clustering-based exploratory analysis, adapts user feedback to improve user guidance, facilitates the interpretation of clusters, and helps quickly reason about differences between clusterings. To this end, Clustrophile 2 contributes a novel feature, the Clustering Tour, to help users choose clustering parameters and assess the quality of different clustering results in relation to current analysis goals and user expectations. We evaluate Clustrophile 2 through a user study with 12 data scientists, who used our tool to explore and interpret sub-cohorts in a dataset of Parkinson's disease patients. Results suggest that Clustrophile 2 improves the speed and effectiveness of exploratory clustering analysis for both experts and non-experts.",10.1109/TVCG.2018.2864477,,TRUE,TRUE,TRUE,T,T,F,C1,KEEP,1,1. AI (Machine Learning/Deep Learning/Data Mining),,,1,1,1,1,1,1,1,1,0,0,0,1,12,1. domain expert,6,2. domain user,6,0,1,0,0,0,1,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,0,0,0,1,0,4. After the deployment,0,,
40,11,2018J027,InkPlanner: Supporting Prewriting via Intelligent Visual Diagramming,"Lu, Zhicong and Fan, Mingming and Wang, Yun and Zhao, Jian and Annett, Michelle and Wigdor, Daniel",2018,2019,Writing;Data visualization;Computer aided instruction;Educational institutions;Writing;prewriting;diagraming;content and structure recommendation;pen and touch interfaces,"Prewriting is the process of generating and organizing ideas before drafting a document. Although often overlooked by novice writers and writing tool developers, prewriting is a critical process that improves the quality of a final document. To better understand current prewriting practices, we first conducted interviews with writing learners and experts. Based on the learners' needs and experts' recommendations, we then designed and developed InkPlanner, a novel pen and touch visualization tool that allows writers to utilize visual diagramming for ideation during prewriting. InkPlanner further allows writers to sort their ideas into a logical and sequential narrative by using a novel widget-NarrativeLine. Using a NarrativeLine, InkPlanner can automatically generate a document outline to guide later drafting exercises. Inkplanner is powered by machine-generated semantic and structural suggestions that are curated from various texts. To qualitatively review the tool and understand how writers use InkPlanner for prewriting, two writing experts were interviewed and a user study was conducted with university students. The results demonstrated that InkPlanner encouraged writers to generate more diverse ideas and also enabled them to think more strategically about how to organize their ideas for later drafting.",10.1109/TVCG.2018.2864887,,TRUE,TRUE,TRUE,,T,F,C2,KEEP,1,19. Others,,Writing,0,1,1,1,1,1,1,1,0,0,0,2,18,1. domain expert,2,,,1,1,0,0,0,1,0,0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,0,1,0,4. After the deployment,0,,
,,2018J027,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,2. domain user,16,,,0,1,0,0,0,1,0,0,0,0,1,0,0,0,1,1,1,1,0,0,0,0,0,0,1,1,4. After the deployment,0,,
41,12,2018J028,DQNViz: A Visual Analytics Approach to Understand Deep Q-Networks,"Wang, Junpeng and Gou, Liang and Shen, Han-Wei and Yang, Hao",2018,2019,Training;Games;Visual analytics;Data visualization;Analytical models;Learning (artificial intelligence);Machine learning;Deep Q-Network (DQN);reinforcement learning;model interpretation;visual analytics,"Deep Q-Network (DQN), as one type of deep reinforcement learning model, targets to train an intelligent agent that acquires optimal actions while interacting with an environment. The model is well known for its ability to surpass professional human players across many Atari 2600 games. Despite the superhuman performance, in-depth understanding of the model and interpreting the sophisticated behaviors of the DQN agent remain to be challenging tasks, due to the long-time model training process and the large number of experiences dynamically generated by the agent. In this work, we propose DQNViz, a visual analytics system to expose details of the blind training process in four levels, and enable users to dive into the large experience space of the agent for comprehensive analysis. As an initial attempt in visualizing DQN models, our work focuses more on Atari games with a simple action space, most notably the Breakout game. From our visual analytics of the agent's experiences, we extract useful action/reward patterns that help to interpret the model and control the training. Through multiple case studies conducted together with deep learning experts, we demonstrate that DQNViz can effectively help domain experts to understand, diagnose, and potentially improve DQN models.",10.1109/TVCG.2018.2864504,,TRUE,TRUE,TRUE,,T,F,C2,KEEP,1,1. AI (Machine Learning/Deep Learning/Data Mining),,Machine Learning,0,1,1,0,1,1,1,1,1,0,0,1,3,1. domain expert,3,,,1,1,0,0,0,1,0,0,1,0,1,0,0,0,1,0,1,1,0,0,1,0,0,0,0,0,4. After the deployment,0,,
43,13,2018J029,RetainVis: Visual Analytics with Interpretable and Interactive Recurrent Neural Networks on Electronic Medical Records,"Kwon, Bum Chul and Choi, Min-Je and Kim, Joanne Taery and Choi, Edward and Kim, Young Bin and Kwon, Soonwook and Sun, Jimeng and Choo, Jaegul",2018,2019,Machine learning;Medical diagnostic imaging;Task analysis;Predictive models;Computational modeling;Visual analytics;Data models;Interactive Artificial Intelligence;XAI (Explainable Artificial Intelligence);Interpretable Deep Learning;Healthcare,"We have recently seen many successful applications of recurrent neural networks (RNNs) on electronic medical records (EMRs), which contain histories of patients' diagnoses, medications, and other various events, in order to predict the current and future states of patients. Despite the strong performance of RNNs, it is often challenging for users to understand why the model makes a particular prediction. Such black-box nature of RNNs can impede its wide adoption in clinical practice. Furthermore, we have no established methods to interactively leverage users' domain expertise and prior knowledge as inputs for steering the model. Therefore, our design study aims to provide a visual analytics solution to increase interpretability and interactivity of RNNs via a joint effort of medical experts, artificial intelligence scientists, and visual analytics researchers. Following the iterative design process between the experts, we design, implement, and evaluate a visual analytics tool called RetainVis, which couples a newly improved, interpretable, and interactive RNN-based model called RetainEX and visualizations for users' exploration of EMR data in the context of prediction tasks. Our study shows the effective use of RetainVis for gaining insights into how individual medical codes contribute to making risk predictions, using EMRs of patients with heart failure and cataract symptoms. Our study also demonstrates how we made substantial changes to the state-of-the-art RNN model called RETAIN in order to make use of temporal information and increase interactivity. This study will provide a useful guideline for researchers that aim to design an interpretable and interactive visual analytics tool for RNNs.",10.1109/TVCG.2018.2865027,,TRUE,TRUE,TRUE,T,,T,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
883,320,2018J030,GAN Lab: Understanding Complex Deep Generative Models using Interactive Visual Experimentation,"Kahng, Minsuk and Thorat, Nikhil and Chau, Duen Horng and ViÃ©gas, Fernanda B. and Wattenberg, Martin",2018,2019,Gallium nitride;Machine learning;Tools;Generative adversarial networks;Generators;Training;Data visualization;Deep learning;information visualization;visual analytics;generative adversarial networks;machine learning;interactive experimentation;explorable explanations,"Recent success in deep learning has generated immense interest among practitioners and students, inspiring many to learn about this new technology. While visual and interactive approaches have been successfully developed to help people more easily learn deep learning, most existing tools focus on simpler models. In this work, we present GAN Lab, the first interactive visualization tool designed for non-experts to learn and experiment with Generative Adversarial Networks (GANs), a popular class of complex deep learning models. With GAN Lab, users can interactively train generative models and visualize the dynamic training process's intermediate results. GAN Lab tightly integrates an model overview graph that summarizes GAN's structure, and a layered distributions view that helps users interpret the interplay between submodels. GAN Lab introduces new interactive experimentation features for learning complex deep learning models, such as step-by-step training at multiple levels of abstraction for understanding intricate training dynamics. Implemented using TensorFlow.js, GAN Lab is accessible to anyone via modern web browsers, without the need for installation or specialized hardware, overcoming a major practical challenge in deploying interactive tools for deep learning.",10.1109/TVCG.2018.2864500,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
44,14,2018J031,ViBr: Visualizing Bipartite Relations at Scale with the Minimum Description Length Principle,"Chan, Gromit Yeuk-Yin and Xu, Panpan and Dai, Zeng and Ren, Liu",2018,2019,Data visualization;Bipartite graph;Visualization;Clustering algorithms;Complexity theory;Data models;Noise measurement;Bipartite Graph;Visual Summarization;Minimum Description Length;Information Theory,"Bipartite graphs model the key relations in many large scale real-world data: customers purchasing items, legislators voting for bills, people's affiliation with different social groups, faults occurring in vehicles, etc. However, it is challenging to visualize large scale bipartite graphs with tens of thousands or even more nodes or edges. In this paper, we propose a novel visual summarization technique for bipartite graphs based on the minimum description length (MDL) principle. The method simultaneously groups the two different set of nodes and constructs aggregated bipartite relations with balanced granularity and precision. It addresses the key trade-off that often occurs for visualizing large scale and noisy data: acquiring a clear and uncluttered overview while maximizing the information content in it. We formulate the visual summarization task as a co-clustering problem and propose an efficient algorithm based on locality sensitive hashing (LSH) that can easily scale to large graphs under reasonable interactive time constraints that previous related methods cannot satisfy. The method leads to the opportunity of introducing a visual analytics framework with multiple levels-of-detail to facilitate interactive data exploration. In the framework, we also introduce a compact visual design inspired by adjacency list representation of graphs as the building block for a small multiples display to compare the bipartite relations for different subsets of data. We showcase the applicability and effectiveness of our approach by applying it on synthetic data with ground truth and performing case studies on real-world datasets from two application domains including roll-call vote record analysis and vehicle fault pattern analysis. Interviews with experts in the political science community and the automotive industry further highlight the benefits of our approach.",10.1109/TVCG.2018.2864826,,TRUE,TRUE,TRUE,,T,F,C2,KEEP,1,11. Humanities and social sciences,,"Political Science, Automotive Industry",1,1,1,0,1,1,0,1,0,0,0,1,2,1. domain expert,1,1. domain expert,1,1,1,0,0,0,1,0,0,1,0,1,0,0,0,1,0,1,1,0,0,1,0,0,0,0,0,4. After the deployment,0,,
47,15,2018J032,A Visual Analytics Framework for Spatiotemporal Trade Network Analysis,"Wang, Hong and Lu, Yafeng and Shutters, Shade T. and Steptoe, Michael and Wang, Feng and Landis, Steven and Maciejewski, Ross",2018,2019,Data visualization;Visual analytics;Correlation;Anomaly detection;Time series analysis;Spatiotemporal phenomena;Global trade network;anomaly detection;visual analytics,"Economic globalization is increasing connectedness among regions of the world, creating complex interdependencies within various supply chains. Recent studies have indicated that changes and disruptions within such networks can serve as indicators for increased risks of violence and armed conflicts. This is especially true of countries that may not be able to compete for scarce commodities during supply shocks. Thus, network-induced vulnerability to supply disruption is typically exported from wealthier populations to disadvantaged populations. As such, researchers and stakeholders concerned with supply chains, political science, environmental studies, etc. need tools to explore the complex dynamics within global trade networks and how the structure of these networks relates to regional instability. However, the multivariate, spatiotemporal nature of the network structure creates a bottleneck in the extraction and analysis of correlations and anomalies for exploratory data analysis and hypothesis generation. Working closely with experts in political science and sustainability, we have developed a highly coordinated, multi-view framework that utilizes anomaly detection, network analytics, and spatiotemporal visualization methods for exploring the relationship between global trade networks and regional instability. Requirements for analysis and initial research questions to be investigated are elicited from domain experts, and a variety of visual encoding techniques for rapid assessment of analysis and correlations between trade goods, network patterns, and time series signatures are explored. We demonstrate the application of our framework through case studies focusing on armed conflicts in Africa, regional instability measures, and their relationship to international global trade.",10.1109/TVCG.2018.2864844,,TRUE,TRUE,TRUE,,T,F,C2,KEEP,1,3. Business and finance,,"Economics, Geopolitics",0,1,1,0,1,1,1,1,0,0,0,1,1,1. domain expert,1,,,1,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,4. After the deployment,0,,
48,16,2018J033,RuleMatrix: Visualizing and Understanding Classifiers with Rules,"Ming, Yao and Qu, Huamin and Bertini, Enrico",2018,2019,Machine learning;Data visualization;Visualization;Neural networks;Decision trees;Data models;Support vector machines;explainable machine learning;rule visualization;visual analytics,"With the growing adoption of machine learning techniques, there is a surge of research interest towards making machine learning systems more transparent and interpretable. Various visualizations have been developed to help model developers understand, diagnose, and refine machine learning models. However, a large number of potential but neglected users are the domain experts with little knowledge of machine learning but are expected to work with machine learning systems. In this paper, we present an interactive visualization technique to help users with little expertise in machine learning to understand, explore and validate predictive models. By viewing the model as a black box, we extract a standardized rule-based knowledge representation from its input-output behavior. Then, we design RuleMatrix, a matrix-based visualization of rules to help users navigate and verify the rules and the black-box model. We evaluate the effectiveness of RuleMatrix via two use cases and a usability study.",10.1109/TVCG.2018.2864812,,TRUE,TRUE,TRUE,T,,F,C2,KEEP,1,1. AI (Machine Learning/Deep Learning/Data Mining),,Machine Learning,0,1,1,1,1,0,1,1,1,0,0,1,9,3. general public,9,,,0,1,0,0,1,1,0,0,0,1,0,0,0,0,0,1,1,1,0,0,0,0,0,0,1,1,4. After the deployment,0,,
884,321,2018J036,Visual Analytics for Topic Model Optimization based on User-Steerable Speculative Execution,"El-Assady, Mennatallah and Sperrle, Fabian and Deussen, Oliver and Keim, Daniel and Collins, Christopher",2018,2019,Analytical models;Visual analytics;Optimization;Clustering algorithms;Computational modeling;Task analysis;User-Steerable Topic Modeling;Speculative Execution;Mixed-Initiative Visual Analytics;Explainable Machine Learning,"To effectively assess the potential consequences of human interventions in model-driven analytics systems, we establish the concept of speculative execution as a visual analytics paradigm for creating user-steerable preview mechanisms. This paper presents an explainable, mixed-initiative topic modeling framework that integrates speculative execution into the algorithmic decision-making process. Our approach visualizes the model-space of our novel incremental hierarchical topic modeling algorithm, unveiling its inner-workings. We support the active incorporation of the user's domain knowledge in every step through explicit model manipulation interactions. In addition, users can initialize the model with expected topic seeds, the backbone priors. For a more targeted optimization, the modeling process automatically triggers a speculative execution of various optimization strategies, and requests feedback whenever the measured model quality deteriorates. Users compare the proposed optimizations to the current model state and preview their effect on the next model iterations, before applying one of them. This supervised human-in-the-Ioop process targets maximum improvement for minimum feedback and has proven to be effective in three independent studies that confirm topic model quality improvements.",10.1109/TVCG.2018.2864769,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2018J038,MAQUI: Interweaving Queries and Pattern Mining for Recursive Event Sequence Exploration,"Law, Po-Ming and Liu, Zhicheng and Malik, Sana and Basole, Rahul C.",2018,2019,Data mining;Task analysis;Data visualization;Public transportation;Companies;Complexity theory;Sequential pattern mining;temporal query;event sequence exploration,"Exploring event sequences by defining queries alone or by using mining algorithms alone is often not sufficient to support analysis. Analysts often interweave querying and mining in a recursive manner during event sequence analysis: sequences extracted as query results are used for mining patterns, patterns generated are incorporated into a new query for segmenting the sequences, and the resulting segments are mined or queried again. To support flexible analysis, we propose a framework that describes the process of interwoven querying and mining. Based on this framework, we developed MAQUI, a Mining And Querying User Interface that enables recursive event sequence exploration. To understand the efficacy of MAQUI, we conducted two case studies with domain experts. The findings suggest that the capability of interweaving querying and mining helps the participants articulate their questions and gain novel insights from their data.",10.1109/TVCG.2018.2864886,,TRUE,TRUE,TRUE,,T,F,C2,KEEP,1,10. Healthcare and medical imaging,3. Business and finance,"Healthcare, Marketing",1,1,1,1,1,1,1,1,0,0,0,1,3,1. domain expert,2,1. domain expert,1,1,1,0,0,0,1,0,0,1,0,1,0,0,1,1,0,1,1,0,0,1,0,0,0,0,0,4. After the deployment,0,,
50,17,2018J039,iForest: Interpreting Random Forests via Visual Analytics,"Zhao, Xun and Wu, Yanhong and Lee, Dik Lun and Cui, Weiwei",2018,2019,Forestry;Vegetation;Predictive models;Decision trees;Machine learning;Cognition;Impurities;Interpretable Machine Learning;Random Forests;Random Forest Visualization;Visual Analytics,"As an ensemble model that consists of many independent decision trees, random forests generate predictions by feeding the input to internal trees and summarizing their outputs. The ensemble nature of the model helps random forests outperform any individual decision tree. However, it also leads to a poor model interpretability, which significantly hinders the model from being used in fields that require transparent and explainable predictions, such as medical diagnosis and financial fraud detection. The interpretation challenges stem from the variety and complexity of the contained decision trees. Each decision tree has its unique structure and properties, such as the features used in the tree and the feature threshold in each tree node. Thus, a data input may lead to a variety of decision paths. To understand how a final prediction is achieved, it is desired to understand and compare all decision paths in the context of all tree structures, which is a huge challenge for any users. In this paper, we propose a visual analytic system aiming at interpreting random forest models and predictions. In addition to providing users with all the tree information, we summarize the decision paths in random forests, which eventually reflects the working mechanism of the model and reduces users' mental burden of interpretation. To demonstrate the effectiveness of our system, two usage scenarios and a qualitative user study are conducted.",10.1109/TVCG.2018.2864475,,TRUE,TRUE,TRUE,,T,F,C2,KEEP,1,1. AI (Machine Learning/Deep Learning/Data Mining),,Machine Learning,0,1,1,1,1,0,1,1,1,0,0,1,10,3. general public,10,,,0,1,0,0,1,1,0,0,0,0,1,0,0,1,1,1,1,1,0,0,0,0,0,0,0,1,4. After the deployment,0,,
53,18,2018J040,Visual Progression Analysis of Event Sequence Data,"Guo, Shunan and Jin, Zhuochen and Gotz, David and Du, Fan and Zha, Hongyuan and Cao, Nan",2018,2019,Visualization;Diseases;Aggregates;Data visualization;Pattern matching;Interviews;Progression Analysis;Visual Analysis;Event Sequence Data,"Event sequence data is common to a broad range of application domains, from security to health care to scholarly communication. This form of data captures information about the progression of events for an individual entity (e.g., a computer network device; a patient; an author) in the form of a series of time-stamped observations. Moreover, each event is associated with an event type (e.g., a computer login attempt, or a hospital discharge). Analyses of event sequence data have been shown to help reveal important temporal patterns, such as clinical paths resulting in improved outcomes, or an understanding of common career trajectories for scholars. Moreover, recent research has demonstrated a variety of techniques designed to overcome methodological challenges such as large volumes of data and high dimensionality. However, the effective identification and analysis of latent stages of progression, which can allow for variation within different but similarly evolving event sequences, remain a significant challenge with important real-world motivations. In this paper, we propose an unsupervised stage analysis algorithm to identify semantically meaningful progression stages as well as the critical events which help define those stages. The algorithm follows three key steps: (1) event representation estimation, (2) event sequence warping and alignment, and (3) sequence segmentation. We also present a novel visualization system, ET2, which interactively illustrates the results of the stage analysis algorithm to help reveal evolution patterns across stages. Finally, we report three forms of evaluation for ET2: (1) case studies with two real-world datasets, (2) interviews with domain expert users, and (3) a performance evaluation on the progression analysis algorithm and the visualization design.",10.1109/TVCG.2018.2864885,,TRUE,TRUE,TRUE,T,T,F,C2,KEEP,1,10. Healthcare and medical imaging,5. Education and e-learning,"Healthcare, Education",1,1,1,1,1,0,1,1,0,0,0,1,3,1. domain expert,2,1. domain expert,1,0,1,0,0,0,1,1,1,1,0,1,0,0,0,1,0,1,1,0,0,1,0,0,1,0,0,4. After the deployment,0,,
54,19,2018J041,Duet: Helping Data Analysis Novices Conduct Pairwise Comparisons by Minimal Specification,"Law, Po-Ming and Basole, Rahul C. and Wu, Yanhong",2018,2019,Data analysis;Data visualization;Tools;Law enforcement;Visualization;Systems operation;Knowledge discovery;Pairwise comparison;novices;data analysis;automatic insight generation,"Data analysis novices often encounter barriers in executing low-level operations for pairwise comparisons. They may also run into barriers in interpreting the artifacts (e.g., visualizations) created as a result of the operations. We developed Duet, a visual analysis system designed to help data analysis novices conduct pairwise comparisons by addressing execution and interpretation barriers. To reduce the barriers in executing low-level operations during pairwise comparison, Duet employs minimal specification: when one object group (i.e. a group of records in a data table) is specified, Duet recommends object groups that are similar to or different from the specified one; when two object groups are specified, Duet recommends similar and different attributes between them. To lower the barriers in interpreting its recommendations, Duet explains the recommended groups and attributes using both visualizations and textual descriptions. We conducted a qualitative evaluation with eight participants to understand the effectiveness of Duet. The results suggest that minimal specification is easy to use and Duet's explanations are helpful for interpreting the recommendations despite some usability issues.",10.1109/TVCG.2018.2864526,,TRUE,TRUE,TRUE,T,,F,C2,KEEP,1,19. Others,,,1,1,1,1,1,0,1,0,0,0,0,1,8,2. domain user,8,,,0,1,1,0,0,1,0,0,0,0,1,0,0,1,1,1,1,1,0,0,0,0,0,0,0,0,4. After the deployment,0,,
58,20,2018J043,Shape-preserving Star Coordinates,"Molchanov, Vladimir and Linsen, Lars",2018,2019,Shape;Two dimensional displays;Visualization;Data analysis;Principal component analysis;Distortion;Data visualization;Star coordinates;multidimensional data projection;multivariate data visualization,"Dimensionality reduction is commonly applied to multidimensional data to reduce the complexity of their analysis. In visual analysis systems, projections embed multidimensional data into 2D or 3D spaces for graphical representation. To facilitate a robust and accurate analysis, essential characteristics of the multidimensional data shall be preserved when projecting. Orthographic star coordinates is a state-of-the-art linear projection method that avoids distortion of multidimensional clusters by restricting interactive exploration to orthographic projections. However, existing numerical methods for computing orthographic star coordinates have a number of limitations when putting them into practice. We overcome these limitations by proposing the novel concept of shape-preserving star coordinates where shape preservation is assured using a superset of orthographic projections. Our scheme is explicit, exact, simple, fast, parameter-free, and stable. To maintain a valid shape-preserving star-coordinates configuration during user interaction with one of the star-coordinates axes, we derive an algorithm that only requires us to modify the configuration of one additional compensatory axis. Different design goals can be targeted by using different strategies for selecting the compensatory axis. We propose and discuss four strategies including a strategy that approximates orthographic star coordinates very well and a data-driven strategy. We further present shape-preserving morphing strategies between two shape-preserving configurations, which can be adapted for the generation of data tours. We apply our concept to multiple data analysis scenarios to document its applicability and validate its desired properties.",10.1109/TVCG.2018.2865118,,TRUE,TRUE,TRUE,,T,F,C2,DROP,0,,,,,,,,0,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2018J044,SRVis: Towards Better Spatial Integration in Ranking Visualization,"Weng, Di and Chen, Ran and Deng, Zikun and Wu, Feiran and Chen, Jingmin and Wu, Yingcai",2018,2019,Visualization;Bars;Decision making;Data visualization;Scalability;Spatial databases;Reliability;Spatial ranking;visualization,"Interactive ranking techniques have substantially promoted analysts' ability in making judicious and informed decisions effectively based on multiple criteria. However, the existing techniques cannot satisfactorily support the analysis tasks involved in ranking large-scale spatial alternatives, such as selecting optimal locations for chain stores, where the complex spatial contexts involved are essential to the decision-making process. Limitations observed in the prior attempts of integrating rankings with spatial contexts motivate us to develop a context-integrated visual ranking technique. Based on a set of generic design requirements we summarized by collaborating with domain experts, we propose SRVis, a novel spatial ranking visualization technique that supports efficient spatial multi-criteria decision-making processes by addressing three major challenges in the aforementioned context integration, namely, a) the presentation of spatial rankings and contexts, b) the scalability of rankings' visual representations, and c) the analysis of context-integrated spatial rankings. Specifically, we encode massive rankings and their cause with scalable matrix-based visualizations and stacked bar charts based on a novel two-phase optimization framework that minimizes the information loss, and the flexible spatial filtering and intuitive comparative analysis are adopted to enable the in-depth evaluation of the rankings and assist users in selecting the best spatial alternative. The effectiveness of the proposed technique has been evaluated and demonstrated with an empirical study of optimization methods, two case studies, and expert interviews.",10.1109/TVCG.2018.2865126,,TRUE,TRUE,TRUE,T,T,F,C2,KEEP,1,3. Business and finance,9. Geosciences and geospatial data,"Business, Geospatial data",1,1,1,0,1,1,1,1,0,0,0,1,2,1. domain expert,2,,,1,1,0,0,0,1,1,0,1,0,1,0,0,0,1,0,1,1,0,0,1,0,0,1,0,0,4. After the deployment,1,,
59,21,2018J048,Patterns and Pace: Quantifying Diverse Exploration Behavior with Visualizations on the Web,"Feng, Mi and Peck, Evan and Harrison, Lane",2018,2019,Data visualization;Extraterrestrial measurements;Companies;Visual analytics;Feature extraction;Interaction;Visualization;Quantitative Evaluation,"The diverse and vibrant ecosystem of interactive visualizations on the web presents an opportunity for researchers and practitioners to observe and analyze how everyday people interact with data visualizations. However, existing metrics of visualization interaction behavior used in research do not fully reveal the breadth of peoples' open-ended explorations with visualizations. One possible way to address this challenge is to determine high-level goals for visualization interaction metrics, and infer corresponding features from user interaction data that characterize different aspects of peoples' explorations of visualizations. In this paper, we identify needs for visualization behavior measurement, and develop corresponding candidate features that can be inferred from users' interaction data. We then propose metrics that capture novel aspects of peoples' open-ended explorations, including exploration uniqueness and exploration pacing. We evaluate these metrics along with four other metrics recently proposed in visualization literature by applying them to interaction data from prior visualization studies. The results of these evaluations suggest that these new metrics 1) reveal new characteristics of peoples' use of visualizations, 2) can be used to evaluate statistical differences between visualization designs, and 3) are statistically independent of prior metrics used in visualization research. We discuss implications of these results for future studies, including the potential for applying these metrics in visualization interaction analysis, as well as emerging challenges in developing and selecting metrics depicting visualization explorations.",10.1109/TVCG.2018.2865117,,TRUE,TRUE,TRUE,T,,F,C2,DROP,0,,,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
64,22,2018J053,Structure-Based Suggestive Exploration: A New Approach for Effective Exploration of Large Networks,"Chen, Wei and Guo, Fangzhou and Han, Dongming and Pan, Jacheng and Nie, Xiaotao and Xia, Jiazhi and Zhang, Xiaolong",2018,2019,Visualization;Navigation;Engines;History;Tools;Systems support;Layout;Large Network Exploration;Structure-Based Exploration;Suggestive Exploration,"When analyzing a visualized network, users need to explore different sections of the network to gain insight. However, effective exploration of large networks is often a challenge. While various tools are available for users to explore the global and local features of a network, these tools usually require significant interaction activities, such as repetitive navigation actions to follow network nodes and edges. In this paper, we propose a structure-based suggestive exploration approach to support effective exploration of large networks by suggesting appropriate structures upon user request. Encoding nodes with vectorized representations by transforming information of surrounding structures of nodes into a high dimensional space, our approach can identify similar structures within a large network, enable user interaction with multiple similar structures simultaneously, and guide the exploration of unexplored structures. We develop a web-based visual exploration system to incorporate this suggestive exploration approach and compare performances of our approach under different vectorizing methods and networks. We also present the usability and effectiveness of our approach through a controlled user study with two datasets.",10.1109/TVCG.2018.2865139,,TRUE,TRUE,TRUE,,T,F,C2,DROP,0,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2018J054,Structure-aware Fisheye Views for Efficient Large Graph Exploration,"Wang, Yunhai and Wang, Yanyan and Zhang, Haifeng and Sun, Yinqi and Fu, Chi-Wing and Sedlmair, Michael and Chen, Baoquan and Deussen, Oliver",2018,2019,Layout;Lenses;Optimization;Task analysis;Distortion;Visualization;Sun;Graph Visualization;Focus-Context Technique;Structure-aware Zoom;Graph Layout Technique,"Traditional fisheye views for exploring large graphs introduce substantial distortions that often lead to a decreased readability of paths and other interesting structures. To overcome these problems, we propose a framework for structure-aware fisheye views. Using edge orientations as constraints for graph layout optimization allows us not only to reduce spatial and temporal distortions during fisheye zooms, but also to improve the readability of the graph structure. Furthermore, the framework enables us to optimize fisheye lenses towards specific tasks and design a family of new lenses: polyfocal, cluster, and path lenses. A GPU implementation lets us process large graphs with up to 15,000 nodes at interactive rates. A comprehensive evaluation, a user study, and two case studies demonstrate that our structure-aware fisheye views improve layout readability and user performance.",10.1109/TVCG.2018.2864911,,TRUE,TRUE,TRUE,T,T,F,C2,DROP,0,,,,,,,,0,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
885,322,2018J056,Vistrates: A Component Model for Ubiquitous Analytics,"Badam, Sriram Karthik and Mathisen, Andreas and RÃ¤dle, Roman and Klokmose, Clemens N. and Elmqvist, Niklas",2018,2019,Data visualization;Tools;Collaboration;Media;Substrates;Task analysis;Data analysis;Components;literate computing;development;exploration;dissemination;collaboration;heterogeneous devices,"Visualization tools are often specialized for specific tasks, which turns the user's analytical workflow into a fragmented process performed across many tools. In this paper, we present a component model design for data visualization to promote modular designs of visualization tools that enhance their analytical scope. Rather than fragmenting tasks across tools, the component model supports unification, where componentsâ€”the building blocks of this modelâ€”can be assembled to support a wide range of tasks. Furthermore, the model also provides additional key properties, such as support for collaboration, sharing across multiple devices, and adaptive usage depending on expertise, from creating visualizations using dropdown menus, through instantiating components, to actually modifying components or creating entirely new ones from scratch using JavaScript or Python source code. To realize our model, we introduce Vistrates, a literate computing platform for developing, assembling, and sharing visualization components. From a visualization perspective, Vistrates features cross-cutting components for visual representations, interaction, collaboration, and device responsiveness maintained in a component repository. From a development perspective, Vistrates offers a collaborative programming environment where novices and experts alike can compose component pipelines for specific analytical activities. Finally, we present several Vistrates use cases that span the full range of the classic â€œanytimeâ€ and â€œanywhereâ€ motto for ubiquitous analysis: from mobile and on-the-go usage, through office settings, to collaborative smart environments covering a variety of tasks and devices.",10.1109/TVCG.2018.2865144,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
886,323,2018J057,SmartCues: A Multitouch Query Approach for Details-on-Demand through Dynamically Computed Overlays,"Subramonyam, Hariharan and Adar, Eytan",2018,2019,Bars;US Department of Defense;Task analysis;Visualization;Data visualization;Libraries;Color;Graphical overlays;details-on-demand;graph comprehension,"Details-on-demand is a crucial feature in the visual information-seeking process but is often only implemented in highly constrained settings. The most common solution, hover queries (i.e., tooltips), are fast and expressive but are usually limited to single mark (e.g., a bar in a bar chart). `Queries' to retrieve details for more complex sets of objects (e.g., comparisons between pairs of elements, averages across multiple items, trend lines, etc.) are difficult for end-users to invoke explicitly. Further, the output of these queries require complex annotations and overlays which need to be displayed and dismissed on demand to avoid clutter. In this work we introduce SmartCues, a library to support details-on-demand through dynamically computed overlays. For end-users, SmartCues provides multitouch interactions to construct complex queries for a variety of details. For designers, SmartCues offers an interaction library that can be used out-of-the-box, and can be extended for new charts and detail types. We demonstrate how SmartCues can be implemented across a wide array of visualization types and, through a lab study, show that end users can effectively use SmartCues.",10.1109/TVCG.2018.2865231,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
66,23,2018J058,"Multiple Coordinated Views at Large Displays for Multiple Users: Empirical Findings on User Behavior, Movements, and Distances","Langner, Ricardo and Kister, Ulrike and Dachselt, Raimund",2018,2019,Data visualization;Collaboration;Visualization;Mobile handsets;Data analysis;Tools;Task analysis;Multiple coordinated views;wall-sized displays;mobile devices;distant interaction;physical navigation;user behavior;user movements;multi-user;collaborative data analysis,"Interactive wall-sized displays benefit data visualization. Due to their sheer display size, they make it possible to show large amounts of data in multiple coordinated views (MCV) and facilitate collaborative data analysis. In this work, we propose a set of important design considerations and contribute a fundamental input vocabulary and interaction mapping for MCV functionality. We also developed a fully functional application with more than 45 coordinated views visualizing a real-world, multivariate data set of crime activities, which we used in a comprehensive qualitative user study investigating how pairs of users behave. Most importantly, we found that flexible movement is essential andâ€”depending on user goalsâ€”is connected to collaboration, perception, and interaction. Therefore, we argue that for future systems interaction from the distance is required and needs good support. We show that our consistent design for both direct touch at the large display and distant interaction using mobile phones enables the seamless exploration of large-scale MCV at wall-sized displays. Our MCV application builds on design aspects such as simplicity, flexibility, and visual consistency and, therefore, supports realistic workflows. We believe that in the future, many visual data analysis scenarios will benefit from wall-sized displays presenting numerous coordinated visualizations, for which our findings provide a valuable foundation.",10.1109/TVCG.2018.2865235,,TRUE,TRUE,TRUE,,T,F,C2,DROP,0,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
892,324,2018J062,NLIZE: A Perturbation-Driven Visual Interrogation Tool for Analyzing and Interpreting Natural Language Inference Models,"Liu, Shusen and Li, Zhimin and Li, Tao and Srikumar, Vivek and Pascucci, Valerio and Bremer, Peer-Timo",2018,2019,Natural languages;Task analysis;Neural networks;Visualization;Computational modeling;Analytical models;Predictive models;Natural Language Processing;Interpretable Machine Learning;Natural Language Inference;Attention Visualization,"With the recent advances in deep learning, neural network models have obtained state-of-the-art performances for many linguistic tasks in natural language processing. However, this rapid progress also brings enormous challenges. The opaque nature of a neural network model leads to hard-to-debug-systems and difficult-to-interpret mechanisms. Here, we introduce a visualization system that, through a tight yet flexible integration between visualization elements and the underlying model, allows a user to interrogate the model by perturbing the input, internal state, and prediction while observing changes in other parts of the pipeline. We use the natural language inference problem as an example to illustrate how a perturbation-driven paradigm can help domain experts assess the potential limitation of a model, probe its inner states, and interpret and form hypotheses about fundamental model mechanisms such as attention.",10.1109/TVCG.2018.2865230,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
70,24,2018J064,Augmenting Visualizations with Interactive Data Facts to Facilitate Interpretation and Communication,"Srinivasan, Arjun and Drucker, Steven M. and Endert, Alex and Stasko, John",2018,2019,Data visualization;Tools;Visualization;Natural languages;Data mining;Histograms;Complexity theory;Natural Language Generation;Mixed-initiative Interaction;Visualization Recommendation;Data-driven Communication,"Recently, an increasing number of visualization systems have begun to incorporate natural language generation (NLG) capabilities into their interfaces. NLG-based visualization systems typically leverage a suite of statistical functions to automatically extract key facts about the underlying data and surface them as natural language sentences alongside visualizations. With current systems, users are typically required to read the system-generated sentences and mentally map them back to the accompanying visualization. However, depending on the features of the visualization (e.g., visualization type, data density) and the complexity of the data fact, mentally mapping facts to visualizations can be a challenging task. Furthermore, more than one visualization could be used to illustrate a single data fact. Unfortunately, current tools provide little or no support for users to explore such alternatives. In this paper, we explore how system-generated data facts can be treated as interactive widgets to help users interpret visualizations and communicate their findings. We present Voder, a system that lets users interact with automatically-generated data facts to explore both alternative visualizations to convey a data fact as well as a set of embellishments to highlight a fact within a visualization. Leveraging data facts as interactive widgets, Voder also facilitates data fact-based visualization search. To assess Voder's design and features, we conducted a preliminary user study with 12 participants having varying levels of experience with visualization tools. Participant feedback suggested that interactive data facts aided them in interpreting visualizations. Participants also stated that the suggestions surfaced through the facts helped them explore alternative visualizations and embellishments to communicate individual data facts.",10.1109/TVCG.2018.2865145,,TRUE,TRUE,TRUE,,T,F,C1,DROP,0,,,,1,1,1,1,1,0,1,0,0,0,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
893,325,2018J067,FiberClay: Sculpting Three Dimensional Trajectories to Reveal Structural Insights,"Hurter, Christophe and Riche, Nathalie Henry and Drucker, Steven M. and Cordeil, Maxime and Alligier, Richard and Vuillemot, Romain",2018,2019,Data visualization;Three-dimensional displays;Trajectory;Two dimensional displays;Optical fiber devices;Aircraft navigation;Immersive Analytics;3D Visualization;Dynamic Queries;Bimanual Interaction;Multidimensional Data,"Visualizing 3D trajectories to extract insights about their similarities and spatial configuration is a critical task in several domains. Air traffic controllers for example deal with large quantities of aircrafts routes to optimize safety in airspace and neuroscientists attempt to understand neuronal pathways in the human brain by visualizing bundles of fibers from DTI images. Extracting insights from masses of 3D trajectories is challenging as the multiple three dimensional lines have complex geometries, may overlap, cross or even merge with each other, making it impossible to follow individual ones in dense areas. As trajectories are inherently spatial and three dimensional, we propose FiberClay: a system to display and interact with 3D trajectories in immersive environments. FiberClay renders a large quantity of trajectories in real time using GP-GPU techniques. FiberClay also introduces a new set of interactive techniques for composing complex queries in 3D space leveraging immersive environment controllers and user position. These techniques enable an analyst to select and compare sets of trajectories with specific geometries and data properties. We conclude by discussing insights found using FiberClay with domain experts in air traffic control and neurology.",10.1109/TVCG.2018.2865191,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
894,326,2018J071,A Framework for Creative Visualization-Opportunities Workshops,"Kerzner, Ethan and Goodwin, Sarah and Dykes, Jason and Jones, Sara and Meyer, Miriah",2018,2019,Conferences;Data visualization;Visualization;Collaboration;Stakeholders;Creativity;User-centered visualization design;design studies;creativity workshops;critically reflective practice,"Applied visualization researchers often work closely with domain collaborators to explore new and useful applications of visualization. The early stages of collaborations are typically time consuming for all stakeholders as researchers piece together an understanding of domain challenges from disparate discussions and meetings. A number of recent projects, however, report on the use of creative visualization-opportunities (CVO) workshops to accelerate the early stages of applied work, eliciting a wealth of requirements in a few days of focused work. Yet, there is no established guidance for how to use such workshops effectively. In this paper, we present the results of a 2-year collaboration in which we analyzed the use of 17 workshops in 10 visualization contexts. Its primary contribution is a framework for CVO workshops that: 1) identifies a process model for using workshops; 2) describes a structure of what happens within effective workshops; 3) recommends 25 actionable guidelines for future workshops; and 4) presents an example workshop and workshop methods. The creation of this framework exemplifies the use of critical reflection to learn about visualization in practice from diverse studies and experience.",10.1109/TVCG.2018.2865241,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
73,25,2018J073,iStoryline: Effective Convergence to Hand-drawn Storylines,"Tang, Tan and Rubab, Sadia and Lai, Jiewen and Cui, Weiwei and Yu, Lingyun and Wu, Yingcai",2018,2019,Visualization;Layout;Tools;Motion pictures;Optimization methods;Guidelines;Hand-drawn illustrations;automatic layout;design space;interactions;optimization,"Storyline visualization techniques have progressed significantly to generate illustrations of complex stories automatically. However, the visual layouts of storylines are not enhanced accordingly despite the improvement in the performance and extension of its application area. Existing methods attempt to achieve several shared optimization goals, such as reducing empty space and minimizing line crossings and wiggles. However, these goals do not always produce optimal results when compared to hand-drawn storylines. We conducted a preliminary study to learn how users translate a narrative into a hand-drawn storyline and check whether the visual elements in hand-drawn illustrations can be mapped back to appropriate narrative contexts. We also compared the hand-drawn storylines with storylines generated by the state-of-the-art methods and found they have significant differences. Our findings led to a design space that summarizes 1) how artists utilize narrative elements and 2) the sequence of actions artists follow to portray expressive and attractive storylines. We developed iStoryline, an authoring tool for integrating high-level user interactions into optimization algorithms and achieving a balance between hand-drawn storylines and automatic layouts. iStoryline allows users to create novel storyline visualizations easily according to their preferences by modifying the automatically generated layouts. The effectiveness and usability of iStoryline are studied with qualitative evaluations.",10.1109/TVCG.2018.2864899,,TRUE,TRUE,TRUE,T,,F,C1,KEEP,1,12. Journalism and media,,visualization creation,0,1,1,1,1,1,1,1,0,0,0,4,114,3. general public,74,,,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,2. Before the deployment (Before or during design phase ONLY),0,,
,,2018J073,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,3. general public,25,,,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,2. Before the deployment (Before or during design phase ONLY),0,,
,,2018J073,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,2. domain user,12,,,0,0,0,0,0,1,0,0,0,0,1,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,4. After the deployment,0,,
,,2018J073,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,3,,,0,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,4. After the deployment,0,,
74,26,2018J074,Narvis: Authoring Narrative Slideshows for Introducing Data Visualization Designs,"Wang, Qianwen and Li, Zhen and Fu, Siwei and Cui, Weiwei and Qu, Huamin",2018,2019,Data visualization;Tools;Visualization;Tutorials;Encoding;Videos;Interviews;Education;Narrative Visualization;Authoring Tools,"Visual designs can be complex in modern data visualization systems, which poses special challenges for explaining them to the non-experts. However, few if any presentation tools are tailored for this purpose. In this study, we present Narvis, a slideshow authoring tool designed for introducing data visualizations to non-experts. Narvis targets two types of end users: teachers, experts in data visualization who produce tutorials for explaining a data visualization, and students, non-experts who try to understand visualization designs through tutorials. We present an analysis of requirements through close discussions with the two types of end users. The resulting considerations guide the design and implementation of Narvis. Additionally, to help teachers better organize their introduction slideshows, we specify a data visualization as a hierarchical combination of components, which are automatically detected and extracted by Narvis. The teachers craft an introduction slideshow through first organizing these components, and then explaining them sequentially. A series of templates are provided for adding annotations and animations to improve efficiency during the authoring process. We evaluate Narvis through a qualitative analysis of the authoring experience, and a preliminary evaluation of the generated slideshows.",10.1109/TVCG.2018.2865232,,TRUE,TRUE,TRUE,T,,F,C1,KEEP,1,5. Education and e-learning,,,0,1,1,1,1,1,1,1,0,0,0,3,37,2. domain user,12,,,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,2. Before the deployment (Before or during design phase ONLY),0,,
,,2018J074,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,2. domain user,5,,,0,0,0,0,0,1,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,0,0,0,0,0,4. After the deployment,0,,
,,2018J074,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,3. general public,20,,,0,0,1,0,0,0,0,1,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,1,0,4. After the deployment,0,,
75,27,2018J075,Charticulator: Interactive Construction of Bespoke Chart Layouts,"Ren, Donghao and Lee, Bongshin and Brehmer, Matthew",2018,2019,Layout;Tools;Visualization;Programming;Data visualization;Transforms;Interactive visualization authoring;Chart layout design;Glyph design;Constraint-based design;Reusable chart layout,"We present Charticulator, an interactive authoring tool that enables the creation of bespoke and reusable chart layouts. Charticulator is our response to most existing chart construction interfaces that require authors to choose from predefined chart layouts, thereby precluding the construction of novel charts. In contrast, Charticulator transforms a chart specification into mathematical layout constraints and automatically computes a set of layout attributes using a constraint-solving algorithm to realize the chart. It allows for the articulation of compound marks or glyphs as well as links between these glyphs, all without requiring any coding or knowledge of constraint satisfaction. Furthermore, thanks to the constraint-based layout approach, Charticulator can export chart designs into reusable templates that can be imported into other visualization tools. In addition to describing Charticulator's conceptual framework and design, we present three forms of evaluation: a gallery to illustrate its expressiveness, a user study to verify its usability, and a click-count comparison between Charticulator and three existing tools. Finally, we discuss the limitations and potentials of Charticulator as well as directions for future research. Charticulator is available with its source code at https://charticulator.com.",10.1109/TVCG.2018.2865158,,TRUE,TRUE,TRUE,T,T,F,C1,DROP,0,,,visualization,1,1,1,1,1,0,1,0,0,0,0,,11,2. domain user,11,,,0,1,0,0,1,1,0,1,0,0,0,0,0,1,0,1,1,1,0,0,0,0,0,1,1,0,4. After the deployment,1,,
78,28,2018J076,Embedded Merge & Split: Visual Adjustment of Data Grouping,"Sarvghad, Ali and Saket, Bahador and Endert, Alex and Weibel, Nadir",2018,2019,Data visualization;Tools;Visualization;Bars;Histograms;Data analysis;Synthetic aperture sonar;Data Visualization;Direct Manipulation;Embedded Merge & Split;Data Grouping;Embedded Interaction,"Data grouping is among the most frequently used operations in data visualization. It is the process through which relevant information is gathered, simplified, and expressed in summary form. Many popular visualization tools support automatic grouping of data (e.g., dividing up a numerical variable into bins). Although grouping plays a pivotal role in supporting data exploration, further adjustment and customization of auto-generated grouping criteria is non-trivial. Such adjustments are currently performed either programmatically or through menus and dialogues which require specific parameter adjustments over several steps. In response, we introduce Embedded Merge & Split (EMS), a new interaction technique for direct adjustment of data grouping criteria. We demonstrate how the EMS technique can be designed to directly manipulate width and position in bar charts and histograms, as a means for adjustment of data grouping criteria. We also offer a set of design guidelines for supporting EMS. Finally, we present the results of two user studies, providing initial evidence that EMS can significantly reduce interaction time compared to WIMP-based technique and was subjectively preferred by participants.",10.1109/TVCG.2018.2865075,,TRUE,TRUE,TRUE,,T,F,C1,DROP,0,,,,1,1,1,1,0,0,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
80,29,2018J078,Optimizing Color Assignment for Perception of Class Separability in Multiclass Scatterplots,"Wang, Yunhai and Chen, Xin and Ge, Tong and Bao, Chen and Sedlmair, Michael and Fu, Chi-Wing and Deussen, Oliver and Chen, Baoquan",2018,2019,Image color analysis;Visualization;Data visualization;Task analysis;Genetic algorithms;Optimization;Tools;Color perception;visual design;scatterplots,"Appropriate choice of colors significantly aids viewers in understanding the structures in multiclass scatterplots and becomes more important with a growing number of data points and groups. An appropriate color mapping is also an important parameter for the creation of an aesthetically pleasing scatterplot. Currently, users of visualization software routinely rely on color mappings that have been pre-defined by the software. A default color mapping, however, cannot ensure an optimal perceptual separability between groups, and sometimes may even lead to a misinterpretation of the data. In this paper, we present an effective approach for color assignment based on a set of given colors that is designed to optimize the perception of scatterplots. Our approach takes into account the spatial relationships, density, degree of overlap between point clusters, and also the background color. For this purpose, we use a genetic algorithm that is able to efficiently find good color assignments. We implemented an interactive color assignment system with three extensions of the basic method that incorporates top $K$ suggestions, user-defined color subsets, and classes of interest for the optimization. To demonstrate the effectiveness of our assignment technique, we conducted a numerical study and a controlled user study to compare our approach with default color assignments; our findings were verified by two expert studies. The results show that our approach is able to support users in distinguishing cluster numbers faster and more precisely than default assignment methods.",10.1109/TVCG.2018.2864912,,TRUE,TRUE,TRUE,,T,F,C1,DROP,0,,,,1,1,1,1,0,0,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
82,30,2018J080,Image-Based Aspect Ratio Selection,"Wang, Yunhai and Wang, Zeyu and Fu, Chi-Wing and Schmauder, HansjÃ¶rq and Deussen, Oliver and Weiskopf, Daniel",2018,2019,Two dimensional displays;Banking;Data visualization;Kernel;Market research;Estimation;Visualization;Aspect ratio;image-based method;Federer's co-area formula;density field;anisotropic kernel density estimation,"Selecting a good aspect ratio is crucial for effective 2D diagrams. There are several aspect ratio selection methods for function plots and line charts, but only few can handle general, discrete diagrams such as 2D scatter plots. However, these methods either lack a perceptual foundation or heavily rely on intermediate isoline representations, which depend on choosing the right isovalues and are time-consuming to compute. This paper introduces a general image-based approach for selecting aspect ratios for a wide variety of 2D diagrams, ranging from scatter plots and density function plots to line charts. Our approach is derived from Federer's co-area formula and a line integral representation that enable us to directly construct image-based versions of existing selection methods using density fields. In contrast to previous methods, our approach bypasses isoline computation, so it is faster to compute, while following the perceptual foundation to select aspect ratios. Furthermore, this approach is complemented by an anisotropic kernel density estimation to construct density fields, allowing us to more faithfully characterize data patterns, such as the subgroups in scatterplots or dense regions in time series. We demonstrate the effectiveness of our approach by quantitatively comparing to previous methods and revisiting a prior user study. Finally, we present extensions for ROI banking, multi-scale banking, and the application to image data.",10.1109/TVCG.2018.2865266,,TRUE,TRUE,TRUE,,T,F,C2,DROP,0,,,,,,,,0,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6,327,2018J081,Mitigating the Attraction Effect with Visualizations,"Dimara, Evanthia and Bailly, Gilles and Bezerianos, Anastasia and Franconeri, Steven",2018,2019,Data visualization;Training;Decision making;Cognition;Visualization;Task analysis;Decision making;cognitive bias;bias alleviation;bias mitigation;debiasing;information visualization;attraction effect,"Human decisions are prone to biases, and this is no less true for decisions made within data visualizations. Bias mitigation strategies often focus on the person, by educating people about their biases, typically with little success. We focus instead on the system, presenting the first evidence that altering the design of an interactive visualization tool can mitigate a strong bias - the attraction effect. Participants viewed 2D scatterplots where choices between superior alternatives were affected by the placement of other suboptimal points. We found that highlighting the superior alternatives weakened the bias, but did not eliminate it. We then tested an interactive approach where participants completely removed locally dominated points from the view, inspired by the elimination by aspects strategy in the decision-making literature. This approach strongly decreased the bias, leading to a counterintuitive suggestion: tools that allow removing inappropriately salient or distracting data from a view may help lead users to make more rational decisions.",10.1109/TVCG.2018.2865233,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
85,31,2018J085,Hypothetical Outcome Plots Help Untrained Observers Judge Trends in Ambiguous Data,"Kale, Alex and Nguyen, Francis and Kay, Matthew and Hullman, Jessica",2018,2019,Uncertainty;Data visualization;Visualization;Bars;Task analysis;Observers;Encoding;uncertainty visualization;hypothetical outcome plots;psychometric functions,"Animated representations of outcomes drawn from distributions (hypothetical outcome plots, or HOPs) are used in the media and other public venues to communicate uncertainty. HOPs greatly improve multivariate probability estimation over conventional static uncertainty visualizations and leverage the ability of the visual system to quickly, accurately, and automatically process the summary statistical properties of ensembles. However, it is unclear how well HOPs support applied tasks resembling real world judgments posed in uncertainty communication. We identify and motivate an appropriate task to investigate realistic judgments of uncertainty in the public domain through a qualitative analysis of uncertainty visualizations in the news. We contribute two crowdsourced experiments comparing the effectiveness of HOPs, error bars, and line ensembles for supporting perceptual decision-making from visualized uncertainty. Participants infer which of two possible underlying trends is more likely to have produced a sample of time series data by referencing uncertainty visualizations which depict the two trends with variability due to sampling error. By modeling each participant's accuracy as a function of the level of evidence presented over many repeated judgments, we find that observers are able to correctly infer the underlying trend in samples conveying a lower level of evidence when using HOPs rather than static aggregate uncertainty visualizations as a decision aid. Modeling approaches like ours contribute theoretically grounded and richly descriptive accounts of user perceptions to visualization evaluation.",10.1109/TVCG.2018.2864909,,TRUE,TRUE,TRUE,T,,F,C2,DROP,0,,,,,,,,0,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2018J086,In Pursuit of Error: A Survey of Uncertainty Visualization Evaluation,"Hullman, Jessica and Qiao, Xiaoli and Correll, Michael and Kale, Alex and Kay, Matthew",2018,2019,Uncertainty;Visualization;Taxonomy;Data visualization;Task analysis;Measurement uncertainty;Decision making;Uncertainty visualization;user study;subjective confidence;probability distribution,"Understanding and accounting for uncertainty is critical to effectively reasoning about visualized data. However, evaluating the impact of an uncertainty visualization is complex due to the difficulties that people have interpreting uncertainty and the challenge of defining correct behavior with uncertainty information. Currently, evaluators of uncertainty visualization must rely on general purpose visualization evaluation frameworks which can be ill-equipped to provide guidance with the unique difficulties of assessing judgments under uncertainty. To help evaluators navigate these complexities, we present a taxonomy for characterizing decisions made in designing an evaluation of an uncertainty visualization. Our taxonomy differentiates six levels of decisions that comprise an uncertainty visualization evaluation: the behavioral targets of the study, expected effects from an uncertainty visualization, evaluation goals, measures, elicitation techniques, and analysis approaches. Applying our taxonomy to 86 user studies of uncertainty visualizations, we find that existing evaluation practice, particularly in visualization research, focuses on Performance and Satisfaction-based measures that assume more predictable and statistically-driven judgment behavior than is suggested by research on human judgment and decision making. We reflect on common themes in evaluation practice concerning the interpretation and semantics of uncertainty, the use of confidence reporting, and a bias toward evaluating performance as accuracy rather than decision quality. We conclude with a concrete set of recommendations for evaluators designed to reduce the mismatch between the conceptualization of uncertainty in visualization versus other fields.",10.1109/TVCG.2018.2864889,,TRUE,TRUE,TRUE,T,T,F,C2,DROP,0,,,,,,0,,0,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2018J088,A Framework for Externalizing Implicit Error Using Visualization,"Mccurdy, Nina and Gerdes, Julie and Meyer, Miriah",2018,2019,Tools;Data visualization;Public healthcare;Surveillance;Diseases;Visualization;implicit error;knowledge externalization;design study,"This paper presents a framework for externalizing and analyzing expert knowledge about discrepancies in data through the use of visualization. Grounded in an 18-month design study with global health experts, the framework formalizes the notion of data discrepancies as implicit error, both in global health data and more broadly. We use the term implicit error to describe measurement error that is inherent to and pervasive throughout a dataset, but that isn't explicitly accounted for or defined. Instead, implicit error exists in the minds of experts, is mainly qualitative, and is accounted for subjectively during expert interpretation of the data. Externalizing knowledge surrounding implicit error can assist in synchronizing, validating, and enhancing interpretation, and can inform error analysis and mitigation. The framework consists of a description of implicit error components that are important for downstream analysis, along with a process model for externalizing and analyzing implicit error using visualization. As a second contribution, we provide a rich, reflective, and verifiable description of our research process as an exemplar summary toward the ongoing inquiry into ways of increasing the validity and transferability of design study research.",10.1109/TVCG.2018.2864913,,TRUE,TRUE,FALSE,,,T,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
13,328,2018J094,Visualization of Large Molecular Trajectories,"Duran, David and Hermosilla, Pedro and Ropinski, Timo and KozlÃ­kovÃ¡, Barbora and Vinacua, Ãlvar and VÃ¡zquez, Pere-Pau",2018,2019,Trajectory;Proteins;Three-dimensional displays;Computational modeling;Visualization;Data models;Inspection;Molecular visualization;simulation inspection;long trajectories,"The analysis of protein-ligand interactions is a time-intensive task. Researchers have to analyze multiple physico-chemical properties of the protein at once and combine them to derive conclusions about the protein-ligand interplay. Typically, several charts are inspected, and 3D animations can be played side-by-side to obtain a deeper understanding of the data. With the advances in simulation techniques, larger and larger datasets are available, with up to hundreds of thousands of steps. Unfortunately, such large trajectories are very difficult to investigate with traditional approaches. Therefore, the need for special tools that facilitate inspection of these large trajectories becomes substantial. In this paper, we present a novel system for visual exploration of very large trajectories in an interactive and user-friendly way. Several visualization motifs are automatically derived from the data to give the user the information about interactions between protein and ligand. Our system offers specialized widgets to ease and accelerate data inspection and navigation to interesting parts of the simulation. The system is suitable also for simulations where multiple ligands are involved. We have tested the usefulness of our tool on a set of datasets obtained from protein engineers, and we describe the expert feedback.",10.1109/TVCG.2018.2864851,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2018J095,Visual Analysis of Aneurysm Data using Statistical Graphics,"Meuschke, Monique and GÃ¼nther, Tobias and Berg, Philipp and WickenhÃ¶fer, Ralph and Preim, Bernhard and Lawonn, Kai",2018,2019,Aneurysm;Data visualization;Two dimensional displays;Three-dimensional displays;Visualization;Surface morphology;Shape;Medical visualizations;aneurysms;blood flow;parametrization,"This paper presents a framework to explore multi-field data of aneurysms occurring at intracranial and cardiac arteries by using statistical graphics. The rupture of an aneurysm is often a fatal scenario, whereas during treatment serious complications for the patient can occur. Whether an aneurysm ruptures or whether a treatment is successful depends on the interaction of different morphological such as wall deformation and thickness, and hemodynamic attributes like wall shear stress and pressure. Therefore, medical researchers are very interested in better understanding these relationships. However, the required analysis is a time-consuming process, where suspicious wall regions are difficult to detect due to the time-dependent behavior of the data. Our proposed visualization framework enables medical researchers to efficiently assess aneurysm risk and treatment options. This comprises a powerful set of views including 2D and 3D depictions of the aneurysm morphology as well as statistical plots of different scalar fields. Brushing and linking aids the user to identify interesting wall regions and to understand the influence of different attributes on the aneurysm's state. Moreover, a visual comparison of pre- and post-treatment as well as different treatment options is provided. Our analysis techniques are designed in collaboration with domain experts, e.g., physicians, and we provide details about the evaluation.",10.1109/TVCG.2018.2864509,,TRUE,TRUE,TRUE,T,T,F,C2,KEEP,1,10. Healthcare and medical imaging,,Healthcare,0,1,1,1,1,1,1,1,0,0,0,1,8,1. domain expert,8,,,1,1,0,0,0,1,0,0,0,0,1,0,0,1,1,1,1,1,0,0,1,0,0,0,0,0,4. After the deployment,1,,
86,32,2018J096,Interactive Visualization of 3D Histopathology in Native Resolution,"Falk, Martin and Ynnerman, Anders and Treanor, Darren and LundstrÃ¶m, Claes",2018,2019,Three-dimensional displays;Data visualization;Pathology;Rendering (computer graphics);Image color analysis;Microscopy;Two dimensional displays;Histology;Pathology;Volume Rendering;Expert Evaluation,"We present a visualization application that enables effective interactive visual analysis of large-scale 3D histopathology, that is, high-resolution 3D microscopy data of human tissue. Clinical work flows and research based on pathology have, until now, largely been dominated by 2D imaging. As we will show in the paper, studying volumetric histology data will open up novel and useful opportunities for both research and clinical practice. Our starting point is the current lack of appropriate visualization tools in histopathology, which has been a limiting factor in the uptake of digital pathology. Visualization of 3D histology data does pose difficult challenges in several aspects. The full-color datasets are dense and large in scale, on the order of $100,000\times 100,000\times 100$ voxels. This entails serious demands on both rendering performance and user experience design. Despite this, our developed application supports interactive study of 3D histology datasets at native resolution. Our application is based on tailoring and tuning of existing methods, system integration work, as well as a careful study of domain specific demands emanating from a close participatory design process with domain experts as team members. Results from a user evaluation employing the tool demonstrate a strong agreement among the 14 participating pathologists that 3D histopathology will be a valuable and enabling tool for their work.",10.1109/TVCG.2018.2864816,,TRUE,TRUE,TRUE,T,,F,C2,KEEP,1,10. Healthcare and medical imaging,,Healthcare,0,1,1,1,1,1,1,1,0,0,0,1,14,1. domain expert,14,,,1,1,0,0,0,1,1,0,0,0,1,0,0,1,0,1,1,1,0,0,0,0,0,1,0,0,4. After the deployment,0,,
88,33,2018J097,Visualization of Neuronal Structures in Wide-Field Microscopy Brain Images,"Boorboor, Saeed and Jadhav, Shreeraj and Ananth, Mala and Talmage, David and Role, Lorna and Kaufman, Arie",2018,2019,Data visualization;Optical microscopy;Neurons;Electron microscopy;Three-dimensional displays;Deconvolution;Wide-field microscopy;volume visualization;neuron visualization;neuroscience,"Wide-field microscopes are commonly used in neurobiology for experimental studies of brain samples. Available visualization tools are limited to electron, two-photon, and confocal microscopy datasets, and current volume rendering techniques do not yield effective results when used with wide-field data. We present a workflow for the visualization of neuronal structures in wide-field microscopy images of brain samples. We introduce a novel gradient-based distance transform that overcomes the out-of-focus blur caused by the inherent design of wide-field microscopes. This is followed by the extraction of the 3D structure of neurites using a multi-scale curvilinear filter and cell-bodies using a Hessian-based enhancement filter. The response from these filters is then applied as an opacity map to the raw data. Based on the visualization challenges faced by domain experts, our workflow provides multiple rendering modes to enable qualitative analysis of neuronal structures, which includes separation of cell-bodies from neurites and an intensity-based classification of the structures. Additionally, we evaluate our visualization results against both a standard image processing deconvolution technique and a confocal microscopy image of the same specimen. We show that our method is significantly faster and requires less computational resources, while producing high quality visualizations. We deploy our workflow in an immersive gigapixel facility as a paradigm for the processing and visualization of large, high-resolution, wide-field microscopy brain datasets.",10.1109/TVCG.2018.2864852,,TRUE,TRUE,TRUE,T,,F,C2,KEEP,1,10. Healthcare and medical imaging,2. Biology and life sciences,Healthcare,0,1,1,1,1,1,1,1,0,0,0,1,1,1. domain expert,1,,,1,1,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,1,0,0,4. After the deployment,0,,
95,34,2018J098,Interactive obstruction-free lensing for volumetric data visualization,"TraorÃ©, Michael and Hurter, Christophe and Telea, Alexandru",2018,2019,Lenses;Strain;Data visualization;Transfer functions;Three-dimensional displays;Animation;Interaction techniques;focus + context;volume visualization;volume rendering;raycasting,"Occlusion is an issue in volumetric visualization as it prevents direct visualization of the region of interest. While many techniques such as transfer functions, volume segmentation or view distortion have been developed to address this, there is still room for improvement to better support the understanding of objects' vicinity. However, most existing Focus+Context fail to solve partial occlusion in datasets where the target and the occluder are very similar density-wise. For these reasons, we investigate a new technique which maintains the general structure of the investigated volumetric dataset while addressing occlusion issues. With our technique, the user interactively defines an area of interest where an occluded region or object is partially visible. Then our lens starts pushing at its border occluding objects, thus revealing hidden volumetric data. Next, the lens is modified with an extended field of view (fish-eye deformation) to better see the vicinity of the selected region. Finally, the user can freely explore the surroundings of the area under investigation within the lens. To provide real-time exploration, we implemented our lens using a GPU accelerated ray-casting framework to handle ray deformations, local lighting, and local viewpoint manipulation. We illustrate our technique with five application scenarios in baggage inspection, 3D fluid flow visualization, chest radiology, air traffic planning, and DTI fiber exploration.",10.1109/TVCG.2018.2864690,,TRUE,TRUE,TRUE,,T,F,C2,KEEP,1,16. Public safety and emergency management,10. Healthcare and medical imaging,"Security, Healthcare, Transportation",1,1,1,0,1,0,1,1,0,0,0,2,11,1. domain expert,3,,,0,1,0,0,0,1,0,1,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,1,0,4. After the deployment,0,,
,,2018J098,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,8,,,0,1,0,0,0,1,0,0,1,0,0,0,0,0,0,1,1,1,0,0,1,0,0,0,1,0,4. After the deployment,0,,
96,35,2018J113,Shared-Memory Parallel Computation of Morse-Smale Complexes with Improved Accuracy,"Gyulassy, Attila and Bremer, Peer-Timo and Pascucci, Valerio",2018,2019,Geometry;Manifolds;Feature extraction;Robustness;Isosurfaces;Tools;Morse complex;Parallel Computation;Topology;Accurate Geometry,"Topological techniques have proven to be a powerful tool in the analysis and visualization of large-scale scientific data. In particular, the Morse-Smale complex and its various components provide a rich framework for robust feature definition and computation. Consequently, there now exist a number of approaches to compute Morse-Smale complexes for large-scale data in parallel. However, existing techniques are based on discrete concepts which produce the correct topological structure but are known to introduce grid artifacts in the resulting geometry. Here, we present a new approach that combines parallel streamline computation with combinatorial methods to construct a high-quality discrete Morse-Smale complex. In addition to being invariant to the orientation of the underlying grid, this algorithm allows users to selectively build a subset of features using high-quality geometry. In particular, a user may specifically select which ascending/descending manifolds are reconstructed with improved accuracy, focusing computational effort where it matters for subsequent analysis. This approach computes Morse-Smale complexes for larger data than previously feasible with significant speedups. We demonstrate and validate our approach using several examples from a variety of different scientific domains, and evaluate the performance of our method.",10.1109/TVCG.2018.2864848,,TRUE,TRUE,TRUE,T,,F,C2,DROP,0,,,,,,,,0,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
97,36,2018J115,Firefly: Virtual Illumination Drones for Interactive Visualization,"Stoppel, Sergej and Erga, Magnus Paulson and Bruckner, Stefan",2018,2019,Lighting;Light sources;Cameras;Optimization;Drones;Geometry;Task analysis;Dynamic lighting design;lighting drones,"Light specification in three dimensional scenes is a complex problem and several approaches have been presented that aim to automate this process. However, there are many scenarios where a static light setup is insufficient, as the scene content and camera position may change. Simultaneous manual control over the camera and light position imposes a high cognitive load on the user. To address this challenge, we introduce a novel approach for automatic scene illumination with Fireflies. Fireflies are intelligent virtual light drones that illuminate the scene by traveling on a closed path. The Firefly path automatically adapts to changes in the scene based on an outcome-oriented energy function. To achieve interactive performance, we employ a parallel rendering pipeline for the light path evaluations. We provide a catalog of energy functions for various application scenarios and discuss the applicability of our method on several examples.",10.1109/TVCG.2018.2864656,,TRUE,TRUE,TRUE,T,T,F,C2,DROP,0,,,,,0,,,0,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
98,37,2018J118,Exploring Time-Varying Multivariate Volume Data Using Matrix of Isosurface Similarity Maps,"Tao, Jun and Imre, Martin and Wang, Chaoli and Chawla, Nitesh V. and Guo, Hanqi and Sever, GÃ¶khan and Kim, Seung Hyun",2018,2019,Isosurfaces;Visualization;Rendering (computer graphics);Tools;Space exploration;Data mining;Time-varying multivariate data visualization;isosurface;similarity map;visual interface;path recommendation,"We present a novel visual representation and interface named the matrix of isosurface similarity maps (MISM) for effective exploration of large time-varying multivariate volumetric data sets. MISM synthesizes three types of similarity maps (i.e., self, temporal, and variable similarity maps) to capture the essential relationships among isosurfaces of different variables and time steps. Additionally, it serves as the main visual mapping and navigation tool for examining the vast number of isosurfaces and exploring the underlying time-varying multivariate data set. We present temporal clustering, variable grouping, and interactive filtering to reduce the huge exploration space of MISM. In conjunction with the isovalue and isosurface views, MISM allows users to identify important isosurfaces or isosurface pairs and compare them over space, time, and value range. More importantly, we introduce path recommendation that suggests, animates, and compares traversal paths for effectively exploring MISM under varied criteria and at different levels-of-detail. A silhouette-based method is applied to render multiple surfaces of interest in a visually succinct manner. We demonstrate the effectiveness of our approach with case studies of several time-varying multivariate data sets and an ensemble data set, and evaluate our work with two domain experts.",10.1109/TVCG.2018.2864808,,TRUE,TRUE,TRUE,T,T,F,C2,KEEP,1,15. Physics and astronomy,14. Materials science and nanotechnology,Physical and material sciences,1,1,1,1,1,0,1,1,0,0,0,1,2,1. domain expert,2,,,1,1,0,0,0,0,1,0,1,0,1,0,0,0,0,0,1,1,0,0,1,0,0,1,1,0,4. After the deployment,0,,
115,38,2019J001,FlowSense: A Natural Language Interface for Visual Data Exploration within a Dataflow System,"Yu, Bowen and Silva, ClÃ¡udio T.",2019,2020,Data visualization;Visualization;Semantics;Usability;Data analysis;Task analysis;Automobiles;Natural language interface;dataflow visualization system;visual data exploration,"Dataflow visualization systems enable flexible visual data exploration by allowing the user to construct a dataflow diagram that composes query and visualization modules to specify system functionality. However learning dataflow diagram usage presents overhead that often discourages the user. In this work we design FlowSense, a natural language interface for dataflow visualization systems that utilizes state-of-the-art natural language processing techniques to assist dataflow diagram construction. FlowSense employs a semantic parser with special utterance tagging and special utterance placeholders to generalize to different datasets and dataflow diagrams. It explicitly presents recognized dataset and diagram special utterances to the user for dataflow context awareness. With FlowSense the user can expand and adjust dataflow diagrams more conveniently via plain English. We apply FlowSense to the VisFlow subset-flow visualization system to enhance its usability. We evaluate FlowSense by one case study with domain experts on a real-world data analysis problem and a formal user study.",10.1109/TVCG.2019.2934668,,TRUE,TRUE,TRUE,T,T,F,C2,DROP,0,,,,,,,,0,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
21,329,2019J002,Data Changes Everything: Challenges and Opportunities in Data Visualization Design Handoff,"Walny, Jagoda and Frisson, Christian and West, Mieka and Kosminsky, Doris and Knudsen, SÃ¸ren and Carpendale, Sheelagh and Willett, Wesley",2019,2020,Data visualization;Tools;Collaboration;Design tools;Software;Task analysis;Information visualization;design handoff;data mapping;design process,"Complex data visualization design projects often entail collaboration between people with different visualization-related skills. For example, many teams include both designers who create new visualization designs and developers who implement the resulting visualization software. We identify gaps between data characterization tools, visualization design tools, and development platforms that pose challenges for designer-developer teams working to create new data visualizations. While it is common for commercial interaction design tools to support collaboration between designers and developers, creating data visualizations poses several unique challenges that are not supported by current tools. In particular, visualization designers must characterize and build an understanding of the underlying data, then specify layouts, data encodings, and other data-driven parameters that will be robust across many different data values. In larger teams, designers must also clearly communicate these mappings and their dependencies to developers, clients, and other collaborators. We report observations and reflections from five large multidisciplinary visualization design projects and highlight six data-specific visualization challenges for design specification and handoff. These challenges include adapting to changing data, anticipating edge cases in data, understanding technical challenges, articulating data-dependent interactions, communicating data mappings, and preserving the integrity of data mappings across iterations. Based on these observations, we identify opportunities for future tools for prototyping, testing, and communicating data-driven designs, which might contribute to more successful and collaborative data visualization design.",10.1109/TVCG.2019.2934538,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
121,39,2019J004,NNVA: Neural Network Assisted Visual Analysis of Yeast Cell Polarization Simulation,"Hazarika, Subhashis and Li, Haoyu and Wang, Ko-Chih and Shen, Han-Wei and Chou, Ching-Shan",2019,2020,Analytical models;Computational modeling;Visualization;Biological system modeling;Neural networks;Machine learning;Data models;Surrogate modeling;Neural networks;Computational biology;Visual analysis;Parameter analysis,"Complex computational models are often designed to simulate real-world physical phenomena in many scientific disciplines. However, these simulation models tend to be computationally very expensive and involve a large number of simulation input parameters, which need to be analyzed and properly calibrated before the models can be applied for real scientific studies. We propose a visual analysis system to facilitate interactive exploratory analysis of high-dimensional input parameter space for a complex yeast cell polarization simulation. The proposed system can assist the computational biologists, who designed the simulation model, to visually calibrate the input parameters by modifying the parameter values and immediately visualizing the predicted simulation outcome without having the need to run the original expensive simulation for every instance. Our proposed visual analysis system is driven by a trained neural network-based surrogate model as the backend analysis framework. In this work, we demonstrate the advantage of using neural networks as surrogate models for visual analysis by incorporating some of the recent advances in the field of uncertainty quantification, interpretability and explainability of neural network-based models. We utilize the trained network to perform interactive parameter sensitivity analysis of the original simulation as well as recommend optimal parameter configurations using the activation maximization framework of neural networks. We also facilitate detail analysis of the trained network to extract useful insights about the simulation model, learned by the network, during the training process. We performed two case studies, and discovered multiple new parameter configurations, which can trigger high cell polarization results in the original simulation model. We evaluated our results by comparing with the original simulation model outcomes as well as the findings from previous parameter analysis performed by our experts.",10.1109/TVCG.2019.2934591,,TRUE,TRUE,TRUE,T,T,F,C1,KEEP,1,2. Biology and life sciences,,computational biology,0,1,1,1,1,1,1,1,0,1,0,2,3,1. domain expert,3,,,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,4. After the deployment,0,,
34,330,2019J007,Understanding the Role of Alternatives in Data Analysis Practices,"Liu, Jiali and Boukhelifa, Nadia and Eagan, James R.",2019,2020,Tools;Data analysis;Analytical models;Computational modeling;Interviews;Task analysis;Data models;alternatives;data workers;data analysis;data science;sensemaking;qualitative study,"Data workers are people who perform data analysis activities as a part of their daily work but do not formally identify as data scientists. They come from various domains and often need to explore diverse sets of hypotheses and theories, a variety of data sources, algorithms, methods, tools, and visual designs. Taken together, we call these alternatives. To better understand and characterize the role of alternatives in their analyses, we conducted semi-structured interviews with 12 data workers with different types of expertise. We conducted four types of analyses to understand 1) why data workers explore alternatives; 2) the different notions of alternatives and how they fit into the sensemaking process; 3) the high-level processes around alternatives; and 4) their strategies to generate, explore, and manage those alternatives. We find that participants' diverse levels of domain and computational expertise, experience with different tools, and collaboration within their broader context play an important role in how they explore these alternatives. These findings call out the need for more attention towards a deeper understanding of alternatives and the need for better tools to facilitate the exploration, interpretation, and management of alternatives. Drawing upon these analyses and findings, we present a framework based on participants' 1) degree of attention, 2) abstraction level, and 3) analytic processes. We show how this framework can help understand how data workers consider such alternatives in their analyses and how tool designers might create tools to better support them.",10.1109/TVCG.2019.2934593,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2019J004,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,5. no participant,0,,,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,4. After the deployment,0,,
123,40,2019J008,VASABI: Hierarchical User Profiles for Interactive Visual User Behaviour Analytics,"Nguyen, Phong H. and Henkin, Rafael and Chen, Siming and Andrienko, Natalia and Andrienko, Gennady and Thonnard, Olivier and Turkay, Cagatay",2019,2020,Task analysis;Data visualization;Feature extraction;Visual analytics;Analytical models;Buildings;hierarchical user profiles;user behaviour analytics;visual analytics;cybersecurity,"User behaviour analytics (UBA) systems offer sophisticated models that capture users' behaviour over time with an aim to identify fraudulent activities that do not match their profiles. Motivated by the challenges in the interpretation of UBA models, this paper presents a visual analytics approach to help analysts gain a comprehensive understanding of user behaviour at multiple levels, namely individual and group level. We take a user-centred approach to design a visual analytics framework supporting the analysis of collections of users and the numerous sessions of activities they conduct within digital applications. The framework is centred around the concept of hierarchical user profiles that are built based on features derived from sessions, as well as on user tasks extracted using a topic modelling approach to summarise and stratify user behaviour. We externalise a series of analysis goals and tasks, and evaluate our methods through use cases conducted with experts. We observe that with the aid of interactive visual hierarchical user profiles, analysts are able to conduct exploratory and investigative analysis effectively, and able to understand the characteristics of user behaviour to make informed decisions whilst evaluating suspicious users and activities.",10.1109/TVCG.2019.2934609,,TRUE,TRUE,TRUE,T,,F,C1,KEEP,1,4. Computer networks and security,,cybersecurity,0,1,1,1,1,1,1,1,0,0,0,2,7,1. domain expert,5,,,1,0,0,0,0,0,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1. Before the deployment (General),1,,
,,2019J008,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,2,,,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,4. After the deployment,0,,
138,41,2019J018,GUIRO: User-Guided Matrix Reordering,"Behrisch, Michael and Schreck, Tobias and Pfister, Hanspeter",2019,2020,Visualization;Data visualization;Indexes;Topology;Measurement;Task analysis;Partitioning algorithms;Visual Analytics;matrix;black-box algorithms;seriation;ordering;sorting;steerable algorithm;interaction;2D projection,"Matrix representations are one of the main established and empirically proven to be effective visualization techniques for relational (or network) data. However, matrices-similar to node-link diagrams-are most effective if their layout reveals the underlying data topology. Given the many developed algorithms, a practical problem arises: â€œWhich matrix reordering algorithm should I choose for my dataset at hand?â€ To make matters worse, different reordering algorithms applied to the same dataset may let significantly different visual matrix patterns emerge. This leads to the question of trustworthiness and explainability of these fully automated, often heuristic, black-box processes. We present GUIRO, a Visual Analytics system that helps novices, network analysts, and algorithm designers to open the black-box. Users can investigate the usefulness and expressiveness of 70 accessible matrix reordering algorithms. For network analysts, we introduce a novel model space representation and two interaction techniques for a user-guided reordering of rows or columns, and especially groups thereof (submatrix reordering). These novel techniques contribute to the understanding of the global and local dataset topology. We support algorithm designers by giving them access to 16 reordering quality metrics and visual exploration means for comparing reordering implementations on a row/column permutation level. We evaluated GUIRO in a guided explorative user study with 12 subjects, a case study demonstrating its usefulness in a real-world scenario, and through an expert study gathering feedback on our design decisions. We found that our proposed methods help even inexperienced users to understand matrix patterns and allow a user-guided steering of reordering algorithms. GUIRO helps to increase the transparency of matrix reordering algorithms, thus helping a broad range of users to get a better insight into the complex reordering process, in turn supporting data and reordering algorithm insights.",10.1109/TVCG.2019.2934300,,TRUE,TRUE,TRUE,T,T,F,C1,KEEP,1,7. Engineering and design,,,1,1,1,1,1,0,1,1,1,0,0,3,8,2. domain user,7,3. general public,5,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,4. After the deployment,0,,
,,2019J018,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,5. no participant,0,,,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,4. After the deployment,0,,
,,2019J018,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,1,,,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,4. After the deployment,0,,
62,331,2019J022,Facetto: Combining Unsupervised and Supervised Learning for Hierarchical Phenotype Analysis in Multi-Channel Image Data,"Krueger, Robert and Beyer, Johanna and Jang, Won-Dong and Kim, Nam Wook and Sokolov, Artem and Sorger, Peter K. and Pfister, Hanspeter",2019,2020,Cancer;Tools;Visualization;Rendering (computer graphics);Biomedical imaging;Multiplexing;Clustering;Classification;Visual Analysis;Multiplex Tissue Imaging;Digital Pathology;Cancer Systems Biology,"Facetto is a scalable visual analytics application that is used to discover single-cell phenotypes in high-dimensional multi-channel microscopy images of human tumors and tissues. Such images represent the cutting edge of digital histology and promise to revolutionize how diseases such as cancer are studied, diagnosed, and treated. Highly multiplexed tissue images are complex, comprising 109 or more pixels, 60-plus channels, and millions of individual cells. This makes manual analysis challenging and error-prone. Existing automated approaches are also inadequate, in large part, because they are unable to effectively exploit the deep knowledge of human tissue biology available to anatomic pathologists. To overcome these challenges, Facetto enables a semi-automated analysis of cell types and states. It integrates unsupervised and supervised learning into the image and feature exploration process and offers tools for analytical provenance. Experts can cluster the data to discover new types of cancer and immune cells and use clustering results to train a convolutional neural network that classifies new cells accordingly. Likewise, the output of classifiers can be clustered to discover aggregate patterns and phenotype subsets. We also introduce a new hierarchical approach to keep track of analysis steps and data subsets created by users; this assists in the identification of cell types. Users can build phenotype trees and interact with the resulting hierarchical structures of both high-dimensional feature and image spaces. We report on use-cases in which domain scientists explore various large-scale fluorescence imaging datasets. We demonstrate how Facetto assists users in steering the clustering and classification process, inspecting analysis results, and gaining new scientific insights into cancer biology.",10.1109/TVCG.2019.2934547,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
139,42,2019J023,ProtoSteer: Steering Deep Sequence Model with Prototypes,"Ming, Yao and Xu, Panpan and Cheng, Furui and Qu, Huamin and Ren, Liu",2019,2020,Prototypes;Data visualization;Data models;Machine learning;Computational modeling;Predictive models;Task analysis;Sequence Data;Explainable Artificial Intelligence (XAI);Recurrent Neural Networks (RNNs);Prototype Learning,"Recently we have witnessed growing adoption of deep sequence models (e.g. LSTMs) in many application domains, including predictive health care, natural language processing, and log analysis. However, the intricate working mechanism of these models confines their accessibility to the domain experts. Their black-box nature also makes it a challenging task to incorporate domain-specific knowledge of the experts into the model. In ProtoSteer (Prototype Steering), we tackle the challenge of directly involving the domain experts to steer a deep sequence model without relying on model developers as intermediaries. Our approach originates in case-based reasoning, which imitates the common human problem-solving process of consulting past experiences to solve new problems. We utilize ProSeNet (Prototype Sequence Network), which learns a small set of exemplar cases (i.e., prototypes) from historical data. In ProtoSteer they serve both as an efficient visual summary of the original data and explanations of model decisions. With ProtoSteer the domain experts can inspect, critique, and revise the prototypes interactively. The system then incorporates user-specified prototypes and incrementally updates the model. We conduct extensive case studies and expert interviews in application domains including sentiment analysis on texts and predictive diagnostics based on vehicle fault logs. The results demonstrate that involvements of domain users can help obtain more interpretable models with concise prototypes while retaining similar accuracy.",10.1109/TVCG.2019.2934267,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,1. AI (Machine Learning/Deep Learning/Data Mining),,xai,1,1,1,0,1,0,1,1,1,0,0,1,5,1. domain expert,5,,,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,0,1,1,0,0,0,0,0,4. After the deployment,0,,
150,43,2019J033,VisTA: Integrating Machine Intelligence with Visualization to Support the Investigation of Think-Aloud Sessions,"Fan, Mingming and Wu, Ke and Zhao, Jian and Li, Yue and Wei, Winter and Truong, Khai N.",2019,2020,Usability;Visual analytics;Tools;Machine intelligence;Feature extraction;Machine learning;Think-aloud;visual analytics;machine intelligence;user study;usability problems;session review behavior;UX practices,"Think-aloud protocols are widely used by user experience (UX) practitioners in usability testing to uncover issues in user interface design. It is often arduous to analyze large amounts of recorded think-aloud sessions and few UX practitioners have an opportunity to get a second perspective during their analysis due to time and resource constraints. Inspired by the recent research that shows subtle verbalization and speech patterns tend to occur when users encounter usability problems, we take the first step to design and evaluate an intelligent visual analytics tool that leverages such patterns to identify usability problem encounters and present them to UX practitioners to assist their analysis. We first conducted and recorded think-aloud sessions, and then extracted textual and acoustic features from the recordings and trained machine learning (ML) models to detect problem encounters. Next, we iteratively designed and developed a visual analytics tool, VisTA, which enables dynamic investigation of think-aloud sessions with a timeline visualization of ML predictions and input features. We conducted a between-subjects laboratory study to compare three conditions, i.e., VisTA, VisTASimple (no visualization of the ML's input features), and Baseline (no ML information at all), with 30 UX professionals. The findings show that UX professionals identified more problem encounters when using VisTA than Baseline by leveraging the problem visualization as an overview, anticipations, and anchors as well as the feature visualization as a means to understand what ML considers and omits. Our findings also provide insights into how they treated ML, dealt with (dis)agreement with ML, and reviewed the videos (i.e., play, pause, and rewind).",10.1109/TVCG.2019.2934797,,TRUE,TRUE,TRUE,T,,F,C1,KEEP,1,19. Others,,UX Evaluation,0,1,1,1,1,0,1,1,0,1,0,2,42,2. domain user,12,,,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,3. Before the deployment (During the development and refinement phrase ONLY),1,,
,,2019J033,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,2. domain user,30,,,1,1,0,0,1,1,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,1,0,1,1,1,4. After the deployment,0,,
151,44,2019J035,A Comparative Evaluation of Animation and Small Multiples for Trend Visualization on Mobile Phones,"Brehmer, Matthew and Lee, Bongshin and Isenberg, Petra and Choe, Eun Kyoung",2019,2020,Data visualization;Animation;Task analysis;Market research;Mobile handsets;Trajectory;Mobile applications;Evaluation;graphical perception;mobile phones;trend visualization;animation;small multiples;crowdsourcing,"We compare the efficacy of animated and small multiples variants of scatterplots on mobile phones for comparing trends in multivariate datasets. Visualization is increasingly prevalent in mobile applications and mobile-first websites, yet there is little prior visualization research dedicated to small displays. In this paper, we build upon previous experimental research carried out on larger displays that assessed animated and non-animated variants of scatterplots. Incorporating similar experimental stimuli and tasks, we conducted an experiment where 96 crowdworker participants performed nine trend comparison tasks using their mobile phones. We found that those using a small multiples design consistently completed tasks in less time, albeit with slightly less confidence than those using an animated design. The accuracy results were more task-dependent, and we further interpret our results according to the characteristics of the individual tasks, with a specific focus on the trajectories of target and distractor data items in each task. We identify cases that appear to favor either animation or small multiples, providing new questions for further experimental research and implications for visualization design on mobile devices. Lastly, we provide a reflection on our evaluation methodology.",10.1109/TVCG.2019.2934397,,TRUE,TRUE,TRUE,T,,F,C1,DROP,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
152,45,2019J039,Tac-Simur: Tactic-based Simulative Visual Analytics of Table Tennis,"Wang, Jiachen and Zhao, Kejian and Deng, Dazhen and Cao, Anqi and Xie, Xiao and Zhou, Zheng and Zhang, Hui and Wu, Yingcai",2019,2020,Sports;Visual analytics;Analytical models;Markov processes;Games;Predictive models;Numerical models;Simulative Visual Analytics;Table Tennis;Design Study,"Simulative analysis in competitive sports can provide prospective insights, which can help improve the performance of players in future matches. However, adequately simulating the complex competition process and effectively explaining the simulation result to domain experts are typically challenging. This work presents a design study to address these challenges in table tennis. We propose a well-established hybrid second-order Markov chain model to characterize and simulate the competition process in table tennis. Compared with existing methods, our approach is the first to support the effective simulation of tactics, which represent high-level competition strategies in table tennis. Furthermore, we introduce a visual analytics system called Tac-Simur based on the proposed model for simulative visual analytics. Tac-Simur enables users to easily navigate different players and their tactics based on their respective performance in matches to identify the player and the tactics of interest for further analysis. Then, users can utilize the system to interactively explore diverse simulation tasks and visually explain the simulation results. The effectiveness and usefulness of this work are demonstrated by two case studies, in which domain experts utilize Tac-Simur to find interesting and valuable insights. The domain experts also provide positive feedback on the usability of Tac-Simur. Our work can be extended to other similar sports such as tennis and badminton.",10.1109/TVCG.2019.2934630,,TRUE,TRUE,TRUE,,T,T,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
68,332,2019J041,Selection Bias Tracking and Detailed Subset Comparison for High-Dimensional Data,"Borland, David and Wang, Wenyuan and Zhang, Jonathan and Shrestha, Joshua and Gotz, David",2019,2020,Data visualization;Visual analytics;Encoding;Tools;Complexity theory;Medical diagnostic imaging;High-dimensional visualization;visual analytics;cohort selection;medical informatics;selection bias,"The collection of large, complex datasets has become common across a wide variety of domains. Visual analytics tools increasingly play a key role in exploring and answering complex questions about these large datasets. However, many visualizations are not designed to concurrently visualize the large number of dimensions present in complex datasets (e.g. tens of thousands of distinct codes in an electronic health record system). This fact, combined with the ability of many visual analytics systems to enable rapid, ad-hoc specification of groups, or cohorts, of individuals based on a small subset of visualized dimensions, leads to the possibility of introducing selection bias-when the user creates a cohort based on a specified set of dimensions, differences across many other unseen dimensions may also be introduced. These unintended side effects may result in the cohort no longer being representative of the larger population intended to be studied, which can negatively affect the validity of subsequent analyses. We present techniques for selection bias tracking and visualization that can be incorporated into high-dimensional exploratory visual analytics systems, with a focus on medical data with existing data hierarchies. These techniques include: (1) tree-based cohort provenance and visualization, including a user-specified baseline cohort that all other cohorts are compared against, and visual encoding of cohort â€œdriftâ€, which indicates where selection bias may have occurred, and (2) a set of visualizations, including a novel icicle-plot based visualization, to compare in detail the per-dimension differences between the baseline and a user-specified focus cohort. These techniques are integrated into a medical temporal event sequence visual analytics tool. We present example use cases and report findings from domain expert user interviews.",10.1109/TVCG.2019.2934209,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
126,333,2019J042,Visual Analysis of High-Dimensional Event Sequence Data via Dynamic Hierarchical Aggregation,"Gotz, David and Zhang, Jonathan and Wang, Wenyuan and Shrestha, Joshua and Borland, David",2019,2020,Data visualization;Visual analytics;Runtime;Sequences;Layout;Navigation;Temporal event sequence visualization;visual analytics;hierarchical aggregation;medical informatics,"Temporal event data are collected across a broad range of domains, and a variety of visual analytics techniques have been developed to empower analysts working with this form of data. These techniques generally display aggregate statistics computed over sets of event sequences that share common patterns. Such techniques are often hindered, however, by the high-dimensionality of many real-world event sequence datasets which can prevent effective aggregation. A common coping strategy for this challenge is to group event types together prior to visualization, as a pre-process, so that each group can be represented within an analysis as a single event type. However, computing these event groupings as a pre-process also places significant constraints on the analysis. This paper presents a new visual analytics approach for dynamic hierarchical dimension aggregation. The approach leverages a predefined hierarchy of dimensions to computationally quantify the informativeness, with respect to a measure of interest, of alternative levels of grouping within the hierarchy at runtime. This information is then interactively visualized, enabling users to dynamically explore the hierarchy to select the most appropriate level of grouping to use at any individual step within an analysis. Key contributions include an algorithm for interactively determining the most informative set of event groupings for a specific analysis context, and a scented scatter-plus-focus visualization design with an optimization-based layout algorithm that supports interactive hierarchical exploration of alternative event type groupings. We apply these techniques to high-dimensional event sequence data from the medical domain and report findings from domain expert interviews.",10.1109/TVCG.2019.2934661,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
148,334,2019J044,Critical Reflections on Visualization Authoring Systems,"Satyanarayan, Arvind and Lee, Bongshin and Ren, Donghao and Heer, Jeffrey and Stasko, John and Thompson, John and Brehmer, Matthew and Liu, Zhicheng",2019,2020,Data visualization;Programming;Visualization;Authoring systems;Grammar;Interactive systems;Libraries;Critical reflection;visualization authoring;expressivity;learnability;reusability,"An emerging generation of visualization authoring systems support expressive information visualization without textual programming. As they vary in their visualization models, system architectures, and user interfaces, it is challenging to directly compare these systems using traditional evaluative methods. Recognizing the value of contextualizing our decisions in the broader design space, we present critical reflections on three systems we developed - Lyra, Data Illustrator, and Charticulator. This paper surfaces knowledge that would have been daunting within the constituent papers of these three systems. We compare and contrast their (previously unmentioned) limitations and trade-offs between expressivity and learnability. We also reflect on common assumptions that we made during the development of our systems, thereby informing future research directions in visualization authoring systems.",10.1109/TVCG.2019.2934281,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
164,335,2019J046,Investigating Direct Manipulation of Graphical Encodings as a Method for User Interaction,"Saket, Bahador and Huron, Samuel and Perin, Charles and Endert, Alex",2019,2020,Bars;Data visualization;Encoding;Visualization;Image color analysis;Tools;Instruments;Direct Manipulation;Data Visualization,"We investigate direct manipulation of graphical encodings as a method for interacting with visualizations. There is an increasing interest in developing visualization tools that enable users to perform operations by directly manipulating graphical encodings rather than external widgets such as checkboxes and sliders. Designers of such tools must decide which direct manipulation operations should be supported, and identify how each operation can be invoked. However, we lack empirical guidelines for how people convey their intended operations using direct manipulation of graphical encodings. We address this issue by conducting a qualitative study that examines how participants perform 15 operations using direct manipulation of standard graphical encodings. From this study, we 1) identify a list of strategies people employ to perform each operation, 2) observe commonalities in strategies across operations, and 3) derive implications to help designers leverage direct manipulation of graphical encoding as a method for user interaction.",10.1109/TVCG.2019.2934534,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
180,336,2019J047,Artifact-Based Rendering: Harnessing Natural and Traditional Visual Media for More Expressive and Engaging 3D Visualizations,"Johnson, Seth and Samsel, Francesca and Abram, Gregory and Olson, Daniel and Solis, Andrew J. and Herman, Bridger and Wolfram, Phillip J. and Lenglet, Christophe and Keefe, Daniel F.",2019,2020,Data visualization;Visualization;Three-dimensional displays;Rendering (computer graphics);Tools;Media;Image color analysis;Visualization Design;Art and Visualization;Data Physicalization;Multivariate Visualization,"We introduce Artifact-Based Rendering (ABR), a framework of tools, algorithms, and processes that makes it possible to produce real, data-driven 3D scientific visualizations with a visual language derived entirely from colors, lines, textures, and forms created using traditional physical media or found in nature. A theory and process for ABR is presented to address three current needs: (i) designing better visualizations by making it possible for non-programmers to rapidly design and critique many alternative data-to-visual mappings; (ii) expanding the visual vocabulary used in scientific visualizations to depict increasingly complex multivariate data; (iii) bringing a more engaging, natural, and human-relatable handcrafted aesthetic to data visualization. New tools and algorithms to support ABR include front-end applets for constructing artifact-based colormaps, optimizing 3D scanned meshes for use in data visualization, and synthesizing textures from artifacts. These are complemented by an interactive rendering engine with custom algorithms and interfaces that demonstrate multiple new visual styles for depicting point, line, surface, and volume data. A within-the-research-team design study provides early evidence of the shift in visualization design processes that ABR is believed to enable when compared to traditional scientific visualization systems. Qualitative user feedback on applications to climate science and brain imaging support the utility of ABR for scientific discovery and public communication.",10.1109/TVCG.2019.2934260,,TRUE,TRUE,FALSE,,,T,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
155,46,2019J048,Designing for Mobile and Immersive Visual Analytics in the Field,"Whitlock, Matt and Wu, Keke and Szafir, Danielle Albers",2019,2020,Data visualization;Data collection;Tools;Decision making;Mobile handsets;Visual analytics;Emergency services;Immersive Analytics;Augmented Reality;Mobile Visualization;Outdoor Visualization;Emergency Response,"Data collection and analysis in the field is critical for operations in domains such as environmental science and public safety. However, field workers currently face dataand platform-oriented issues in efficient data collection and analysis in the field, such as limited connectivity, screen space, and attentional resources. In this paper, we explore how visual analytics tools might transform field practices by more deeply integrating data into these operations. We use a design probe coupling mobile, cloud, and immersive analytics components to guide interviews with ten experts from five domains to explore how visual analytics could support data collection and analysis needs in the field. The results identify shortcomings of current approaches and target scenarios and design considerations for future field analysis systems. We embody these findings in FieldView, an extensible, open-source prototype designed to support critical use cases for situated field analysis. Our findings suggest the potential for integrating mobile and immersive technologies to enhance data's utility for various field operations and new directions for visual analytics tools to transform fieldwork.",10.1109/TVCG.2019.2934282,,TRUE,TRUE,TRUE,,T,F,C1,DROP-design study,0,,,,1,1,1,1,1,1,0,1,0,0,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
158,47,2019J051,"There Is No Spoon: Evaluating Performance, Space Use, and Presence with Expert Domain Users in Immersive Analytics","Batch, Andrea and Cunningham, Andrew and Cordeil, Maxime and Elmqvist, Niklas and Dwyer, Tim and Thomas, Bruce H. and Marriott, Kim",2019,2020,Three-dimensional displays;Data visualization;Navigation;Data analysis;Macroeconomics;Tools;Design study;evaluation;economic analysis;immersive analytics,"Immersive analytics turns the very space surrounding the user into a canvas for data analysis, supporting human cognitive abilities in myriad ways. We present the results of a design study, contextual inquiry, and longitudinal evaluation involving professional economists using a Virtual Reality (VR) system for multidimensional visualization to explore actual economic data. Results from our preregistered evaluation highlight the varied use of space depending on context (exploration vs. presentation), the organization of space to support work, and the impact of immersion on navigation and orientation in the 3D analysis space.",10.1109/TVCG.2019.2934803,,TRUE,TRUE,TRUE,T,,T,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
166,48,2019J053,Interactive Learning for Identifying Relevant Tweets to Support Real-time Situational Awareness,"Snyder, Luke S. and Lin, Yi-Shan and Karimzadeh, Morteza and Goldwasser, Dan and Ebert, David S.",2019,2020,Real-time systems;Social networking (online);Computational modeling;Visual analytics;Machine learning;Adaptation models;Training;Interactive machine learning;human-computer interaction;social media analytics;emergency/disaster management;situational awareness,"Various domain users are increasingly leveraging real-time social media data to gain rapid situational awareness. However, due to the high noise in the deluge of data, effectively determining semantically relevant information can be difficult, further complicated by the changing definition of relevancy by each end user for different events. The majority of existing methods for short text relevance classification fail to incorporate users' knowledge into the classification process. Existing methods that incorporate interactive user feedback focus on historical datasets. Therefore, classifiers cannot be interactively retrained for specific events or user-dependent needs in real-time. This limits real-time situational awareness, as streaming data that is incorrectly classified cannot be corrected immediately, permitting the possibility for important incoming data to be incorrectly classified as well. We present a novel interactive learning framework to improve the classification process in which the user iteratively corrects the relevancy of tweets in real-time to train the classification model on-the-fly for immediate predictive improvements. We computationally evaluate our classification model adapted to learn at interactive rates. Our results show that our approach outperforms state-of-the-art machine learning models. In addition, we integrate our framework with the extended Social Media Analytics and Reporting Toolkit (SMART) 2.0 system, allowing the use of our interactive learning framework within a visual analytics system tailored for real-time situational awareness. To demonstrate our framework's effectiveness, we provide domain expert feedback from first responders who used the extended SMART 2.0 system.",10.1109/TVCG.2019.2934614,,TRUE,TRUE,TRUE,T,,F,C1,KEEP,1,,,"HCI,Social Media",1,1,1,0,1,1,1,1,1,1,0,2,4,2. domain user,4,,,0,1,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,4. After the deployment,0,,
,,2019J053,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,5. no participant,0,,,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,4. After the deployment,0,,
167,49,2019J055,PlanningVis: A Visual Analytics Approach to Production Planning in Smart Factories,"Sun, Dong and Huang, Renfei and Chen, Yuanzhe and Wang, Yong and Zeng, Jia and Yuan, Mingxuan and Pong, Ting-Chuen and Qu, Huamin",2019,2020,Production facilities;Task analysis;Optimization;Manufacturing;Raw materials;Production Planning;Time Series Data;Comparative Analysis;Visual Analytics;Smart Factory;Industry 4.0,"Production planning in the manufacturing industry is crucial for fully utilizing factory resources (e.g., machines, raw materials and workers) and reducing costs. With the advent of industry 4.0, plenty of data recording the status of factory resources have been collected and further involved in production planning, which brings an unprecedented opportunity to understand, evaluate and adjust complex production plans through a data-driven approach. However, developing a systematic analytics approach for production planning is challenging due to the large volume of production data, the complex dependency between products, and unexpected changes in the market and the plant. Previous studies only provide summarized results and fail to show details for comparative analysis of production plans. Besides, the rapid adjustment to the plan in the case of an unanticipated incident is also not supported. In this paper, we propose PlanningVis, a visual analytics system to support the exploration and comparison of production plans with three levels of details: a plan overview presenting the overall difference between plans, a product view visualizing various properties of individual products, and a production detail view displaying the product dependency and the daily production details in related factories. By integrating an automatic planning algorithm with interactive visual explorations, PlanningVis can facilitate the efficient optimization of daily production planning as well as support a quick response to unanticipated incidents in manufacturing. Two case studies with real-world data and carefully designed interviews with domain experts demonstrate the effectiveness and usability of PlanningVis.",10.1109/TVCG.2019.2934275,,TRUE,TRUE,TRUE,T,T,F,C2,KEEP,1,7. Engineering and design,,Engineering,0,1,1,1,1,1,1,1,0,0,0,1,6,1. domain expert,6,,,1,1,0,0,0,1,0,0,0,0,1,0,0,1,1,0,1,1,0,0,1,0,0,0,1,0,4. After the deployment,0,,
168,50,2019J056,Visual Analytics for Electromagnetic Situation Awareness in Radio Monitoring and Management,"Zhao, Ying and Luo, Xiaobo and Lin, Xiaoru and Wang, Hairong and Kui, Xiaoyan and Zhou, Fangfang and Wang, Jinsong and Chen, Yi and Chen, Wei",2019,2020,Data visualization;Electromagnetics;Time-frequency analysis;Monitoring;Computational modeling;Visual analytics;Radio monitoring and management;radio signal data;radio spectrum data;situation awareness;visual analytics,"Traditional radio monitoring and management largely depend on radio spectrum data analysis, which requires considerable domain experience and heavy cognition effort and frequently results in incorrect signal judgment and incomprehensive situation awareness. Faced with increasingly complicated electromagnetic environments, radio supervisors urgently need additional data sources and advanced analytical technologies to enhance their situation awareness ability. This paper introduces a visual analytics approach for electromagnetic situation awareness. Guided by a detailed scenario and requirement analysis, we first propose a signal clustering method to process radio signal data and a situation assessment model to obtain qualitative and quantitative descriptions of the electromagnetic situations. We then design a two-module interface with a set of visualization views and interactions to help radio supervisors perceive and understand the electromagnetic situations by a joint analysis of radio signal data and radio spectrum data. Evaluations on real-world data sets and an interview with actual users demonstrate the effectiveness of our prototype system. Finally, we discuss the limitations of the proposed approach and provide future work directions.",10.1109/TVCG.2019.2934655,,TRUE,TRUE,TRUE,T,T,F,C2,KEEP,1,19. Others,,Radio Monitoring,0,1,1,1,1,1,1,1,0,0,0,1,2,2. domain user,2,,,1,1,0,0,0,1,1,0,1,0,0,0,0,0,1,0,0,1,0,0,1,1,0,1,0,0,4. After the deployment,0,,
169,51,2019J063,A Deep Generative Model for Graph Layout,"Kwon, Oh-Hyun and Ma, Kwan-Liu",2019,2020,Layout;Training;Visualization;Task analysis;Data visualization;Machine learning;Data models;Graph;network;visualization;layout;machine learning;deep learning;neural network;generative model;autoencoder,"Different layouts can characterize different aspects of the same graph. Finding a â€œgoodâ€ layout of a graph is thus an important task for graph visualization. In practice, users often visualize a graph in multiple layouts by using different methods and varying parameter settings until they find a layout that best suits the purpose of the visualization. However, this trial-and-error process is often haphazard and time-consuming. To provide users with an intuitive way to navigate the layout design space, we present a technique to systematically visualize a graph in diverse layouts using deep generative models. We design an encoder-decoder architecture to learn a model from a collection of example layouts, where the encoder represents training examples in a latent space and the decoder produces layouts from the latent space. In particular, we train the model to construct a two-dimensional latent space for users to easily explore and generate various layouts. We demonstrate our approach through quantitative and qualitative evaluations of the generated layouts. The results of our evaluations show that our model is capable of learning and generalizing abstract concepts of graph layouts, not just memorizing the training examples. In summary, this paper presents a fundamentally new approach to graph visualization where a machine learning model learns to visualize a graph from examples without manually-defined heuristics.",10.1109/TVCG.2019.2934396,,TRUE,TRUE,TRUE,T,,F,C2,DROP,0,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
233,337,2019J065,Interactive Structure-aware Blending of Diverse Edge Bundling Visualizations,"Wang, Yunhai and Xue, Mingliang and Wang, Yanyan and Yan, Xinyuan and Chen, Baoquan and Fu, Chi-Wing and Hurter, Christophe",2019,2020,Layout;Data visualization;Visualization;Task analysis;Strain;Smoothing methods;Optimization;path visualization;trajectory visualization;edge bundles,"Many edge bundling techniques (i.e., data simplification as a support for data visualization and decision making) exist but they are not directly applicable to any kind of dataset and their parameters are often too abstract and difficult to set up. As a result, this hinders the user ability to create efficient aggregated visualizations. To address these issues, we investigated a novel way of handling visual aggregation with a task-driven and user-centered approach. Given a graph, our approach produces a decluttered view as follows: first, the user investigates different edge bundling results and specifies areas, where certain edge bundling techniques would provide user-desired results. Second, our system then computes a smooth and structural preserving transition between these specified areas. Lastly, the user can further fine-tune the global visualization with a direct manipulation technique to remove the local ambiguity and to apply different visual deformations. In this paper, we provide details for our design rationale and implementation. Also, we show how our algorithm gives more suitable results compared to current edge bundling techniques, and in the end, we provide concrete instances of usages, where the algorithm combines various edge bundling results to support diverse data exploration and visualizations.",10.1109/TVCG.2019.2934805,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
240,338,2019J075,SmartCube: An Adaptive Data Management Architecture for the Real-Time Visualization of Spatiotemporal Datasets,"Liu, Can and Wu, Cong and Shao, Hanning and Yuan, Xiaoru",2019,2020,Data visualization;Data structures;Spatiotemporal phenomena;Memory management;Task analysis;Real-time systems;Data aggregation;data management;spatial-temporal data,"Interactive visualization and exploration of large spatiotemporal data sets is difficult without carefully-designed data preprocessing and management tools. We propose a novel architecture for spatiotemporal data management. The architecture can dynamically update itself based on user queries. Datasets is stored in a tree-like structure to support memory sharing among cuboids in a logical structure of data cubes. An update mechanism is designed to create or remove cuboids on it, according to the analysis of the user queries, with the consideration of memory size limitation. Data structure is dynamically optimized according to different user queries. During a query process, user queries are recorded to predict the performance increment of the new cuboid. The creation or deletion of a cuboid is determined by performance increment. Experiment results show that our prototype system deliveries good performance towards user queries on different spatiotemporal datasets, which costing small memory size with comparable performance compared with other state-of-the-art algorithms.",10.1109/TVCG.2019.2934434,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
170,52,2019J076,AirVis: Visual Analytics of Air Pollution Propagation,"Deng, Zikun and Weng, Di and Chen, Jiahui and Liu, Ren and Wang, Zhibin and Bao, Jie and Zheng, Yu and Wu, Yingcai",2019,2020,Air pollution;Data visualization;Data mining;Atmospheric modeling;Transportation;Spatiotemporal phenomena;Air pollution propagation;pattern mining;graph visualization,"Air pollution has become a serious public health problem for many cities around the world. To find the causes of air pollution, the propagation processes of air pollutants must be studied at a large spatial scale. However, the complex and dynamic wind fields lead to highly uncertain pollutant transportation. The state-of-the-art data mining approaches cannot fully support the extensive analysis of such uncertain spatiotemporal propagation processes across multiple districts without the integration of domain knowledge. The limitation of these automated approaches motivates us to design and develop AirVis, a novel visual analytics system that assists domain experts in efficiently capturing and interpreting the uncertain propagation patterns of air pollution based on graph visualizations. Designing such a system poses three challenges: a) the extraction of propagation patterns; b) the scalability of pattern presentations; and c) the analysis of propagation processes. To address these challenges, we develop a novel pattern mining framework to model pollutant transportation and extract frequent propagation patterns efficiently from large-scale atmospheric data. Furthermore, we organize the extracted patterns hierarchically based on the minimum description length (MDL) principle and empower expert users to explore and analyze these patterns effectively on the basis of pattern topologies. We demonstrated the effectiveness of our approach through two case studies conducted with a real-world dataset and positive feedback from domain experts.",10.1109/TVCG.2019.2934670,,TRUE,TRUE,TRUE,,T,F,C2,KEEP,1,9. Geosciences and geospatial data,,Environmental Data,0,1,1,1,1,1,1,1,0,0,0,1,3,1. domain expert,3,,,1,1,0,0,0,1,0,0,1,0,1,0,0,0,1,0,1,1,0,1,1,0,0,0,1,0,4. After the deployment,0,,
171,53,2019J080,Multiscale Visual Drilldown for the Analysis of Large Ensembles of Multi-Body Protein Complexes,"FurmanovÃ¡, KatarÃ­na and JurÄÃ­k, Adam and KozlÃ­kovÃ¡, Barbora and Hauser, Helwig and ByÅ¡ka, Jan",2019,2020,Proteins;Tools;Visualization;Amino acids;Proteomics;Task analysis;Space exploration;Molecular visualization;data filtering;coordinated and multiple views,"When studying multi-body protein complexes, biochemists use computational tools that can suggest hundreds or thousands of their possible spatial configurations. However, it is not feasible to experimentally verify more than only a very small subset of them. In this paper, we propose a novel multiscale visual drilldown approach that was designed in tight collaboration with proteomic experts, enabling a systematic exploration of the configuration space. Our approach takes advantage of the hierarchical structure of the data - from the whole ensemble of protein complex configurations to the individual configurations, their contact interfaces, and the interacting amino acids. Our new solution is based on interactively linked 2D and 3D views for individual hierarchy levels. At each level, we offer a set of selection and filtering operations that enable the user to narrow down the number of configurations that need to be manually scrutinized. Furthermore, we offer a dedicated filter interface, which provides the users with an overview of the applied filtering operations and enables them to examine their impact on the explored ensemble. This way, we maintain the history of the exploration process and thus enable the user to return to an earlier point of the exploration. We demonstrate the effectiveness of our approach on two case studies conducted by collaborating proteomic experts.",10.1109/TVCG.2019.2934333,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,2. Biology and life sciences,,biochemical sciences,0,1,1,0,1,1,1,1,0,0,0,1,2,1. domain expert,2,,,0,0,0,0,0,1,0,0,1,0,1,0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,4. After the deployment,0,,
241,339,2019J082,"Ablate, Variate, and Contemplate: Visual Analytics for Discovering Neural Architectures","Cashman, Dylan and Perer, Adam and Chang, Remco and Strobelt, Hendrik",2019,2020,Neural networks;Computer architecture;Tools;Training;Visual analytics;Machine learning;visual analytics;neural networks;parameter space exploration,"The performance of deep learning models is dependent on the precise configuration of many layers and parameters. However, there are currently few systematic guidelines for how to configure a successful model. This means model builders often have to experiment with different configurations by manually programming different architectures (which is tedious and time consuming) or rely on purely automated approaches to generate and train the architectures (which is expensive). In this paper, we present Rapid Exploration of Model Architectures and Parameters, or REMAP, a visual analytics tool that allows a model builder to discover a deep learning model quickly via exploration and rapid experimentation of neural network architectures. In REMAP, the user explores the large and complex parameter space for neural network architectures using a combination of global inspection and local experimentation. Through a visual overview of a set of models, the user identifies interesting clusters of architectures. Based on their findings, the user can run ablation and variation experiments to identify the effects of adding, removing, or replacing layers in a given architecture and generate new models accordingly. They can also handcraft new models using a simple graphical interface. As a result, a model builder can build deep learning models quickly, efficiently, and without manual programming. We inform the design of REMAP through a design study with four deep learning model builders. Through a use case, we demonstrate that REMAP allows users to discover performant neural network architectures efficiently using visual exploration and user-defined semi-automated searches through the model space.",10.1109/TVCG.2019.2934261,,TRUE,TRUE,FALSE,,,T,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
176,54,2019J083,VASSL: A Visual Analytics Toolkit for Social Spambot Labeling,"Khayat, Mosab and Karimzadeh, Morteza and Zhao, Jieqiong and Ebert, David S.",2019,2020,Labeling;Social networking (online);Visual analytics;Feature extraction;Tools;Manuals;Spambot;Labeling;Detection;Visual Analytics;Social Media Annotation,"Social media platforms are filled with social spambots. Detecting these malicious accounts is essential, yet challenging, as they continually evolve to evade detection techniques. In this article, we present VASSL, a visual analytics system that assists in the process of detecting and labeling spambots. Our tool enhances the performance and scalability of manual labeling by providing multiple connected views and utilizing dimensionality reduction, sentiment analysis and topic modeling, enabling insights for the identification of spambots. The system allows users to select and analyze groups of accounts in an interactive manner, which enables the detection of spambots that may not be identified when examined individually. We present a user study to objectively evaluate the performance of VASSL users, as well as capturing subjective opinions about the usefulness and the ease of use of the tool.",10.1109/TVCG.2019.2934266,,TRUE,TRUE,TRUE,T,T,F,C1,KEEP,1,12. Journalism and media,,social media,0,1,1,1,1,0,1,1,0,0,0,1,12,3. general public,12,,,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,1,0,1,0,0,4. After the deployment,0,,
183,55,2019J084,Visual Interaction with Deep Learning Models through Collaborative Semantic Inference,"Gehrmann, Sebastian and Strobelt, Hendrik and KrÃ¼ger, Robert and Pfister, Hanspeter and Rush, Alexander M.",2019,2020,Visualization;Collaboration;Semantics;Tools;Analytical models;Cognition;Predictive models;Human-Computer Collaboration;Deep Learning;Neural Networks;Interaction Design;Human-Centered Design,"Automation of tasks can have critical consequences when humans lose agency over decision processes. Deep learning models are particularly susceptible since current black-box approaches lack explainable reasoning. We argue that both the visual interface and model structure of deep learning systems need to take into account interaction design. We propose a framework of collaborative semantic inference (CSI) for the co-design of interactions and models to enable visual collaboration between humans and algorithms. The approach exposes the intermediate reasoning process of models which allows semantic interactions with the visual metaphors of a problem, which means that a user can both understand and control parts of the model reasoning process. We demonstrate the feasibility of CSI with a co-designed case study of a document summarization system.",10.1109/TVCG.2019.2934595,,TRUE,TRUE,TRUE,,T,F,C1,DROP-design study,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
193,56,2019J085,DataShot: Automatic Generation of Fact Sheets from Tabular Data,"Wang, Yun and Sun, Zhida and Zhang, Haidong and Cui, Weiwei and Xu, Ke and Ma, Xiaojuan and Zhang, Dongmei",2019,2020,Data visualization;Visualization;Data mining;Statistical analysis;Computer graphics;Data analysis;Fact sheet;infographic;visualization;and automated design,"Fact sheets with vivid graphical design and intriguing statistical insights are prevalent for presenting raw data. They help audiences understand data-related facts effectively and make a deep impression. However, designing a fact sheet requires both data and design expertise and is a laborious and time-consuming process. One needs to not only understand the data in depth but also produce intricate graphical representations. To assist in the design process, we present DataShot which, to the best of our knowledge, is the first automated system that creates fact sheets automatically from tabular data. First, we conduct a qualitative analysis of 245 infographic examples to explore general infographic design space at both the sheet and element levels. We identify common infographic structures, sheet layouts, fact types, and visualization styles during the study. Based on these findings, we propose a fact sheet generation pipeline, consisting of fact extraction, fact composition, and presentation synthesis, for the auto-generation workflow. To validate our system, we present use cases with three real-world datasets. We conduct an in-lab user study to understand the usage of our system. Our evaluation results show that DataShot can efficiently generate satisfactory fact sheets to support further customization and data presentation.",10.1109/TVCG.2019.2934398,,TRUE,TRUE,TRUE,T,T,F,C1,KEEP,1,,,visualization,1,1,1,1,1,0,1,1,0,0,0,2,10,5. no participant,0,,,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4. After the deployment,0,,
,,2019J085,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,3. general public,10,,,0,0,1,0,0,1,0,0,0,0,1,0,0,1,0,1,0,1,0,0,0,0,0,0,0,0,4. After the deployment,0,,
195,57,2019J086,Text-to-Viz: Automatic Generation of Infographics from Proportion-Related Natural Language Statements,"Cui, Weiwei and Zhang, Xiaoyu and Wang, Yun and Huang, He and Chen, Bei and Fang, Lei and Zhang, Haidong and Lou, Jian-Guan and Zhang, Dongmei",2019,2020,Data visualization;Visualization;Tools;Sports;Authoring systems;Natural languages;Social networking (online);Visualization for the masses;infographic;automatic visualization;presentation;and dissemination,"Combining data content with visual embellishments, infographics can effectively deliver messages in an engaging and memorable manner. Various authoring tools have been proposed to facilitate the creation of infographics. However, creating a professional infographic with these authoring tools is still not an easy task, requiring much time and design expertise. Therefore, these tools are generally not attractive to casual users, who are either unwilling to take time to learn the tools or lacking in proper design expertise to create a professional infographic. In this paper, we explore an alternative approach: to automatically generate infographics from natural language statements. We first conducted a preliminary study to explore the design space of infographics. Based on the preliminary study, we built a proof-of-concept system that automatically converts statements about simple proportion-related statistics to a set of infographics with pre-designed styles. Finally, we demonstrated the usability and usefulness of the system through sample results, exhibits, and expert reviews.",10.1109/TVCG.2019.2934785,,TRUE,TRUE,TRUE,,T,F,C1,DROP,0,,,,1,1,1,1,0,0,1,1,0,1,0,,83,3. general public,80,,,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,4. After the deployment,0,,
,,2019J086,,,,,,,,,,,,,,,,,0,,,,,,,,,,,,,,,,,5. no participant,0,,,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4. After the deployment,0,,
,,2019J086,,,,,,,,,,,,,,,,,0,,,,,,,,,,,,,,,,,1. domain expert,3,,,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,4. After the deployment,0,,
200,58,2019J088,EmoCo: Visual Analysis of Emotion Coherence in Presentation Videos,"Zeng, Haipeng and Wang, Xingbo and Wu, Aoyu and Wang, Yong and Li, Quan and Endert, Alex and Qu, Huamin",2019,2020,Coherence;Videos;Feature extraction;Visual analytics;Emotion recognition;Face;Emotion;coherence;video analysis;visual analysis,"Emotions play a key role in human communication and public presentations. Human emotions are usually expressed through multiple modalities. Therefore, exploring multimodal emotions and their coherence is of great value for understanding emotional expressions in presentations and improving presentation skills. However, manually watching and studying presentation videos is often tedious and time-consuming. There is a lack of tool support to help conduct an efficient and in-depth multi-level analysis. Thus, in this paper, we introduce EmoCo, an interactive visual analytics system to facilitate efficient analysis of emotion coherence across facial, text, and audio modalities in presentation videos. Our visualization system features a channel coherence view and a sentence clustering view that together enable users to obtain a quick overview of emotion coherence and its temporal evolution. In addition, a detail view and word view enable detailed exploration and comparison from the sentence level and word level, respectively. We thoroughly evaluate the proposed system and visualization techniques through two usage scenarios based on TED Talk videos and interviews with two domain experts. The results demonstrate the effectiveness of our system in gaining insights into emotion coherence in presentations.",10.1109/TVCG.2019.2934656,,TRUE,TRUE,TRUE,T,T,F,C1,KEEP,1,12. Journalism and media,,,0,1,1,1,1,1,1,1,0,0,0,2,4,1. domain expert,2,,,0,0,0,0,0,1,0,0,0,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,4. After the deployment,0,,
,,2019J088,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,2. domain user,2,,,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,4. After the deployment,0,,
201,59,2019J089,CerebroVis: Designing an Abstract yet Spatially Contextualized Cerebral Artery Network Visualization,"Pandey, Aditeya and Shukla, Harsh and Young, Geoffrey S. and Qin, Lei and Zamani, Amir A. and Hsu, Liangge and Huang, Raymond and Dunne, Cody and Borkin, Michelle A.",2019,2020,Arteries;Blood;Visualization;Three-dimensional displays;Two dimensional displays;Task analysis;Imaging;Network Visualization;Spatial Context;Abstract Design;Flow Network;Medical Imaging;Cerebral Arteries,"Blood circulation in the human brain is supplied through a network of cerebral arteries. If a clinician suspects a patient has a stroke or other cerebrovascular condition, they order imaging tests. Neuroradiologists visually search the resulting scans for abnormalities. Their visual search tasks correspond to the abstract network analysis tasks of browsing and path following. To assist neuroradiologists in identifying cerebral artery abnormalities, we designed CerebroVis, a novel abstract-yet spatially contextualized-cerebral artery network visualization. In this design study, we contribute a novel framing and definition of the cerebral artery system in terms of network theory and characterize neuroradiologist domain goals as abstract visualization and network analysis tasks. Through an iterative, user-centered design process we developed an abstract network layout technique which incorporates cerebral artery spatial context. The abstract visualization enables increased domain task performance over 3D geometry representations, while including spatial context helps preserve the user's mental map of the underlying geometry. We provide open source implementations of our network layout technique and prototype cerebral artery visualization tool. We demonstrate the robustness of our technique by successfully laying out 61 open source brain scans. We evaluate the effectiveness of our layout through a mixed methods study with three neuroradiologists. In a formative controlled experiment our study participants used CerebroVis and a conventional 3D visualization to examine real cerebral artery imaging data to identify a simulated intracranial artery stenosis. Participants were more accurate at identifying stenoses using CerebroVis (absolute risk difference 13%). A free copy of this paper, the evaluation stimuli and data, and source code are available at osf.io/e5sxt.",10.1109/TVCG.2019.2934402,,TRUE,TRUE,TRUE,T,,T,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
202,60,2019J093,Motion Browser: Visualizing and Understanding Complex Upper Limb Movement Under Obstetrical Brachial Plexus Injuries,"Chan, Gromit Yeuk-Yin and Nonato, Luis Gustavo and Chu, Alice and Raghavan, Preeti and Aluru, Viswanath and Silva, ClÃ¡udio T.",2019,2020,Muscles;Data visualization;Brachytherapy;Time series analysis;Task analysis;Visual analytics;Medical Data Visualization;Visual Analytics Application;Time Series Data;Multimodal Data;Brachial Plexus Injuries,"The brachial plexus is a complex network of peripheral nerves that enables sensing from and control of the movements of the arms and hand. Nowadays, the coordination between the muscles to generate simple movements is still not well understood, hindering the knowledge of how to best treat patients with this type of peripheral nerve injury. To acquire enough information for medical data analysis, physicians conduct motion analysis assessments with patients to produce a rich dataset of electromyographic signals from multiple muscles recorded with joint movements during real-world tasks. However, tools for the analysis and visualization of the data in a succinct and interpretable manner are currently not available. Without the ability to integrate, compare, and compute multiple data sources in one platform, physicians can only compute simple statistical values to describe patient's behavior vaguely, which limits the possibility to answer clinical questions and generate hypotheses for research. To address this challenge, we have developed MOTION BROWSER, an interactive visual analytics system which provides an efficient framework to extract and compare muscle activity patterns from the patient's limbs and coordinated views to help users analyze muscle signals, motion data, and video information to address different tasks. The system was developed as a result of a collaborative endeavor between computer scientists and orthopedic surgery and rehabilitation physicians. We present case studies showing physicians can utilize the information displayed to understand how individuals coordinate their muscles to initiate appropriate treatment and generate new hypotheses for future research.",10.1109/TVCG.2019.2934280,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,10. Healthcare and medical imaging,,"medical, healthcare",0,1,1,0,1,1,1,1,0,0,0,1,1,1. domain expert,1,,,0,1,0,0,0,1,0,0,0,0,1,0,0,0,1,0,1,1,0,1,1,0,0,0,0,0,4. After the deployment,0,,
203,61,2019J095,Semantic Concept Spaces: Guided Topic Model Refinement using Word-Embedding Projections,"El-Assady, Mennatallah and Kehlbeck, Rebecca and Collins, Christopher and Keim, Daniel and Deussen, Oliver",2019,2020,Semantics;Analytical models;Computational modeling;Visual analytics;Machine learning;Task analysis;Topic Model Optimization;Word Embedding;Mixed-Initiative Refinement;Guided Visual Analytics;Semantic Mapping,"We present a framework that allows users to incorporate the semantics of their domain knowledge for topic model refinement while remaining model-agnostic. Our approach enables users to (1) understand the semantic space of the model, (2) identify regions of potential conflicts and problems, and (3) readjust the semantic relation of concepts based on their understanding, directly influencing the topic modeling. These tasks are supported by an interactive visual analytics workspace that uses word-embedding projections to define concept regions which can then be refined. The user-refined concepts are independent of a particular document collection and can be transferred to related corpora. All user interactions within the concept space directly affect the semantic relations of the underlying vector space model, which, in turn, change the topic modeling. In addition to direct manipulation, our system guides the users' decisionmaking process through recommended interactions that point out potential improvements. This targeted refinement aims at minimizing the feedback required for an efficient human-in-the-loop process. We confirm the improvements achieved through our approach in two user studies that show topic model quality improvements through our visual knowledge externalization and learning process.",10.1109/TVCG.2019.2934654,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,1. AI (Machine Learning/Deep Learning/Data Mining),,,0,1,1,1,1,0,1,1,1,0,0,1,6,1. domain expert,6,,,0,1,1,0,0,1,0,0,0,0,1,0,0,1,1,0,1,1,0,0,0,1,0,0,0,0,4. After the deployment,0,,
204,62,2019J098,A Comparison of Radial and Linear Charts for Visualizing Daily Patterns,"Waldner, Manuela and Diehl, Alexandra and GraÄanin, Denis and Splechtna, Rainer and Delrieux, Claudio and MatkoviÄ‡, KreÅ¡imir",2019,2020,Bars;Data visualization;Layout;Clocks;Task analysis;Time series analysis;Encoding;Radial charts;time series series data;daily patterns;crowd-sourced experiment,"Radial charts are generally considered less effective than linear charts. Perhaps the only exception is in visualizing periodical time-dependent data, which is believed to be naturally supported by the radial layout. It has been demonstrated that the drawbacks of radial charts outweigh the benefits of this natural mapping. Visualization of daily patterns, as a special case, has not been systematically evaluated using radial charts. In contrast to yearly or weekly recurrent trends, the analysis of daily patterns on a radial chart may benefit from our trained skill on reading radial clocks that are ubiquitous in our culture. In a crowd-sourced experiment with 92 non-expert users, we evaluated the accuracy, efficiency, and subjective ratings of radial and linear charts for visualizing daily traffic accident patterns. We systematically compared juxtaposed 12-hours variants and single 24-hours variants for both layouts in four low-level tasks and one high-level interpretation task. Our results show that over all tasks, the most elementary 24-hours linear bar chart is most accurate and efficient and is also preferred by the users. This provides strong evidence for the use of linear layouts - even for visualizing periodical daily patterns.",10.1109/TVCG.2019.2934784,,TRUE,TRUE,TRUE,T,,F,C1,DROP-empirical study,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
205,63,2019J101,explAIner: A Visual Analytics Framework for Interactive and Explainable Machine Learning,"Spinner, Thilo and Schlegel, Udo and SchÃ¤fer, Hanna and El-Assady, Mennatallah",2019,2020,Data models;Analytical models;Computational modeling;Pipelines;Machine learning;Monitoring;Explainable AI;Interactive Machine Learning;Deep Learning;Visual Analytics;Interpretability;Explainability,"We propose a framework for interactive and explainable machine learning that enables users to (1) understand machine learning models; (2) diagnose model limitations using different explainable AI methods; as well as (3) refine and optimize the models. Our framework combines an iterative XAI pipeline with eight global monitoring and steering mechanisms, including quality monitoring, provenance tracking, model comparison, and trust building. To operationalize the framework, we present explAIner, a visual analytics system for interactive and explainable machine learning that instantiates all phases of the suggested pipeline within the commonly used TensorBoard environment. We performed a user-study with nine participants across different expertise levels to examine their perception of our workflow and to collect suggestions to fill the gap between our system and framework. The evaluation confirms that our tightly integrated system leads to an informed machine learning process while disclosing opportunities for further extensions.",10.1109/TVCG.2019.2934629,,TRUE,TRUE,TRUE,T,,F,C1,KEEP,1,1. AI (Machine Learning/Deep Learning/Data Mining),,xai,0,1,1,1,1,0,1,1,1,0,0,1,9,2. domain user,9,,,1,1,0,0,0,1,0,0,0,0,0,0,0,1,1,0,1,1,0,0,0,0,0,0,0,0,4. After the deployment,0,,
207,64,2019J102,Explaining Vulnerabilities to Adversarial Machine Learning through Visual Analytics,"Ma, Yuxin and Xie, Tiankai and Li, Jundong and Maciejewski, Ross",2019,2020,Analytical models;Machine learning;Visual analytics;Training;Predictive models;Adversarial machine learning;data poisoning;visual analytics,"Machine learning models are currently being deployed in a variety of real-world applications where model predictions are used to make decisions about healthcare, bank loans, and numerous other critical tasks. As the deployment of artificial intelligence technologies becomes ubiquitous, it is unsurprising that adversaries have begun developing methods to manipulate machine learning models to their advantage. While the visual analytics community has developed methods for opening the black box of machine learning models, little work has focused on helping the user understand their model vulnerabilities in the context of adversarial attacks. In this paper, we present a visual analytics framework for explaining and exploring model vulnerabilities to adversarial attacks. Our framework employs a multi-faceted visualization scheme designed to support the analysis of data poisoning attacks from the perspective of models, data instances, features, and local structures. We demonstrate our framework through two case studies on binary classifiers and illustrate model vulnerabilities with respect to varying attack strategies.",10.1109/TVCG.2019.2934631,,TRUE,TRUE,TRUE,,T,F,C2,KEEP,1,1. AI (Machine Learning/Deep Learning/Data Mining),,Machine Learning,0,1,1,1,1,1,1,1,1,0,0,1,4,1. domain expert,4,,,1,1,0,0,0,1,0,0,1,0,0,0,0,0,1,0,0,1,0,0,1,0,0,0,0,0,4. After the deployment,0,,
208,65,2019J103,FairSight: Visual Analytics for Fairness in Decision Making,"Ahn, Yongsu and Lin, Yu-Ru",2019,2020,Decision making;Machine learning;Tools;Pipelines;Visual analytics;Machine learning algorithms;Task analysis;Fairness in Machine Learning;Visual Analytic,"Data-driven decision making related to individuals has become increasingly pervasive, but the issue concerning the potential discrimination has been raised by recent studies. In response, researchers have made efforts to propose and implement fairness measures and algorithms, but those efforts have not been translated to the real-world practice of data-driven decision making. As such, there is still an urgent need to create a viable tool to facilitate fair decision making. We propose FairSight, a visual analytic system to address this need; it is designed to achieve different notions of fairness in ranking decisions through identifying the required actions - understanding, measuring, diagnosing and mitigating biases - that together lead to fairer decision making. Through a case study and user study, we demonstrate that the proposed visual analytic and diagnostic modules in the system are effective in understanding the fairness-aware decision pipeline and obtaining more fair outcomes.",10.1109/TVCG.2019.2934262,,TRUE,TRUE,TRUE,,T,F,C2,KEEP,1,1. AI (Machine Learning/Deep Learning/Data Mining),,Machine Learning,0,1,1,1,1,0,1,1,1,0,0,1,20,2. domain user,20,,,0,1,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,1,0,0,1,0,4. After the deployment,0,,
209,66,2019J104,Summit: Scaling Deep Learning Interpretability by Visualizing Activation and Attribution Summarizations,"Hohman, Fred and Park, Haekyu and Robinson, Caleb and Polo Chau, Duen Horng",2019,2020,Neurons;Biological neural networks;Feature extraction;Data visualization;Computational modeling;Predictive models;Visualization;Deep learning interpretability;visual analytics;scalable summarization;attribution graph,"Deep learning is increasingly used in decision-making tasks. However, understanding how neural networks produce final predictions remains a fundamental challenge. Existing work on interpreting neural network predictions for images often focuses on explaining predictions for single images or neurons. As predictions are often computed from millions of weights that are optimized over millions of images, such explanations can easily miss a bigger picture. We present Summit, an interactive system that scalably and systematically summarizes and visualizes what features a deep learning model has learned and how those features interact to make predictions. Summit introduces two new scalable summarization techniques: (1) activation aggregation discovers important neurons, and (2) neuron-influence aggregation identifies relationships among such neurons. Summit combines these techniques to create the novel attribution graph that reveals and summarizes crucial neuron associations and substructures that contribute to a model's outcomes. Summit scales to large data, such as the ImageNet dataset with 1.2M images, and leverages neural network feature visualization and dataset examples to help users distill large, complex neural network models into compact, interactive visualizations. We present neural network exploration scenarios where Summit helps us discover multiple surprising insights into a prevalent, large-scale image classifier's learned representations and informs future neural network architecture design. The Summit visualization runs in modern web browsers and is open-sourced.",10.1109/TVCG.2019.2934659,,TRUE,TRUE,TRUE,,T,F,C2,DROP-no detailed evaluation only scenarios,0,1. AI (Machine Learning/Deep Learning/Data Mining),,Machine Learning,0,1,1,0,1,0,1,1,1,0,0,,0,5. no participant,0,,,,,,,,,,,,,,,,,,,,,,,1,,,,,,4. After the deployment,0,,
210,67,2019J105,CloudDet: Interactive Visual Analysis of Anomalous Performances in Cloud Computing Systems,"Xu, Ke and Wang, Yun and Yang, Leni and Wang, Yifang and Qiao, Bo and Qin, Si and Xu, Yong and Zhang, Haidong and Qu, Huamin",2019,2020,Cloud computing;Data visualization;Anomaly detection;Measurement;Time series analysis;Visualization;Principal component analysis;Cloud computing;anomaly detection;multidimensional data;performance visualization;visual analytics,"Detecting and analyzing potential anomalous performances in cloud computing systems is essential for avoiding losses to customers and ensuring the efficient operation of the systems. To this end, a variety of automated techniques have been developed to identify anomalies in cloud computing. These techniques are usually adopted to track the performance metrics of the system (e.g., CPU, memory, and disk I/O), represented by a multivariate time series. However, given the complex characteristics of cloud computing data, the effectiveness of these automated methods is affected. Thus, substantial human judgment on the automated analysis results is required for anomaly interpretation. In this paper, we present a unified visual analytics system named CloudDet to interactively detect, inspect, and diagnose anomalies in cloud computing systems. A novel unsupervised anomaly detection algorithm is developed to identify anomalies based on the specific temporal patterns of the given metrics data (e.g., the periodic pattern). Rich visualization and interaction designs are used to help understand the anomalies in the spatial and temporal context. We demonstrate the effectiveness of CloudDet through a quantitative evaluation, two case studies with real-world data, and interviews with domain experts.",10.1109/TVCG.2019.2934613,,TRUE,TRUE,TRUE,T,T,F,C2,KEEP,1,4. Computer networks and security,,Cloud Computing,0,1,1,1,1,1,1,1,0,0,0,1,2,1. domain expert,2,,,0,1,0,0,0,1,1,0,1,0,1,0,0,0,1,0,1,1,0,1,1,1,0,1,0,0,4. After the deployment,0,,
251,340,2019J106,Visualizing a Moving Target: A Design Study on Task Parallel Programs in the Presence of Evolving Data and Concerns,"Williams, Katy and Bigelow, Alex and Isaacs, Kate",2019,2020,Task analysis;Data visualization;Computational modeling;Runtime;Tools;Parallel processing;Data collection;design studies;software visualization;parallel computing;graph visualization,"Common pitfalls in visualization projects include lack of data availability and the domain users' needs and focus changing too rapidly for the design process to complete. While it is often prudent to avoid such projects, we argue it can be beneficial to engage them in some cases as the visualization process can help refine data collection, solving a â€œchicken and eggâ€ problem of having the data and tools to analyze it. We found this to be the case in the domain of task parallel computing where such data and tooling is an open area of research. Despite these hurdles, we conducted a design study. Through a tightly-coupled iterative design process, we built Atria, a multi-view execution graph visualization to support performance analysis. Atria simplifies the initial representation of the execution graph by aggregating nodes as related to their line of code. We deployed Atria on multiple platforms, some requiring design alteration. We describe how we adapted the design study methodology to the â€œmoving targetâ€ of both the data and the domain experts' concerns and how this movement kept both the visualization and programming project healthy. We reflect on our process and discuss what factors allow the project to be successful in the presence of changing data and user needs.",10.1109/TVCG.2019.2934285,,TRUE,TRUE,FALSE,,,T,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
217,68,2019J107,Exploranative Code Quality Documents,"Mumtaz, Haris and Latif, Shahid and Beck, Fabian and Weiskopf, Daniel",2019,2020,Data visualization;Visual analytics;Software;Software metrics;Software engineering;Code quality;interactive documents;natural language generation;sparklines,"Good code quality is a prerequisite for efficiently developing maintainable software. In this paper, we present a novel approach to generate exploranative (explanatory and exploratory) data-driven documents that report code quality in an interactive, exploratory environment. We employ a template-based natural language generation method to create textual explanations about the code quality, dependent on data from software metrics. The interactive document is enriched by different kinds of visualization, including parallel coordinates plots and scatterplots for data exploration and graphics embedded into text. We devise an interaction model that allows users to explore code quality with consistent linking between text and visualizations; through integrated explanatory text, users are taught background knowledge about code quality aspects. Our approach to interactive documents was developed in a design study process that included software engineering and visual analytics experts. Although the solution is specific to the software engineering scenario, we discuss how the concept could generalize to multivariate data and report lessons learned in a broader scope.",10.1109/TVCG.2019.2934669,,TRUE,TRUE,TRUE,,T,T,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
218,69,2019J108,OntoPlot: A Novel Visualisation for Non-hierarchical Associations in Large Ontologies,"Yang, Ying and Wybrow, Michael and Li, Yuan-Fang and Czauderna, Tobias and He, Yongqun",2019,2020,Ontologies;Visualization;Drugs;Task analysis;Data visualization;Tools;Biology;Ontology visualisation;visual compression;interactive exploration;ontology associations,"Ontologies are formal representations of concepts and complex relationships among them. They have been widely used to capture comprehensive domain knowledge in areas such as biology and medicine, where large and complex ontologies can contain hundreds of thousands of concepts. Especially due to the large size of ontologies, visualisation is useful for authoring, exploring and understanding their underlying data. Existing ontology visualisation tools generally focus on the hierarchical structure, giving much less emphasis to non-hierarchical associations. In this paper we present OntoPlot, a novel visualisation specifically designed to facilitate the exploration of all concept associations whilst still showing an ontology's large hierarchical structure. This hybrid visualisation combines icicle plots, visual compression techniques and interactivity, improving space-efficiency and reducing visual structural complexity. We conducted a user study with domain experts to evaluate the usability of OntoPlot, comparing it with the de facto ontology editor ProtÃ©gÃ©. The results confirm that OntoPlot attains our design goals for association-related tasks and is strongly favoured by domain experts.",10.1109/TVCG.2019.2934557,,TRUE,TRUE,TRUE,T,T,F,C2,KEEP,1,2. Biology and life sciences,,"Ontologies, Biomedical Data",0,1,1,1,1,1,1,1,0,0,0,2,32,1. domain expert,12,,,0,1,0,0,1,1,0,0,0,0,1,0,0,0,0,1,1,1,0,1,0,1,0,0,1,0,4. After the deployment,0,,
,,2019J108,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,3. general public,18,1. domain expert,2,0,1,0,0,1,1,0,0,0,0,1,0,0,0,0,1,1,1,0,1,0,1,0,0,1,0,4. After the deployment,0,,
262,341,2019J109,P5: Portable Progressive Parallel Processing Pipelines for Interactive Data Analysis and Visualization,"Li, Jianping Kelvin and Ma, Kwan-Liu",2019,2020,Data visualization;Graphics processing units;Parallel processing;Data analysis;Grammar;Libraries;Big Data;Information visualization;progressive analytics;visualization software;GPU computing;data exploration,"We present P5, a web-based visualization toolkit that combines declarative visualization grammar and GPU computing for progressive data analysis and visualization. To interactively analyze and explore big data, progressive analytics and visualization methods have recently emerged. Progressive visualizations of incrementally refining results have the advantages of allowing users to steer the analysis process and make early decisions. P5 leverages declarative grammar for specifying visualization designs and exploits GPU computing to accelerate progressive data processing and rendering. The declarative specifications can be modified during progressive processing to create different visualizations for analyzing the intermediate results. To enable user interactions for progressive data analysis, P5 utilizes the GPU to automatically aggregate and index data based on declarative interaction specifications to facilitate effective interactive visualization. We demonstrate the effectiveness and usefulness of P5 through a variety of example applications and several performance benchmark tests.",10.1109/TVCG.2019.2934537,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
264,342,2019J110,RSATree: Distribution-Aware Data Representation of Large-Scale Tabular Datasets for Flexible Visual Query,"Mei, Honghui and Chen, Wei and Wei, Yating and Hu, Yuanzhe and Zhou, Shuyue and Lin, Bingru and Zhao, Ying and Xia, Jiazhi",2019,2020,Visualization;Data visualization;Aggregates;Histograms;Time factors;Visual databases;Social networking (online);Aggregate query;visual query;large-scale data visualization;R-tree;summed area table;hashing,"Analysts commonly investigate the data distributions derived from statistical aggregations of data that are represented by charts, such as histograms and binned scatterplots, to visualize and analyze a large-scale dataset. Aggregate queries are implicitly executed through such a process. Datasets are constantly extremely large; thus, the response time should be accelerated by calculating predefined data cubes. However, the queries are limited to the predefined binning schema of preprocessed data cubes. Such limitation hinders analysts' flexible adjustment of visual specifications to investigate the implicit patterns in the data effectively. Particularly, RSATree enables arbitrary queries and flexible binning strategies by leveraging three schemes, namely, an R-tree-based space partitioning scheme to catch the data distribution, a locality-sensitive hashing technique to achieve locality-preserving random access to data items, and a summed area table scheme to support interactive query of aggregated values with a linear computational complexity. This study presents and implements a web-based visual query system that supports visual specification, query, and exploration of large-scale tabular data with user-adjustable granularities. We demonstrate the efficiency and utility of our approach by performing various experiments on real-world datasets and analyzing time and space complexity.",10.1109/TVCG.2019.2934800,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
219,70,2019J114,R-Map: A Map Metaphor for Visualizing Information Reposting Process in Social Media,"Chen, Shuai and Li, Sihang and Chen, Siming and Yuan, Xiaoru",2019,2020,Semantics;Visualization;Diffusion processes;Data visualization;Twitter;Lakes;Social Media;Information Diffusion;Map-like Visual Metaphor,"We propose R-Map (Reposting Map), a visual analytical approach with a map metaphor to support interactive exploration and analysis of the information reposting process in social media. A single original social media post can cause large cascades of repostings (i.e., retweets) on online networks, involving thousands, even millions of people with different opinions. Such reposting behaviors form the reposting tree, in which a node represents a message and a link represents the reposting relation. In R-Map, the reposting tree structure can be spatialized with highlighted key players and tiled nodes. The important reposting behaviors, the following relations and the semantics relations are represented as rivers, routes and bridges, respectively, in a virtual geographical space. R-Map supports a scalable overview of a large number of information repostings with semantics. Additional interactions on the map are provided to support the investigation of temporal patterns and user behaviors in the information diffusion process. We evaluate the usability and effectiveness of our system with two use cases and a formal user study.",10.1109/TVCG.2019.2934263,,TRUE,TRUE,TRUE,T,T,F,C2,KEEP,1,11. Humanities and social sciences,12. Journalism and media,Social Media,0,1,1,1,1,1,1,1,0,0,0,1,14,3. general public,14,,,0,1,1,0,1,1,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,1,0,4. After the deployment,0,,
221,71,2019J118,The Role of Latency and Task Complexity in Predicting Visual Search Behavior,"Battle, Leilani and Crouser, R. Jordan and Nakeshimana, Audace and Montoly, Ananda and Chang, Remco and Stonebraker, Michael",2019,2020,Task analysis;Complexity theory;Human computer interaction;Visualization;Data visualization;Delays;Visual search;latency;system response time;SRT,"Latency in a visualization system is widely believed to affect user behavior in measurable ways, such as requiring the user to wait for the visualization system to respond, leading to interruption of the analytic flow. While this effect is frequently observed and widely accepted, precisely how latency affects different analysis scenarios is less well understood. In this paper, we examine the role of latency in the context of visual search, an essential task in data foraging and exploration using visualization. We conduct a series of studies on Amazon Mechanical Turk and find that under certain conditions, latency is a statistically significant predictor of visual search behavior, which is consistent with previous studies. However, our results also suggest that task type, task complexity, and other factors can modulate the effect of latency, in some cases rendering latency statistically insignificant in predicting user behavior. This suggests a more nuanced view of the role of latency than previously reported. Building on these results and the findings of prior studies, we propose design guidelines for measuring and interpreting the effects of latency when evaluating performance on visual search tasks.",10.1109/TVCG.2019.2934556,,TRUE,TRUE,TRUE,,T,F,C2,DROP,0,,,,,,,,0,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
223,72,2019J119,A Natural-language-based Visual Query Approach of Uncertain Human Trajectories,"Huang, Zhaosong and Zhao, Ye and Chen, Wei and Gao, Shengjie and Yu, Kejie and Xu, Weixia and Tang, Mingjie and Zhu, Minfeng and Xu, Mingliang",2019,2020,Trajectory;Semantics;Visualization;Natural languages;Indexing;Spatiotemporal phenomena;Engines;Natural-language-based Visual Query;Spatial Uncertaity;Trajectory Exploration,"Visual querying is essential for interactively exploring massive trajectory data. However, the data uncertainty imposes profound challenges to fulfill advanced analytics requirements. On the one hand, many underlying data does not contain accurate geographic coordinates, e.g., positions of a mobile phone only refer to the regions (i.e., mobile cell stations) in which it resides, instead of accurate GPS coordinates. On the other hand, domain experts and general users prefer a natural way, such as using a natural language sentence, to access and analyze massive movement data. In this paper, we propose a visual analytics approach that can extract spatial-temporal constraints from a textual sentence and support an effective query method over uncertain mobile trajectory data. It is built up on encoding massive, spatially uncertain trajectories by the semantic information of the POIs and regions covered by them, and then storing the trajectory documents in text database with an effective indexing scheme. The visual interface facilitates query condition specification, situation-aware visualization, and semantic exploration of large trajectory data. Usage scenarios on real-world human mobility datasets demonstrate the effectiveness of our approach.",10.1109/TVCG.2019.2934671,,TRUE,TRUE,TRUE,,T,F,C2,DROP,0,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
224,73,2019J120,You can't always sketch what you want: Understanding Sensemaking in Visual Query Systems,"Lee, Doris Jung-Lin and Lee, John and Siddiqui, Tarique and Kim, Jaewoo and Karahalios, Karrie and Parameswaran, Aditya",2019,2020,Visualization;Data visualization;Interviews;User centered design;Taxonomy;Buildings;Pattern matching;Visual analytics;exploratory analysis;visual queries,"Visual query systems (VQSs) empower users to interactively search for line charts with desired visual patterns, typically specified using intuitive sketch-based interfaces. Despite decades of past work on VQSs, these efforts have not translated to adoption in practice, possibly because VQSs are largely evaluated in unrealistic lab-based settings. To remedy this gap in adoption, we collaborated with experts from three diverse domains-astronomy, genetics, and material science-via a year-long user-centered design process to develop a VQS that supports their workflow and analytical needs, and evaluate how VQSs can be used in practice. Our study results reveal that ad-hoc sketch-only querying is not as commonly used as prior work suggests, since analysts are often unable to precisely express their patterns of interest. In addition, we characterize three essential sensemaking processes supported by our enhanced VQS. We discover that participants employ all three processes, but in different proportions, depending on the analytical needs in each domain. Our findings suggest that all three sensemaking processes must be integrated in order to make future VQSs useful for a wide range of analytical inquiries.",10.1109/TVCG.2019.2934666,,TRUE,TRUE,TRUE,T,,F,C2,DROP,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
225,74,2020J004,PlotThread: Creating Expressive Storyline Visualizations using Reinforcement Learning,"Tang, Tan and Li, Renzhong and Wu, Xinke and Liu, Shuhan and Knittel, Johannes and Koch, Steffen and Ertl, Thomas and Yu, Lingyun and Ren, Peiran and Wu, Yingcai",2020,2021,Layout;Visualization;Reinforcement learning;Collaboration;Task analysis;Optimization;Storyline visualization;reinforcement learning;mixed-initiative design,"Storyline visualizations are an effective means to present the evolution of plots and reveal the scenic interactions among characters. However, the design of storyline visualizations is a difficult task as users need to balance between aesthetic goals and narrative constraints. Despite that the optimization-based methods have been improved significantly in terms of producing aesthetic and legible layouts, the existing (semi-) automatic methods are still limited regarding 1) efficient exploration of the storyline design space and 2) flexible customization of storyline layouts. In this work, we propose a reinforcement learning framework to train an AI agent that assists users in exploring the design space efficiently and generating well-optimized storylines. Based on the framework, we introduce PlotThread, an authoring tool that integrates a set of flexible interactions to support easy customization of storyline visualizations. To seamlessly integrate the AI agent into the authoring process, we employ a mixed-initiative approach where both the agent and designers work on the same canvas to boost the collaborative design of storylines. We evaluate the reinforcement learning model through qualitative and quantitative experiments and demonstrate the usage of PlotThread using a collection of use cases.",10.1109/TVCG.2020.3030467,,TRUE,TRUE,TRUE,T,,F,C1,KEEP,1,12. Journalism and media,,,0,1,1,1,1,0,1,1,0,1,0,2,3,1. domain expert,2,4. visual expert,1,0,0,0,1,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,4. After the deployment,0,,
,,2020J004,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,5. no participant,0,,,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,4. After the deployment,0,,
227,75,2020J005,Lyra 2: Designing Interactive Visualizations by Demonstration,"Zong, Jonathan and Barnwal, Dhiraj and Neogy, Rupayan and Satyanarayan, Arvind",2020,2021,Data visualization;Visualization;Brushes;Programming;Image color analysis;Usability;Tools;Direct manipulation;interactive visualization;interaction design by demonstration,"Recent graphical interfaces offer direct manipulation mechanisms for authoring visualizations, but are largely restricted to static output. To author interactive visualizations, users must instead turn to textual specification, but such approaches impose a higher technical burden. To bridge this gap, we introduce Lyra 2, a system that extends a prior visualization design environment with novel methods for authoring interaction techniques by demonstration. Users perform an interaction (e.g., button clicks, drags, or key presses) directly on the visualization they are editing. The system interprets this performance using a set of heuristics and enumerates suggestions of possible interaction designs. These heuristics account for the properties of the interaction (e.g., target and event type) as well as the visualization (e.g., mark and scale types, and multiple views). Interaction design suggestions are displayed as thumbnails; users can preview and test these suggestions, iteratively refine them through additional demonstrations, and finally apply and customize them via property inspectors. We evaluate our approach through a gallery of diverse examples, and evaluate its usability through a first-use study and via an analysis of its cognitive dimensions. We find that, in Lyra 2, interaction design by demonstration enables users to rapidly express a wide range of interactive visualizations.",10.1109/TVCG.2020.3030367,,TRUE,TRUE,TRUE,T,,F,C1,DROP-d3,0,,,visualization,1,1,1,1,1,0,1,1,0,0,0,,,4. visual expert,2,3. general public,4,0,0,0,0,0,1,0,1,1,0,0,0,0,0,1,1,1,1,0,,,0,0,0,0,0,4. After the deployment,0,,
336,343,2020J006,StructGraphics: Flexible Visualization Design through Data-Agnostic and Reusable Graphical Structures,"Tsandilas, Theophanis",2020,2021,Data visualization;Layout;Visualization;Tools;Programming;Task analysis;Visualization design;graphical structures;visualization grammars;layout constraints;infographics;flexible data binding,"Information visualization research has developed powerful systems that enable users to author custom data visualizations without textual programming. These systems can support graphics-driven practices by bridging lazy data-binding mechanisms with vector-graphics editing tools. Yet, despite their expressive power, visualization authoring systems often assume that users want to generate visual representations that they already have in mind rather than explore designs. They also impose a data-to-graphics workflow, where binding data dimensions to graphical properties is a necessary step for generating visualization layouts. In this paper, we introduce StructGraphics, an approach for creating data-agnostic and fully reusable visualization designs. StructGraphics enables designers to construct visualization designs by drawing graphics on a canvas and then structuring their visual properties without relying on a concrete dataset or data schema. In StructGraphics, tabular data structures are derived directly from the structure of the graphics. Later, designers can link these structures with real datasets through a spreadsheet user interface. StructGraphics supports the design and reuse of complex data visualizations by combining graphical property sharing, by-example design specification, and persistent layout constraints. We demonstrate the power of the approach through a gallery of visualization examples and reflect on its strengths and limitations in interaction with graphic designers and data visualization experts.",10.1109/TVCG.2020.3030476,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
228,76,2020J007,VisCode: Embedding Information in Visualization Images using Encoder-Decoder Network,"Zhang, Peiying and Li, Chenhui and Wang, Changbo",2020,2021,Data visualization;Visualization;Decoding;Image coding;Encoding;Image color analysis;Media;Information visualization;information steganography;autocoding;saliency detection;visualization retargeting,"We present an approach called VisCode for embedding information into visualization images. This technology can implicitly embed data information specified by the user into a visualization while ensuring that the encoded visualization image is not distorted. The VisCode framework is based on a deep neural network. We propose to use visualization images and QR codes data as training data and design a robust deep encoder-decoder network. The designed model considers the salient features of visualization images to reduce the explicit visual loss caused by encoding. To further support large-scale encoding and decoding, we consider the characteristics of information visualization and propose a saliency-based QR code layout algorithm. We present a variety of practical applications of VisCode in the context of information visualization and conduct a comprehensive evaluation of the perceptual quality of encoding, decoding success rate, anti-attack capability, time performance, etc. The evaluation results demonstrate the effectiveness of VisCode.",10.1109/TVCG.2020.3030343,,TRUE,TRUE,TRUE,T,,F,C1,DROP-algorithm,0,,,,0,1,1,0,0,0,,,,,,,,,0,,,0,0,0,0,0,0,1,0,1,,0,0,0,0,0,0,0,0,0,,,1,0,1,0,0,4. After the deployment,,,
230,77,2020J008,Chartem: Reviving Chart Images with Data Embedding,"Fu, Jiayun and Zhu, Bin and Cui, Weiwei and Ge, Song and Wang, Yun and Zhang, Haidong and Huang, He and Tang, Yuanyuan and Zhang, Dongmei and Ma, Xiaojing",2020,2021,Data mining;Watermarking;Visualization;Image color analysis;Image coding;Bars;Prototypes;Chart embedding;background embedding;data embedding;chart image;chart reuse,"In practice, charts are widely stored as bitmap images. Although easily consumed by humans, they are not convenient for other uses. For example, changing the chart style or type or a data value in a chart image practically requires creating a completely new chart, which is often a time-consuming and error-prone process. To assist these tasks, many approaches have been proposed to automatically extract information from chart images with computer vision and machine learning techniques. Although they have achieved promising preliminary results, there are still a lot of challenges to overcome in terms of robustness and accuracy. In this paper, we propose a novel alternative approach called Chartem to address this issue directly from the root. Specifically, we design a data-embedding schema to encode a significant amount of information into the background of a chart image without interfering human perception of the chart. The embedded information, when extracted from the image, can enable a variety of visualization applications to reuse or repurpose chart images. To evaluate the effectiveness of Chartem, we conduct a user study and performance experiments on Chartem embedding and extraction algorithms. We further present several prototype applications to demonstrate the utility of Chartem.",10.1109/TVCG.2020.3030351,,TRUE,TRUE,TRUE,T,T,F,C1,DROP,0,,,data embedding,0,1,1,0,0,0,0,0,0,0,0,,,3. general public,22,,,1?,0,0,0,0,0,0,0,0,,0,0,0,0,0,0,0,0,0,,,1,0,0,0,0,2. Before the deployment (Before or during design phase ONLY),,,
,,2020J008,,,,,,,,,,,,,,,,,0,,,,,,,,,,,,,,,,,,0,,,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,,,1,0,1,0,0,4. After the deployment,0,,
234,78,2020J009,VisConnect: Distributed Event Synchronization for Collaborative Visualization,"Schwab, Michail and Saffo, David and Zhang, Yixuan and Sinha, Shash and Nita-Rotaru, Cristina and Tompkin, James and Dunne, Cody and Borkin, Michelle A.",2020,2021,Data visualization;Collaboration;Synchronization;Visualization;Computer architecture;Peer-to-peer computing;Safety;Collaborative visualization;distributed visualization;toolkit,"Tools and interfaces are increasingly expected to be synchronous and distributed to accommodate remote collaboration. Yet, adoption of these techniques for data visualization is low partly because development is difficult: existing collaboration software systems either do not support simultaneous interaction or require expensive redevelopment of existing visualizations. We contribute VisConnect: a web-based synchronous distributed collaborative visualization system that supports most web-based SVG data visualizations, balances system safety with responsiveness, and supports simultaneous interaction from many collaborators. VisConnect works with existing visualization implementations with little-to-no code changes by synchronizing low-level JavaScript events across clients such that visualization updates proceed transparently across clients. This is accomplished via a peer-to-peer system that establishes consensus among clients on the per-element sequence of events, and uses a lock service to grant access over elements to clients. We contribute collaborative extensions of traditional visualization interaction techniques, such as drag, brush, and lasso, and discuss different strategies for collaborative visualization interactions. To demonstrate the utility of VisConnect, we present novel examples of collaborative visualizations in the healthcare domain, remote collaboration with annotation, and show in an education case study for e-learning with 22 participants that students found the ability to remotely collaborate on class activities helpful and enjoyable for understanding concepts. A free copy of this paper and source code are available on OSF at osf.io/ut7e6 and at visconnect.us.",10.1109/TVCG.2020.3030366,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,5. Education and e-learning,,,1,1,1,1,1,0,1,1,0,0,0,2,23,2. domain user,1,,,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,4. After the deployment,0,,
,,2020J009,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,2. domain user,22,,,0,0,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,4. After the deployment,0,,
235,79,2020J013,PipelineProfiler: A Visual Analytics Tool for the Exploration of AutoML Pipelines,"Ono, Jorge Piazentin and Castelo, Sonia and Lopez, Roque and Bertini, Enrico and Freire, Juliana and Silva, Claudio",2020,2021,Pipelines;Tools;Visual analytics;Machine learning;Data visualization;Search problems;Correlation;Automatic Machine Learning;Pipeline Visualization;Model Evaluation,"In recent years, a wide variety of automated machine learning (AutoML) methods have been proposed to generate end-to-end ML pipelines. While these techniques facilitate the creation of models, given their black-box nature, the complexity of the underlying algorithms, and the large number of pipelines they derive, they are difficult for developers to debug. It is also challenging for machine learning experts to select an AutoML system that is well suited for a given problem. In this paper, we present the Pipeline Profiler, an interactive visualization tool that allows the exploration and comparison of the solution space of machine learning (ML) pipelines produced by AutoML systems. PipelineProfiler is integrated with Jupyter Notebook and can be combined with common data science tools to enable a rich set of analyses of the ML pipelines, providing users a better understanding of the algorithms that generated them as well as insights into how they can be improved. We demonstrate the utility of our tool through use cases where PipelineProfiler is used to better understand and improve a real-world AutoML system. Furthermore, we validate our approach by presenting a detailed analysis of a think-aloud experiment with six data scientists who develop and evaluate AutoML tools.",10.1109/TVCG.2020.3030361,,TRUE,TRUE,TRUE,T,,F,C1,KEEP,1,1. AI (Machine Learning/Deep Learning/Data Mining),,,0,1,1,1,1,1,1,1,1,0,0,2,8,1. domain expert,6,,,0,1,0,0,0,1,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,4. After the deployment,0,,
,,2020J013,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,2,,,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,4. After the deployment,0,,
237,80,2020J015,Competing Models: Inferring Exploration Patterns and Information Relevance via Bayesian Model Selection,"Monadjemi, Shayan and Garnett, Roman and Ottley, Alvitta",2020,2021,Data visualization;Hidden Markov models;Data models;Visual analytics;Analytical models;Bayes methods;Task analysis;User Interaction Modeling;Bayesian Machine Learning,"Analyzing interaction data provides an opportunity to learn about users, uncover their underlying goals, and create intelligent visualization systems. The first step for intelligent response in visualizations is to enable computers to infer user goals and strategies through observing their interactions with a system. Researchers have proposed multiple techniques to model users, however, their frameworks often depend on the visualization design, interaction space, and dataset. Due to these dependencies, many techniques do not provide a general algorithmic solution to user exploration modeling. In this paper, we construct a series of models based on the dataset and pose user exploration modeling as a Bayesian model selection problem where we maintain a belief over numerous competing models that could explain user interactions. Each of these competing models represent an exploration strategy the user could adopt during a session. The goal of our technique is to make high-level and in-depth inferences about the user by observing their low-level interactions. Although our proposed idea is applicable to various probabilistic model spaces, we demonstrate a specific instance of encoding exploration patterns as competing models to infer information relevance. We validate our technique's ability to infer exploration bias, predict future interactions, and summarize an analytic session using user study datasets. Our results indicate that depending on the application, our method outperforms established baselines for bias detection and future interaction prediction. Finally, we discuss future research directions based on our proposed modeling paradigm and suggest how practitioners can use this method to build intelligent visualization systems that understand users' goals and adapt to improve the exploration process.",10.1109/TVCG.2020.3030430,,TRUE,TRUE,TRUE,,T,F,C1,DROP,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
238,81,2020J016,II-20: Intelligent and pragmatic analytic categorization of image collections,"ZahÃ¡lka, Jan and Worring, Marcel and Van Wijk, Jarke J.",2020,2021,Analytical models;Semantics;Pragmatics;Computational modeling;Task analysis;Visual analytics;Multimedia analytics;image data;analytic categorization;pragmatic gap,"In this paper, we introduce 11-20 (Image Insight 2020), a multimedia analytics approach for analytic categorization of image collections. Advanced visualizations for image collections exist, but they need tight integration with a machine model to support the task of analytic categorization. Directly employing computer vision and interactive learning techniques gravitates towards search. Analytic categorization, however, is not machine classification (the difference between the two is called the pragmatic gap): a human adds/redefines/deletes categories of relevance on the fly to build insight, whereas the machine classifier is rigid and non-adaptive. Analytic categorization that truly brings the user to insight requires a flexible machine model that allows dynamic sliding on the exploration-search axis, as well as semantic interactions: a human thinks about image data mostly in semantic terms. 11-20 brings three major contributions to multimedia analytics on image collections and towards closing the pragmatic gap. Firstly, a new machine model that closely follows the user's interactions and dynamically models her categories of relevance. II-20's machine model, in addition to matching and exceeding the state of the art's ability to produce relevant suggestions, allows the user to dynamically slide on the exploration-search axis without any additional input from her side. Secondly, the dynamic, 1-image-at-a-time Tetris metaphor that synergizes with the model. It allows a well-trained model to analyze the collection by itself with minimal interaction from the user and complements the classic grid metaphor. Thirdly, the fast-forward interaction, allowing the user to harness the model to quickly expand (â€œfast-forwardâ€) the categories of relevance, expands the multimedia analytics semantic interaction dictionary. Automated experiments show that II-20's machine model outperforms the existing state of the art and also demonstrate the Tetris metaphor's analytic quality. User studies further confirm that II-20 is an intuitive, efficient, and effective multimedia analytics tool.",10.1109/TVCG.2020.3030383,,TRUE,TRUE,TRUE,,T,F,C1,DROP,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
239,82,2020J017,Argus: Interactive a priori Power Analysis,"Wang, Xiaoyi and Eiselmayer, Alexander and Mackay, Wendy E. and Hornbaek, Kasper and Wacharamanotham, Chat",2020,2021,Fatigue;Tools;Human computer interaction;Statistics;Sociology;Task analysis;History;Experiment design;power analysis;simulation,"A key challenge HCl researchers face when designing a controlled experiment is choosing the appropriate number of participants, or sample size. A priori power analysis examines the relationships among multiple parameters, including the complexity associated with human participants, e.g., order and fatigue effects, to calculate the statistical power of a given experiment design. We created Argus, a tool that supports interactive exploration of statistical power: Researchers specify experiment design scenarios with varying confounds and effect sizes. Argus then simulates data and visualizes statistical power across these scenarios, which lets researchers interactively weigh various trade-offs and make informed decisions about sample size. We describe the design and implementation of Argus, a usage scenario designing a visualization experiment, and a think-aloud study.",10.1109/TVCG.2020.3028894,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,19. Others,,visualization and hci,0,1,1,1,1,0,1,1,0,0,0,1,9,1. domain expert,5,2. domain user,4,0,1,0,0,0,1,0,0,0,0,0,0,0,1,1,0,1,1,0,0,0,0,0,0,0,0,4. After the deployment,0,,
242,83,2020J019,Calliope: Automatic Visual Data Story Generation from a Spreadsheet,"Shi, Danqing and Xu, Xinyue and Sun, Fuling and Shi, Yang and Cao, Nan",2020,2021,Data visualization;Visualization;Space exploration;Tools;Authoring systems;Market research;Data models;Information Visualization;Visual Storytelling;Data Story,"Visual data stories shown in the form of narrative visualizations such as a poster or a data video, are frequently used in data-oriented storytelling to facilitate the understanding and memorization of the story content. Although useful, technique barriers, such as data analysis, visualization, and scripting, make the generation of a visual data story difficult. Existing authoring tools rely on users' skills and experiences, which are usually inefficient and still difficult. In this paper, we introduce a novel visual data story generating system, Calliope, which creates visual data stories from an input spreadsheet through an automatic process and facilities the easy revision of the generated story based on an online story editor. Particularly, Calliope incorporates a new logic-oriented Monte Carlo tree search algorithm that explores the data space given by the input spreadsheet to progressively generate story pieces (i.e., data facts) and organize them in a logical order. The importance of data facts is measured based on information theory, and each data fact is visualized in a chart and captioned by an automatically generated description. We evaluate the proposed technique through three example stories, two controlled experiments, and a series of interviews with 10 domain experts. Our evaluation shows that Calliope is beneficial to efficient visual data story generation.",10.1109/TVCG.2020.3030403,,TRUE,TRUE,TRUE,T,,F,C1,KEEP,1,12. Journalism and media,,,0,1,1,1,1,0,1,1,0,1,0,3,27,2. domain user,20,3. general public,16,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,4. After the deployment,0,,
,,2020J019,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,5. no participant,0,,,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4. After the deployment,0,,
,,2020J019,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,7,4. visual expert,3,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,1,0,1,0,0,0,0,0,0,0,0,4. After the deployment,0,,
244,84,2020J020,MobileVisFixer: Tailoring Web Visualizations for Mobile Phones Leveraging an Explainable Reinforcement Learning Framework,"Wu, Aoyu and Tong, Wai and Dwyer, Tim and Lee, Bongshin and Isenberg, Petra and Qu, Huamin",2020,2021,Data visualization;Visualization;Mobile handsets;Sociology;Statistics;Encoding;Layout;Mobile visualization;Responsive visualization;Machine learning for visualizations;Reinforcement learning,"We contribute MobileVisFixer, a new method to make visualizations more mobile-friendly. Although mobile devices have become the primary means of accessing information on the web, many existing visualizations are not optimized for small screens and can lead to a frustrating user experience. Currently, practitioners and researchers have to engage in a tedious and time-consuming process to ensure that their designs scale to screens of different sizes, and existing toolkits and libraries provide little support in diagnosing and repairing issues. To address this challenge, MobileVisFixer automates a mobile-friendly visualization re-design process with a novel reinforcement learning framework. To inform the design of MobileVisFixer, we first collected and analyzed SVG-based visualizations on the web, and identified five common mobile-friendly issues. MobileVisFixer addresses four of these issues on single-view Cartesian visualizations with linear or discrete scales by a Markov Decision Process model that is both generalizable across various visualizations and fully explainable. MobileVisFixer deconstructs charts into declarative formats, and uses a greedy heuristic based on Policy Gradient methods to find solutions to this difficult, multi-criteria optimization problem in reasonable time. In addition, MobileVisFixer can be easily extended with the incorporation of optimization algorithms for data visualizations. Quantitative evaluation on two real-world datasets demonstrates the effectiveness and generalizability of our method.",10.1109/TVCG.2020.3030423,,TRUE,TRUE,TRUE,T,,F,C2,DROP,0,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
247,85,2020J022,Gemini: A Grammar and Recommender System for Animated Transitions in Statistical Graphics,"Kim, Younghoon and Heer, Jeffrey",2020,2021,Animation;Data visualization;Grammar;Visualization;Timing;Task analysis;Animated transition;animation;transition;declarative grammar;automated design;charts,"Animated transitions help viewers follow changes between related visualizations. Specifying effective animations demands significant effort: authors must select the elements and properties to animate, provide transition parameters, and coordinate the timing of stages. To facilitate this process, we present Gemini, a declarative grammar and recommendation system for animated transitions between single-view statistical graphics. Gemini specifications define transition â€œstepsâ€ in terms of high-level visual components (marks, axes, legends) and composition rules to synchronize and concatenate steps. With this grammar, Gemini can recommend animation designs to augment and accelerate designers' work. Gemini enumerates staged animation designs for given start and end states, and ranks those designs using a cost function informed by prior perceptual studies. To evaluate Gemini, we conduct both a formative study on Mechanical Turk to assess and tune our ranking function, and a summative study in which 8 experienced visualization developers implement animations in D3 that we then compare to Gemini's suggestions. We find that most designs (9/11) are exactly replicable in Gemini, with many (8/11) achievable via edits to suggestions, and that Gemini suggestions avoid multiple participant errors.",10.1109/TVCG.2020.3030360,,TRUE,TRUE,TRUE,T,,F,C2,DROP,0,,,,,,,,0,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
248,86,2020J023,VizCommender: Computing Text-Based Similarity in Visualization Repositories for Content-Based Recommendations,"Oppermann, Michael and Kincaid, Robert and Munzner, Tamara",2020,2021,Data visualization;Visualization;Task analysis;Feature extraction;Encoding;Recommender systems;Natural language processing;visualization recommendation;content-based filtering;recommender systems;visualization workbook repositories,"Cloud-based visualization services have made visual analytics accessible to a much wider audience than ever before. Systems such as Tableau have started to amass increasingly large repositories of analytical knowledge in the form of interactive visualization workbooks. When shared, these collections can form a visual analytic knowledge base. However, as the size of a collection increases, so does the difficulty in finding relevant information. Content-based recommendation (CBR) systems could help analysts in finding and managing workbooks relevant to their interests. Toward this goal, we focus on text-based content that is representative of the subject matter of visualizations rather than the visual encodings and style. We discuss the challenges associated with creating a CBR based on visualization specifications and explore more concretely how to implement the relevance measures required using Tableau workbook specifications as the source of content data. We also demonstrate what information can be extracted from these visualization specifications and how various natural language processing techniques can be used to compute similarity between workbooks as one way to measure relevance. We report on a crowd-sourced user study to determine if our similarity measure mimics human judgement. Finally, we choose latent Dirichl et al.ocation (LDA) as a specific model and instantiate it in a proof-of-concept recommender tool to demonstrate the basic function of our similarity measure.",10.1109/TVCG.2020.3030387,,TRUE,TRUE,TRUE,,T,F,C2,DROP,0,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
249,87,2020J024,A Visual Analytics Approach for Ecosystem Dynamics based on Empirical Dynamic Modeling,"Natsukawa, Hiroaki and Deyle, Ethan R. and Pao, Gerald M. and Koyamada, Koji and Sugihara, George",2020,2021,Visual analytics;Time series analysis;Data visualization;Ecosystems;Task analysis;Time measurement;Ecology;Visual analytics;empirical dynamic modeling;dynamic network;exploratory data analysis,"An important approach for scientific inquiry across many disciplines involves using observational time series data to understand the relationships between key variables to gain mechanistic insights into the underlying rules that govern the given system. In real systems, such as those found in ecology, the relationships between time series variables are generally not static; instead, these relationships are dynamical and change in a nonlinear or state-dependent manner. To further understand such systems, we investigate integrating methods that appropriately characterize these dynamics (i.e., methods that measure interactions as they change with time-varying system states) with visualization techniques that can help analyze the behavior of the system. Here, we focus on empirical dynamic modeling (EDM) as a state-of-the-art method that specifically identifies causal variables and measures changing state-dependent relationships between time series variables. Instead of using approaches centered on parametric equations, EDM is an equation-free approach that studies systems based on their dynamic attractors. We propose a visual analytics system to support the identification and mechanistic interpretation of system states using an EDM-constructed dynamic graph. This work, as detailed in four analysis tasks and demonstrated with a GUI, provides a novel synthesis of EDM and visualization techniques such as brush-link visualization and visual summarization to interpret dynamic graphs representing ecosystem dynamics. We applied our proposed system to ecological simulation data and real data from a marine mesocosm study as two key use cases. Our case studies show that our visual analytics tools support the identification and interpretation of the system state by the user, and enable us to discover both confirmatory and new findings in ecosystem dynamics. Overall, we demonstrated that our system can facilitate an understanding of how systems function beyond the intuitive analysis of high-dimensional information based on specific domain knowledge.",10.1109/TVCG.2020.3028956,,TRUE,TRUE,TRUE,,T,F,C2,KEEP,1,2. Biology and life sciences,,Ecology,1,1,1,1,1,1,1,1,0,0,0,1,3,1. domain expert,3,,,0,1,0,0,0,1,0,0,1,0,1,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,4. After the deployment,0,,
253,88,2020J028,Visual Analytics for Temporal Hypergraph Model Exploration,"Fischer, Maximilian T. and Arya, Devanshu and Streeb, Dirk and Seebacher, Daniel and Keim, Daniel A. and Worring, Marcel",2020,2021,Visualization;Computational modeling;Machine learning;Predictive models;Analytical models;Semantics;Data models;Hypergraph;communication analysis;geometric deep learning;semantic zoom;matrix ordering;visual analytics,"Many processes, from gene interaction in biology to computer networks to social media, can be modeled more precisely as temporal hypergraphs than by regular graphs. This is because hypergraphs generalize graphs by extending edges to connect any number of vertices, allowing complex relationships to be described more accurately and predict their behavior over time. However, the interactive exploration and seamless refinement of such hypergraph-based prediction models still pose a major challenge. We contribute Hyper-Matrix, a novel visual analytics technique that addresses this challenge through a tight coupling between machine-learning and interactive visualizations. In particular, the technique incorporates a geometric deep learning model as a blueprint for problem-specific models while integrating visualizations for graph-based and category-based data with a novel combination of interactions for an effective user-driven exploration of hypergraph models. To eliminate demanding context switches and ensure scalability, our matrix-based visualization provides drill-down capabilities across multiple levels of semantic zoom, from an overview of model predictions down to the content. We facilitate a focused analysis of relevant connections and groups based on interactive user-steering for filtering and search tasks, a dynamically modifiable partition hierarchy, various matrix reordering techniques, and interactive model feedback. We evaluate our technique in a case study and through formative evaluation with law enforcement experts using real-world internet forum communication data. The results show that our approach surpasses existing solutions in terms of scalability and applicability, enables the incorporation of domain knowledge, and allows for fast search-space traversal. With the proposed technique, we pave the way for the visual analytics of temporal hypergraphs in a wide variety of domains.",10.1109/TVCG.2020.3030408,,TRUE,TRUE,TRUE,T,T,F,C2,KEEP,1,16. Public safety and emergency management,,Law Enforcement,1,1,1,1,0,0,0,1,0,1,0,1,3,1. domain expert,3,,,0,1,0,0,0,1,0,0,1,0,1,0,0,0,1,0,1,1,0,1,1,0,0,0,0,0,4. After the deployment,0,,
381,344,2020J032,A Suggestive Interface for Untangling Mathematical Knots,"Liu, Huan and Zhang, Hui",2020,2021,Three-dimensional displays;Visualization;Image reconstruction;Strain;Geometry;Law;Knot theory;Reidemeister moves;Gauss code;Mathematical visualization;Suggestive interface,"In this paper we present a user-friendly sketching-based suggestive interface for untangling mathematical knots with complicated structures. Rather than treating mathematical knots as if they were 3D ropes, our interface is designed to assist the user to interact with knots with the right sequence of mathematically legal moves. Our knot interface allows one to sketch and untangle knots by proposing the Reidemeister moves, and can guide the user to untangle mathematical knots to the fewest possible number of crossings by suggesting the moves needed. The system highlights parts of the knot where the Reidemeister moves are applicable, suggests the possible moves, and constrains the user's drawing to legal moves only. This ongoing suggestion is based on a Reidemeister move analyzer, that reads the evolving knot in its Gauss code and predicts the needed Reidemeister moves towards the fewest possible number of crossings. For our principal test case of mathematical knot diagrams, this for the first time permits us to visualize, analyze, and deform them in a mathematical visual interface. In addition, understanding of a fairly long mathematical deformation sequence in our interface can be aided by visual analysis and comparison over the identified â€œkey momentsâ€ where only critical changes occur in the sequence. Our knot interface allows users to track and trace mathematical knot deformation with a significantly reduced number of visual frames containing only the Reidemeister moves being applied. All these combine to allow a much cleaner exploratory interface for us to analyze and study mathematical knots and their dynamics in topological space.",10.1109/TVCG.2020.3028893,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
255,89,2020J038,Githru: Visual Analytics for Understanding Software Development History Through Git Metadata Analysis,"Kim, Youngtaek and Kim, Jaeyoung and Jeon, Hyeon and Kim, Young-Ho and Song, Hyunjoo and Kim, Bohyoung and Seo, Jinwook",2020,2021,History;Metadata;Software;Visualization;Interviews;Tools;Complexity theory;git;history;exploration;overview;repository;visualization;cluster;DAG,"Git metadata contains rich information for developers to understand the overall context of a large software development project. Thus it can help new developers, managers, and testers understand the history of development without needing to dig into a large pile of unfamiliar source code. However, the current tools for Git visualization are not adequate to analyze and explore the metadata: They focus mainly on improving the usability of Git commands instead of on helping users understand the development history. Furthermore, they do not scale for large and complex Git commit graphs, which can play an important role in understanding the overall development history. In this paper, we present Githru, an interactive visual analytics system that enables developers to effectively understand the context of development history through the interactive exploration of Git metadata. We design an interactive visual encoding idiom to represent a large Git graph in a scalable manner while preserving the topological structures in the Git graph. To enable scalable exploration of a large Git commit graph, we propose novel techniques (graph reconstruction, clustering, and Context-Preserving Squash Merge (CSM) methods) to abstract a large-scale Git commit graph. Based on these Git commit graph abstraction techniques, Githru provides an interactive summary view to help users gain an overview of the development history and a comparison view in which users can compare different clusters of commits. The efficacy of Githru has been demonstrated by case studies with domain experts using real-world, in-house datasets from a large software development team at a major international IT company. A controlled user study with 12 developers comparing Githru to previous tools also confirms the effectiveness of Githru in terms of task completion time.",10.1109/TVCG.2020.3030414,,TRUE,TRUE,TRUE,,T,F,C2,KEEP,1,19. Others,,Software Development,0,1,1,1,1,1,1,1,0,0,0,2,17,1. domain expert,5,,,1,1,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,4. After the deployment,0,,
,,2020J038,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,2. domain user,12,,,0,1,0,0,1,1,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,1,0,0,1,0,4. After the deployment,0,,
256,90,2020J039,CcNav: Understanding Compiler Optimizations in Binary Code,"Devkota, Sabin and Aschwanden, Pascal and Kunen, Adam and Legendre, Matthew and Isaacs, Katherine E.",2020,2021,Optimization;Tools;Visualization;Binary codes;Navigation;Task analysis;Debugging;Design study;program analysis;compilation;binary code;transferability;immersion,"Program developers spend significant time on optimizing and tuning programs. During this iterative process, they apply optimizations, analyze the resulting code, and modify the compilation until they are satisfied. Understanding what the compiler did with the code is crucial to this process but is very time-consuming and labor-intensive. Users need to navigate through thousands of lines of binary code and correlate it to source code concepts to understand the results of the compilation and to identify optimizations. We present a design study in collaboration with program developers and performance analysts. Our collaborators work with various artifacts related to the program such as binary code, source code, control flow graphs, and call graphs. Through interviews, feedback, and pair-analytics sessions, we analyzed their tasks and workflow. Based on this task analysis and through a human-centric design process, we designed a visual analytics system Compilation Navigator (CcNav) to aid exploration of the effects of compiler optimizations on the program. CcNav provides a streamlined workflow and a unified context that integrates disparate artifacts. CcNav supports consistent interactions across all the artifacts making it easy to correlate binary code with source code concepts. CcNav enables users to navigate and filter large binary code to identify and summarize optimizations such as inlining, vectorization, loop unrolling, and code hoisting. We evaluate CcNav through guided sessions and semi-structured interviews. We reflect on our design process, particularly the immersive elements, and on the transferability of design studies through our experience with a previous design study on program analysis.",10.1109/TVCG.2020.3030357,,TRUE,TRUE,TRUE,T,,T,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2020J040,Humane Visual AI: Telling the Stories Behind a Medical Condition,"So, Wonyoung and Bogucka, Edyta P. and Å Ä‡epanoviÄ‡, Sanja and Joglekar, Sagar and Zhou, Ke and Quercia, Daniele",2020,2021,Psychology;Data visualization;Medical conditions;Reddit;Drugs;Biology;complex problem communication;storytelling;AI;social media data;healthcare;Martini Glass structure,"A biological understanding is key for managing medical conditions, yet psychological and social aspects matter too. The main problem is that these two aspects are hard to quantify and inherently difficult to communicate. To quantify psychological aspects, this work mined around half a million Reddit posts in the sub-communities specialised in 14 medical conditions, and it did so with a new deep-learning framework. In so doing, it was able to associate mentions of medical conditions with those of emotions. To then quantify social aspects, this work designed a probabilistic approach that mines open prescription data from the National Health Service in England to compute the prevalence of drug prescriptions, and to relate such a prevalence to census data. To finally visually communicate each medical condition's biological, psychological, and social aspects through storytelling, we designed a narrative-style layered Martini Glass visualization. In a user study involving 52 participants, after interacting with our visualization, a considerable number of them changed their mind on previously held opinions: 10% gave more importance to the psychological aspects of medical conditions, and 27% were more favourable to the use of social media data in healthcare, suggesting the importance of persuasive elements in interactive visualizations.",10.1109/TVCG.2020.3030391,,TRUE,TRUE,TRUE,,T,F,C2,DROP,0,,,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
257,91,2020J042,Visualization of Human Spine Biomechanics for Spinal Surgery,"Eulzer, Pepe and Bauer, Sabine and Kilian, Francis and Lawonn, Kai",2020,2021,Biological system modeling;Data visualization;Three-dimensional displays;Load modeling;Biomechanics;Surgery;Computational modeling;Medical visualization;bioinformatics;coordinated views;focus and context;biomechanical simulation,"We propose a visualization application, designed for the exploration of human spine simulation data. Our goal is to support research in biomechanical spine simulation and advance efforts to implement simulation-backed analysis in surgical applications. Biomechanical simulation is a state-of-the-art technique for analyzing load distributions of spinal structures. Through the inclusion of patient-specific data, such simulations may facilitate personalized treatment and customized surgical interventions. Difficulties in spine modelling and simulation can be partly attributed to poor result representation, which may also be a hindrance when introducing such techniques into a clinical environment. Comparisons of measurements across multiple similar anatomical structures and the integration of temporal data make commonly available diagrams and charts insufficient for an intuitive and systematic display of results. Therefore, we facilitate methods such as multiple coordinated views, abstraction and focus and context to display simulation outcomes in a dedicated tool. By linking the result data with patient-specific anatomy, we make relevant parameters tangible for clinicians. Furthermore, we introduce new concepts to show the directions of impact force vectors, which were not accessible before. We integrated our toolset into a spine segmentation and simulation pipeline and evaluated our methods with both surgeons and biomechanical researchers. When comparing our methods against standard representations that are currently in use, we found increases in accuracy and speed in data exploration tasks. In a qualitative review, domain experts deemed the tool highly useful when dealing with simulation result data, which typically combines time-dependent patient movement and the resulting force distributions on spinal structures.",10.1109/TVCG.2020.3030388,,TRUE,TRUE,TRUE,T,,F,C2,KEEP,1,10. Healthcare and medical imaging,,Healthcare,0,1,1,1,1,1,1,1,0,0,0,1,6,1. domain expert,6,,,1,1,0,0,1,1,0,0,0,0,1,0,0,1,1,0,1,1,0,0,0,0,1,0,1,0,1. Before the deployment (General),1,,
403,345,2020J043,In Search of Patient Zero: Visual Analytics of Pathogen Transmission Pathways in Hospitals,"Baumgartl, T. and Petzold, M. and Wunderlich, M. and Hohn, M. and Archambault, D. and Lieser, M. and Dalpke, A. and Scheithauer, S. and Marschollek, M. and Eichel, V. M. and Mutters, N. T. and Consortium, Highmed and Landesberger, T. Von",2020,2021,Hospitals;Pathogens;Data visualization;Task analysis;Visual analytics;Statistics;Sociology;dynamic networks;visualization applications;health;medicine;outbreak;Klebsiella;infection control,"Pathogen outbreaks (i.e., outbreaks of bacteria and viruses) in hospitals can cause high mortality rates and increase costs for hospitals significantly. An outbreak is generally noticed when the number of infected patients rises above an endemic level or the usual prevalence of a pathogen in a defined population. Reconstructing transmission pathways back to the source of an outbreak - the patient zero or index patient - requires the analysis of microbiological data and patient contacts. This is often manually completed by infection control experts. We present a novel visual analytics approach to support the analysis of transmission pathways, patient contacts, the progression of the outbreak, and patient timelines during hospitalization. Infection control experts applied our solution to a real outbreak of Klebsiella pneumoniae in a large German hospital. Using our system, our experts were able to scale the analysis of transmission pathways to longer time intervals (i.e., several years of data instead of days) and across a larger number of wards. Also, the system is able to reduce the analysis time from days to hours. In our final study, feedback from twenty-five experts from seven German hospitals provides evidence that our solution brings significant benefits for analyzing outbreaks.",10.1109/TVCG.2020.3030437,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
259,92,2020J045,Visual cohort comparison for spatial single-cell omics-data,"Somarakis, Antonios and Ijsselsteijn, Marieke E. and Luk, Sietse J. and Kenkhuis, Boyd and de Miranda, Noel F.C.C. and Lelieveldt, Boudewijn P.F. and HÃ¶llt, Thomas",2020,2021,Visualization;Image segmentation;Biomedical imaging;Spatial databases;Task analysis;Tools;Visual analytics;Imaging Mass Cytometry;Vectra;spatially-resolved data;single-cell omics-data;Visual comparison,"Spatially-resolved omics-data enable researchers to precisely distinguish cell types in tissue and explore their spatial interactions, enabling deep understanding of tissue functionality. To understand what causes or deteriorates a disease and identify related biomarkers, clinical researchers regularly perform large-scale cohort studies, requiring the comparison of such data at cellular level. In such studies, with little a-priori knowledge of what to expect in the data, explorative data analysis is a necessity. Here, we present an interactive visual analysis workflow for the comparison of cohorts of spatially-resolved omics-data. Our workflow allows the comparative analysis of two cohorts based on multiple levels-of-detail, from simple abundance of contained cell types over complex co-localization patterns to individual comparison of complete tissue images. As a result, the workflow enables the identification of cohort-differentiating features, as well as outlier samples at any stage of the workflow. During the development of the workflow, we continuously consulted with domain experts. To show the effectiveness of the workflow, we conducted multiple case studies with domain experts from different application areas and with different data modalities.",10.1109/TVCG.2020.3030336,,TRUE,TRUE,TRUE,,T,F,C2,KEEP,1,2. Biology and life sciences,10. Healthcare and medical imaging,Microbiology,0,1,1,1,1,1,1,1,0,0,0,1,4,1. domain expert,3,2. domain user,1,1,1,0,0,0,1,0,0,0,0,1,0,0,0,0,1,1,1,0,0,1,0,0,0,0,0,4. After the deployment,0,,
260,93,2020J046,Improving the Usability of Virtual Reality Neuron Tracing with Topological Elements,"McDonald, Torin and Usher, Will and Morrical, Nate and Gyulassy, Attila and Petruzza, Steve and Federer, Frederick and Angelucci, Alessandra and Pascucci, Valerio",2020,2021,Neurons;Tools;Manuals;Image reconstruction;Three-dimensional displays;Data visualization;Virtual reality;Virtual Reality;Morse-Smale Complex;Semi-automatic Neuron Tracing,"Researchers in the field of connectomics are working to reconstruct a map of neural connections in the brain in order to understand at a fundamental level how the brain processes information. Constructing this wiring diagram is done by tracing neurons through high-resolution image stacks acquired with fluorescence microscopy imaging techniques. While a large number of automatic tracing algorithms have been proposed, these frequently rely on local features in the data and fail on noisy data or ambiguous cases, requiring time-consuming manual correction. As a result, manual and semi-automatic tracing methods remain the state-of-the-art for creating accurate neuron reconstructions. We propose a new semi-automatic method that uses topological features to guide users in tracing neurons and integrate this method within a virtual reality (VR) framework previously used for manual tracing. Our approach augments both visualization and interaction with topological elements, allowing rapid understanding and tracing of complex morphologies. In our pilot study, neuroscientists demonstrated a strong preference for using our tool over prior approaches, reported less fatigue during tracing, and commended the ability to better understand possible paths and alternatives. Quantitative evaluation of the traces reveals that users' tracing speed increased, while retaining similar accuracy compared to a fully manual approach.",10.1109/TVCG.2020.3030363,,TRUE,TRUE,TRUE,T,,F,C2,KEEP,1,10. Healthcare and medical imaging,,Healthcare,0,1,1,1,1,1,1,1,0,0,1,2,5,1. domain expert,2,2. domain user,3,0,1,0,0,1,1,0,0,0,0,1,0,0,0,0,1,1,1,0,1,0,1,0,0,1,0,4. After the deployment,0,,
,,2020J046,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,5. no participant,0,,,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,4. After the deployment,0,,
261,94,2020J047,InCorr: Interactive Data-Driven Correlation Panels for Digital Outcrop Analysis,"Ortner, Thomas and Walch, Andreas and Nowak, Rebecca and Barnes, Robert and HÃ¶llt, Thomas and GrÃ¶ller, M. Eduard",2020,2021,Correlation;Three-dimensional displays;Tools;Geologic measurements;Rocks;Solid modeling;Geographic / geospatial visualization;remote sensing geology;digital outcrop analysis;integration of spatial and non-spatial data visualization,"Geological analysis of 3D Digital Outcrop Models (DOMs) for reconstruction of ancient habitable environments is a key aspect of the upcoming ESA ExoMars 2022 Rosalind Franklin Rover and the NASA 2020 Rover Perseverance missions in seeking signs of past life on Mars. Geologists measure and interpret 3D DOMs, create sedimentary logs and combine them in `correlation panels' to map the extents of key geological horizons, and build a stratigraphic model to understand their position in the ancient landscape. Currently, the creation of correlation panels is completely manual and therefore time-consuming, and inflexible. With InCorr we present a visualization solution that encompasses a 3D logging tool and an interactive data-driven correlation panel that evolves with the stratigraphic analysis. For the creation of InCorr we closely cooperated with leading planetary geologists in the form of a design study. We verify our results by recreating an existing correlation analysis with InCorr and validate our correlation panel against a manually created illustration. Further, we conducted a user-study with a wider circle of geologists. Our evaluation shows that InCorr efficiently supports the domain experts in tackling their research questions and that it has the potential to significantly impact how geologists work with digital outcrop representations in general.",10.1109/TVCG.2020.3030409,,TRUE,TRUE,TRUE,T,,T,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
455,346,2020J050,Interactive Visualization of Atmospheric Effects for Celestial Bodies,"Costa, Jonathas and Bock, Alexander and Emmart, Carter and Hansen, Charles and Ynnerman, Anders and Silva, ClÃ¡udio",2020,2021,Atmospheric modeling;Data visualization;Terrestrial atmosphere;Scattering;Atmospheric measurements;Real-time systems;Physical & Environmental Sciences;Engineering;Mathematics;Computer Graphics Techniques,"We present an atmospheric model tailored for the interactive visualization of planetary surfaces. As the exploration of the solar system is progressing with increasingly accurate missions and instruments, the faithful visualization of planetary environments is gaining increasing interest in space research, mission planning, and science communication and education. Atmospheric effects are crucial in data analysis and to provide contextual information for planetary data. Our model correctly accounts for the non-linear path of the light inside the atmosphere (in Earth's case), the light absorption effects by molecules and dust particles, such as the ozone layer and the Martian dust, and a wavelength-dependent phase function for Mie scattering. The mode focuses on interactivity, versatility, and customization, and a comprehensive set of interactive controls make it possible to adapt its appearance dynamically. We demonstrate our results using Earth and Mars as examples. However, it can be readily adapted for the exploration of other atmospheres found on, for example, of exoplanets. For Earth's atmosphere, we visually compare our results with pictures taken from the International Space Station and against the CIE clear sky model. The Martian atmosphere is reproduced based on available scientific data, feedback from domain experts, and is compared to images taken by the Curiosity rover. The work presented here has been implemented in the OpenSpace system, which enables interactive parameter setting and real-time feedback visualization targeting presentations in a wide range of environments, from immersive dome theaters to virtual reality headsets.",10.1109/TVCG.2020.3030333,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
263,95,2020J053,Towards Better Bus Networks: A Visual Analytics Approach,"Weng, Di and Zheng, Chengbo and Deng, Zikun and Ma, Mingze and Bao, Jie and Zheng, Yu and Xu, Mingliang and Wu, Yingcai",2020,2021,Visual analytics;Planning;Transportation;Data visualization;Decision making;Urban areas;Knowledge engineering;Bus route planning;spatial decision-making;urban data visual analytics,"Bus routes are typically updated every 3-5 years to meet constantly changing travel demands. However, identifying deficient bus routes and finding their optimal replacements remain challenging due to the difficulties in analyzing a complex bus network and the large solution space comprising alternative routes. Most of the automated approaches cannot produce satisfactory results in real-world settings without laborious inspection and evaluation of the candidates. The limitations observed in these approaches motivate us to collaborate with domain experts and propose a visual analytics solution for the performance analysis and incremental planning of bus routes based on an existing bus network. Developing such a solution involves three major challenges, namely, a) the in-depth analysis of complex bus route networks, b) the interactive generation of improved route candidates, and c) the effective evaluation of alternative bus routes. For challenge a, we employ an overview-to-detail approach by dividing the analysis of a complex bus network into three levels to facilitate the efficient identification of deficient routes. For challenge b, we improve a route generation model and interpret the performance of the generation with tailored visualizations. For challenge c, we incorporate a conflict resolution strategy in the progressive decision-making process to assist users in evaluating the alternative routes and finding the most optimal one. The proposed system is evaluated with two usage scenarios based on real-world data and received positive feedback from the experts.",10.1109/TVCG.2020.3030458,,TRUE,TRUE,TRUE,T,T,F,C2,KEEP,1,18. Transportation and mobility,9. Geosciences and geospatial data,"transportation, traffic management",0,1,1,1,1,1,1,1,0,0,0,1,4,1. domain expert,4,,,1,1,0,0,0,1,0,0,0,0,1,0,0,1,1,0,1,1,0,0,0,0,0,0,0,0,4. After the deployment,0,,
266,96,2020J055,Revisiting the Modifiable Areal Unit Problem in Deep Traffic Prediction with Visual Analytics,"Zeng, Wei and Lin, Chengqiao and Lin, Juncong and Jiang, Jincheng and Xia, Jiazhi and Turkay, Cagatay and Chen, Wei",2020,2021,Predictive models;Visual analytics;Data visualization;Analytical models;Uncertainty;Perturbation methods;MAUP;traffic prediction;deep learning;model diagnostic;visual analytics,"Deep learning methods are being increasingly used for urban traffic prediction where spatiotemporal traffic data is aggregated into sequentially organized matrices that are then fed into convolution-based residual neural networks. However, the widely known modifiable areal unit problem within such aggregation processes can lead to perturbations in the network inputs. This issue can significantly destabilize the feature embeddings and the predictions - rendering deep networks much less useful for the experts. This paper approaches this challenge by leveraging unit visualization techniques that enable the investigation of many-to-many relationships between dynamically varied multi-scalar aggregations of urban traffic data and neural network predictions. Through regular exchanges with a domain expert, we design and develop a visual analytics solution that integrates 1) a Bivariate Map equipped with an advanced bivariate colormap to simultaneously depict input traffic and prediction errors across space, 2) a Moran's I Scatterplot that provides local indicators of spatial association analysis, and 3) a Multi-scale Attribution View that arranges non-linear dot plots in a tree layout to promote model analysis and comparison across scales. We evaluate our approach through a series of case studies involving a real-world dataset of Shenzhen taxi trips, and through interviews with domain experts. We observe that geographical scale variations have important impact on prediction performances, and interactive visual exploration of dynamically varying inputs and outputs benefit experts in the development of deep traffic prediction models.",10.1109/TVCG.2020.3030410,,TRUE,TRUE,TRUE,T,T,F,C1,KEEP,1,18. Transportation and mobility,,"transportation, traffic management",0,1,1,1,1,1,1,1,0,0,0,2,3,1. domain expert,2,,,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,4. After the deployment,0,,
,,2020J055,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,1,,,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,4. After the deployment,0,,
267,97,2020J056,TaxThemis: Interactive Mining and Exploration of Suspicious Tax Evasion Groups,"Lin, Yating and Wong, Kamkwai and Wang, Yong and Zhang, Rong and Dong, Bo and Qu, Huamin and Zheng, Qinghua",2020,2021,Finance;Data visualization;Visual analytics;Bars;Network topology;Investment;Visual Analytics;Tax Network;Tax Evasion Detection;Anomaly detection;Multidimensional data,"Tax evasion is a serious economic problem for many countries, as it can undermine the government's tax system and lead to an unfair business competition environment. Recent research has applied data analytics techniques to analyze and detect tax evasion behaviors of individual taxpayers. However, they have failed to support the analysis and exploration of the related party transaction tax evasion (RPTTE) behaviors (e.g., transfer pricing), where a group of taxpayers is involved. In this paper, we present TaxThemis, an interactive visual analytics system to help tax officers mine and explore suspicious tax evasion groups through analyzing heterogeneous tax-related data. A taxpayer network is constructed and fused with the respective trade network to detect suspicious RPTTE groups. Rich visualizations are designed to facilitate the exploration and investigation of suspicious transactions between related taxpayers with profit and topological data analysis. Specifically, we propose a calendar heatmap with a carefully-designed encoding scheme to intuitively show the evidence of transferring revenue through related party transactions. We demonstrate the usefulness and effectiveness of TaxThemis through two case studies on real-world tax-related data and interviews with domain experts.",10.1109/TVCG.2020.3030370,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,3. Business and finance,,,0,1,1,1,1,1,1,1,0,0,0,1,2,1. domain expert,2,,,0,0,0,0,0,1,0,0,0,0,1,0,0,0,1,0,0,1,0,0,1,0,0,0,0,0,4. After the deployment,0,,
268,98,2020J057,ShuttleSpace: Exploring and Analyzing Movement Trajectory in Immersive Visualization,"Ye, Shuainan and Chen, Zhutian and Chu, Xiangtong and Wang, Yifan and Fu, Siwei and Shen, Lejun and Zhou, Kun and Wu, Yingcai",2020,2021,Trajectory;Three-dimensional displays;Sports;Data visualization;Two dimensional displays;Visualization;Games;Movement trajectory;badminton analytics;virtual reality,"We present ShuttleSpace, an immersive analytics system to assist experts in analyzing trajectory data in badminton. Trajectories in sports, such as the movement of players and balls, contain rich information on player behavior and thus have been widely analyzed by coaches and analysts to improve the players' performance. However, existing visual analytics systems often present the trajectories in court diagrams that are abstractions of reality, thereby causing difficulty for the experts to imagine the situation on the court and understand why the player acted in a certain way. With recent developments in immersive technologies, such as virtual reality (VR), experts gradually have the opportunity to see, feel, explore, and understand these 3D trajectories from the player's perspective. Yet, few research has studied how to support immersive analysis of sports data from such a perspective. Specific challenges are rooted in data presentation (e.g., how to seamlessly combine 2D and 3D visualizations) and interaction (e.g., how to naturally interact with data without keyboard and mouse) in VR. To address these challenges, we have worked closely with domain experts who have worked for a top national badminton team to design ShuttleSpace. Our system leverages 1) the peripheral vision to combine the 2D and 3D visualizations and 2) the VR controller to support natural interactions via a stroke metaphor. We demonstrate the effectiveness of ShuttleSpace through three case studies conducted by the experts with useful insights. We further conduct interviews with the experts whose feedback confirms that our first-person immersive analytics system is suitable and useful for analyzing badminton data.",10.1109/TVCG.2020.3030392,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,17. Sports and entertainment,,,0,1,1,1,1,1,1,1,0,0,1,1,4,1. domain expert,4,,,0,0,0,0,0,1,0,0,0,0,1,0,0,0,1,0,0,1,0,0,1,0,0,0,0,0,4. After the deployment,0,,
278,99,2020J058,QLens: Visual Analytics of MUlti-step Problem-solving Behaviors for Improving Question Design,"Xia, Meng and Velumani, Reshika Palaniyappan and Wang, Yong and Qu, Huamin and Ma, Xiaojuan",2020,2021,Problem-solving;Hidden Markov models;Visual analytics;Data visualization;Task analysis;Programming;Learning Behavior Analysis;Visual Analytics;Time Series Data,"With the rapid development of online education in recent years, there has been an increasing number of learning platforms that provide students with multi-step questions to cultivate their problem-solving skills. To guarantee the high quality of such learning materials, question designers need to inspect how students' problem-solving processes unfold step by step to infer whether students' problem-solving logic matches their design intent. They also need to compare the behaviors of different groups (e.g., students from different grades) to distribute questions to students with the right level of knowledge. The availability of fine-grained interaction data, such as mouse movement trajectories from the online platforms, provides the opportunity to analyze problem-solving behaviors. However, it is still challenging to interpret, summarize, and compare the high dimensional problem-solving sequence data. In this paper, we present a visual analytics system, QLens, to help question designers inspect detailed problem-solving trajectories, compare different student groups, distill insights for design improvements. In particular, QLens models problem-solving behavior as a hybrid state transition graph and visualizes it through a novel glyph-embedded Sankey diagram, which reflects students' problem-solving logic, engagement, and encountered difficulties. We conduct three case studies and three expert interviews to demonstrate the usefulness of QLens on real-world datasets that consist of thousands of problem-solving traces.",10.1109/TVCG.2020.3030337,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,5. Education and e-learning,,,0,1,1,1,1,1,1,1,0,0,0,2,7,1. domain expert,4,,,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,1. Before the deployment (General),0,,
,,2020J058,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,3,,,0,0,0,0,0,1,0,1,0,0,1,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,4. After the deployment,0,,
280,100,2020J059,Visilant: Visual Support for the Exploration and Analytical Process Tracking in Criminal Investigations,"ZÃ¡kopÄanovÃ¡, KristÃ­na and Å˜ehÃ¡Äek, Marko and BÃ¡trna, Jozef and Plakinger, Daniel and Stoppel, Sergej and KozlÃ­kovÃ¡, Barbora",2020,2021,Visualization;Tools;Collaboration;Data visualization;Databases;Cognition;Computer crime;Criminal investigation;visualization;network;exploration;interaction;tracking;diagram,"The daily routine of criminal investigators consists of a thorough analysis of highly complex and heterogeneous data of crime cases. Such data can consist of case descriptions, testimonies, criminal networks, spatial and temporal information, and virtually any other data that is relevant for the case. Criminal investigators work under heavy time pressure to analyze the data for relationships, propose and verify several hypotheses, and derive conclusions, while the data can be incomplete or inconsistent and is changed and updated throughout the investigation, as new findings are added to the case. Based on a four-year intense collaboration with criminalists, we present a conceptual design for a visual tool supporting the investigation workflow and Visilant, a web-based tool for the exploration and analysis of criminal data guided by the proposed design. Visilant aims to support namely the exploratory part of the investigation pipeline, from case overview, through exploration and hypothesis generation, to the case presentation. Visilant tracks the reasoning process and as the data is changing, it informs investigators which hypotheses are affected by the data change and should be revised. The tool was evaluated by senior criminology experts within two sessions and their feedback is summarized in the paper. Additional supplementary material contains the technical details and exemplary case study.",10.1109/TVCG.2020.3030356,,TRUE,TRUE,TRUE,T,T,F,C1,KEEP,1,16. Public safety and emergency management,,,0,0,1,1,1,1,1,1,0,0,0,2,2,1. domain expert,2,,,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,3. Before the deployment (During the development and refinement phrase ONLY),1,,
,,2020J059,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,2,,,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,4. After the deployment,0,,
281,101,2020J060,ChemVA: Interactive Visual Analysis of Chemical Compound Similarity in Virtual Screening,"Sabando, MarÃ­a Virginia and Ulbrich, Pavol and Selzer, MatÃ­as and ByÅ¡ka, Jan and MiÄan, Jan and Ponzoni, Ignacio and Soto, Axel J. and Ganuza, MarÃ­a LujÃ¡n and KozlÃ­kovÃ¡, Barbora",2020,2021,Tools;Compounds;Visualization;Two dimensional displays;Drugs;Three-dimensional displays;Chemicals;Virtual screening;visual analysis;dimensionality reduction;coordinated views;cheminformatics,"In the modern drug discovery process, medicinal chemists deal with the complexity of analysis of large ensembles of candidate molecules. Computational tools, such as dimensionality reduction (DR) and classification, are commonly used to efficiently process the multidimensional space of features. These underlying calculations often hinder interpretability of results and prevent experts from assessing the impact of individual molecular features on the resulting representations. To provide a solution for scrutinizing such complex data, we introduce ChemVA, an interactive application for the visual exploration of large molecular ensembles and their features. Our tool consists of multiple coordinated views: Hexagonal view, Detail view, 3D view, Table view, and a newly proposed Difference view designed for the comparison of DR projections. These views display DR projections combined with biological activity, selected molecular features, and confidence scores for each of these projections. This conjunction of views allows the user to drill down through the dataset and to efficiently select candidate compounds. Our approach was evaluated on two case studies of finding structurally similar ligands with similar binding affinity to a target protein, as well as on an external qualitative evaluation. The results suggest that our system allows effective visual inspection and comparison of different high-dimensional molecular representations. Furthermore, ChemVA assists in the identification of candidate compounds while providing information on the certainty behind different molecular representations.",10.1109/TVCG.2020.3030438,,TRUE,TRUE,TRUE,T,T,F,C1,KEEP,1,2. Biology and life sciences,,biochemical sciences,0,1,1,1,1,1,1,1,0,0,0,2,4,1. domain expert,1,,,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,4. After the deployment,0,,
,,2020J060,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,2,4. visual expert,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,4. After the deployment,0,,
,,2020J061,A Visualization Framework for Multi-scale Coherent Structures in Taylor-Couette Turbulence,"Nguyen, Duong B. and Monico, Rodolfo Ostilla and Chen, Guoning",2020,2021,Visualization;Three-dimensional displays;Two dimensional displays;Feature extraction;Periodic structures;Standards;Rendering (computer graphics);Flow visualization;Taylor-Couette turbulence;coherent structures,"Taylor-Couette flow (TCF) is the turbulent fluid motion created between two concentric and independently rotating cylinders. It has been heavily researched in fluid mechanics thanks to the various nonlinear dynamical phenomena that are exhibited in the flow. As many dense coherent structures overlap each other in TCF, it is challenging to isolate and visualize them, especially when the cylinder rotation ratio is changing. Previous approaches rely on 2D cross sections to study TCF due to its simplicity, which cannot provide the complete information of TCF. In the meantime, standard visualization techniques, such as volume rendering / iso-surfacing of certain attributes and the placement of integral curves/surfaces, usually produce cluttered visualization. To address this challenge and to support domain experts in the analysis of TCF, we developed a visualization framework to separate large-scale structures from the dense, small-scale structures and provide an effective visual representation of these structures. Instead of using a single physical attribute as the standard approach which cannot efficiently separate structures in different scales for TCF, we adapt the feature level-set method to combine multiple attributes and use them as a filter to separate large- and small-scale structures. To visualize these structures, we apply the iso-surface extraction on the kernel density estimate of the distance field generated from the feature level-set. The proposed methods successfully reveal 3D large-scale coherent structures of TCF with different control parameter settings, which are difficult to achieve with the conventional methods.",10.1109/TVCG.2020.3028892,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
282,102,2020J062,Chemicals in the Creek: designing a situated data physicalization of open government data with the community,"Perovich, Laura J. and Wylie, Sara Ann and Bongiovanni, Roseann",2020,2021,Data visualization;Oils;Government;Chemicals;Buildings;Green products;Collaboration;data physicalization;Participatory Action Research;water quality;environmental HCl,"Over the last decade growing amounts of government data have been made available in an attempt to increase transparency and civic participation, but it is unclear if this data serves non-expert communities due to gaps in access and the technical knowledge needed to interpret this â€œopenâ€ data. We conducted a two-year design study focused on the creation of a community-based data display using the United States Environmental Protection Agency data on water permit violations by oil storage facilities on the Chelsea Creek in Massachusetts to explore whether situated data physicalization and Participatory Action Research could support meaningful engagement with open data. We selected this data as it is of interest to local groups and available online, yet remains largely invisible and inaccessible to the Chelsea community. The resulting installation, Chemicals in the Creek, responds to the call for community-engaged visualization processes and provides an application of situated methods of data representation. It proposes event-centered and power-aware modes of engagement using contextual and embodied data representations. The design of Chemicals in the Creek is grounded in interactive workshops and we analyze it through event observation, interviews, and community outcomes. We reflect on the role of community engaged research in the Information Visualization community relative to recent conversations on new approaches to design studies and evaluation.",10.1109/TVCG.2020.3030472,,TRUE,TRUE,TRUE,T,,T,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
286,103,2020J063,Designing Narrative-Focused Role-Playing Games for Visualization Literacy in Young Children,"Huynh, Elaine and Nyhout, Angela and Ganea, Patricia and Chevalier, Fanny",2020,2021,Data visualization;Games;Education;Visualization;Computer science;Tools;Probes;Visualization Literacy;Educational technology;Gamification;Narrative,"Building on game design and education research, this paper introduces narrative-focused role-playing games as a way to promote visualization literacy in young children. Visualization literacy skills are vital in understanding the world around us and constructing meaningful visualizations, yet, how to better develop these skills at an early age remains largely overlooked and understudied. Only recently has the visualization community started to fill this gap, resulting in preliminary studies and development of educational tools for use in early education. We add to these efforts through the exploration of gamification to support learning, and identify an opportunity to apply role-playing game-based designs by leveraging the presence of narratives in data-related problems involving visualizations. We study the effects of including narrative elements on learning through a technology probe, grounded in a set of design considerations stemming from visualization, game design and education science. We create two versions of a game - one with narrative elements and one without - and evaluate our instances on 33 child participants between 11- to 13-years old using a between-subjects study design. Despite participants requiring double the amount of time to complete their game due to additional narrative elements, the inclusion of such elements were found to improve engagement without sacrificing learning; our results indicate no significant differences in development of graph-reading skills, but significant differences in engagement and overall enjoyment of the game. We report observations and qualitative feedback collected, and note areas for improvement and room for future work.",10.1109/TVCG.2020.3030464,,TRUE,TRUE,TRUE,T,,F,C1,DROP-empirical study,0,5. Education and e-learning,,visualization literacy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
553,347,2020J066,Table Scraps: An Actionable Framework for Multi-Table Data Wrangling From An Artifact Study of Computational Journalism,"Kasica, Stephen and Berret, Charles and Munzner, Tamara",2020,2021,Journalism;Taxonomy;Tools;Data analysis;Encoding;Task analysis;Cleaning;Computational journalism;Data journalism;Data wrangling,"For the many journalists who use data and computation to report the news, data wrangling is an integral part of their work. Despite an abundance of literature on data wrangling in the context of enterprise data analysis, little is known about the specific operations, processes, and pain points journalists encounter while performing this tedious, time-consuming task. To better understand the needs of this user group, we conduct a technical observation study of 50 public repositories of data and analysis code authored by 33 professional journalists at 26 news organizations. We develop two detailed and cross-cutting taxonomies of data wrangling in computational journalism, for actions and for processes. We observe the extensive use of multiple tables, a notable gap in previous wrangling analyses. We develop a concise, actionable framework for general multi-table data wrangling that includes wrangling operations documented in our taxonomy that are without clear parallels in other work. This framework, the first to incorporate tables as first-class objects, will support future interactive wrangling tools for both computational journalism and general-purpose use. We assess the generative and descriptive power of our framework through discussion of its relationship to our set of taxonomies.",10.1109/TVCG.2020.3030462,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2020J070,Towards Modeling Visualization Processes as Dynamic Bayesian Networks,"Heine, Christian",2020,2021,Visualization;Computational modeling;Mathematical model;Task analysis;Predictive models;Guidelines;Cognition;Visualization;model building;perception;cognition;dynamic Bayesian networks,"Visualization designs typically need to be evaluated with user studies, because their suitability for a particular task is hard to predict. What the field of visualization is currently lacking are theories and models that can be used to explain why certain designs work and others do not. This paper outlines a general framework for modeling visualization processes that can serve as the first step towards such a theory. It surveys related research in mathematical and computational psychology and argues for the use of dynamic Bayesian networks to describe these time-dependent, probabilistic processes. It is discussed how these models could be used to aid in design evaluation. The development of concrete models will be a long process. Thus, the paper outlines a research program sketching how to develop prototypes and their extensions from existing models, controlled experiments, and observational studies.",10.1109/TVCG.2020.3030395,,TRUE,TRUE,TRUE,T,T,F,C1,DROP-theory,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
287,104,2020J074,A Testing Environment for Continuous Colormaps,"Nardini, P. and Chen, M. and Bujack, R. and Bottinger, M. and Scheuermann, G.",2020,2021,Image color analysis;Data visualization;Task analysis;Optimization;Computer science;Natural language processing;Visualization;Testing Environment;Color Perception;Scalar Analysis,"Many computer science disciplines (e.g., combinatorial optimization, natural language processing, and information retrieval) use standard or established test suites for evaluating algorithms. In visualization, similar approaches have been adopted in some areas (e.g., volume visualization), while user testimonies and empirical studies have been the dominant means of evaluation in most other areas, such as designing colormaps. In this paper, we propose to establish a test suite for evaluating the design of colormaps. With such a suite, the users can observe the effects when different continuous colormaps are applied to planar scalar fields that may exhibit various characteristic features, such as jumps, local extrema, ridge or valley lines, different distributions of scalar values, different gradients, different signal frequencies, different levels of noise, and so on. The suite also includes an expansible collection of real-world data sets including the most popular data for colormap testing in the visualization literature. The test suite has been integrated into a web-based application for creating continuous colormaps (https://ccctool.com/), facilitating close inter-operation between design and evaluation processes. This new facility complements traditional evaluation methods such as user testimonies and empirical studies.",10.1109/TVCG.2020.3028955,,TRUE,TRUE,TRUE,T,,F,C1,DROP,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
570,348,2020J076,No mark is an island: Precision and category repulsion biases in data reproductions,"McColeman, Caitlyn M. and Harrison, Lane and Feng, Mi and Franconeri, Steven",2020,2021,Bars;Visualization;Data visualization;Task analysis;Particle measurements;Atmospheric measurements;Semantics;Cognition and perception;Graphical perception;Perceptual biases;Ratio perception,"Data visualization is powerful in large part because it facilitates visual extraction of values. Yet, existing measures of perceptual precision for data channels (e.g., position, length, orientation, etc.) are based largely on verbal reports of ratio judgments between two values (e.g., [7]). Verbal report conflates multiple sources of error beyond actual visual precision, introducing a ratio computation between these values and a requirement to translate that ratio to a verbal number. Here we observe raw measures of precision by eliminating both ratio computations and verbal reports; we simply ask participants to reproduce marks (a single bar or dot) to match a previously seen one. We manipulated whether the mark was initially presented (and later drawn) alone, paired with a reference (e.g. a second `100%' bar also present at test, or a y-axis for the dot), or integrated with the reference (merging that reference bar into a stacked bar graph, or placing the dot directly on the axis). Reproductions of smaller values were overestimated, and larger values were underestimated, suggesting systematic memory biases. Average reproduction error was around 10% of the actual value, regardless of whether the reproduction was done on a common baseline with the original. In the reference and (especially) the integrated conditions, responses were repulsed from an implicit midpoint of the reference mark, such that values above 50% were overestimated, and values below 50% were underestimated. This reproduction paradigm may serve within a new suite of more fundamental measures of the precision of graphical perception.",10.1109/TVCG.2020.3030345,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
588,349,2020J078,Introducing Layers of Meaning (LoM): A Framework to Reduce Semantic Distance of Visualization In Humanistic Research,"Lamqaddam, Houda and Vande Moere, Andrew and Vanden Abeele, Vero and Brosens, Koenraad and Verbert, Katrien",2020,2021,Tools;Data visualization;Conferences;Task analysis;Guidelines;Collaboration;Semantics;Infovis;Humanities;Digital Humanities,"Information visualization (infovis) is a powerful tool for exploring rich datasets. Within humanistic research, rich qualitative data and domain culture make traditional infovis approaches appear reductive and disconnected, leading to low adoption. In this paper, we use a multi-step approach to scrutinize the relationship between infovis and the humanities and suggest new directions for it. We first look into infovis from the humanistic perspective by exploring the humanistic literature around infovis. We validate and expand those findings though a co-design workshop with humanist and infovis experts. Then, we translate our findings into guidelines for designers and conduct a design critique exercise to explore their effect on the perception of humanist researchers. Based on these steps, we introduce Layers of Meaning, a framework to reduce the semantic distance between humanist researchers and visualizations of their research material, by grounding infovis tools in time and space, physicality, terminology, nuance, and provenance.",10.1109/TVCG.2020.3030426,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
595,350,2020J082,A Structured Review of Data Management Technology for Interactive Visualization and Analysis,"Battle, Leilani and Scheidegger, Carlos",2020,2021,Data visualization;Optimization;Encoding;Visual databases;Visualization;Task analysis,"In the last two decades, interactive visualization and analysis have become a central tool in data-driven decision making. Concurrently to the contributions in data visualization, research in data management has produced technology that directly benefits interactive analysis. Here, we contribute a systematic review of 30 years of work in this adjacent field, and highlight techniques and principles we believe to be underappreciated in visualization work. We structure our review along two axes. First, we use task taxonomies from the visualization literature to structure the space of interactions in usual systems. Second, we created a categorization of data management work that strikes a balance between specificity and generality. Concretely, we contribute a characterization of 131 research papers along these two axes. We find that five notions in data management venues fit interactive visualization systems well: materialized views, approximate query processing, user modeling and query prediction, muiti-query optimization, lineage techniques, and indexing techniques. In addition, we find a preponderance of work in materialized views and approximate query processing, most targeting a limited subset of the interaction tasks in the taxonomy we used. This suggests natural avenues of future research both in visualization and data management. Our categorization both changes how we visualization researchers design and build our systems, and highlights where future work is necessary.",10.1109/TVCG.2020.3028891,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
293,105,2020J083,Visual Analysis of Argumentation in Essays,"Kiesel, Dora and Riehmann, Patrick and Wachsmuth, Henning and Stein, Benno and Froehlich, Bernd",2020,2021,Task analysis;Annotations;Skin;Visual analytics;Histograms;Data visualization;Information Visualization;Text Analysis;User Interfaces;Visual Analytics;Argumentation Visualization;Glyph-based Techniques;Text and Document Data;Tree-based Visualization;Coordinated and Multiple Views;Close and Distant Reading,"This paper presents a visual analytics system for exploring, analyzing and comparing argument structures in essay corpora. We provide an overview of the corpus by a list of ArguLines which represent the argument units of each essay by a sequence of glyphs. Each glyph encodes the stance, the depth and the relative position of an argument unit. The overview can be ordered in various ways to reveal patterns and outliers. Subsets of essays can be selected and analyzed in detail using the Argument Unit Occurrence Tree which aggregates the argument structures using hierarchical histograms. This hierarchical view facilitates the estimation of statistics and trends concerning the progression of the argumentation in the essays. It also provides insights into the commonalities and differences between selected subsets. The text view is the necessary textual basis to verify conclusions from the other views and the annotation process. Linking the views and interaction techniques for visual filtering, studying the evolution of stance within a subset of essays and scrutinizing the order of argumentative units enable a deep analysis of essay corpora. Our expert reviews confirmed the utility of the system and revealed detailed and previously unknown information about the argumentation in our sample corpus.",10.1109/TVCG.2020.3030425,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,,,,1,1,1,0,1,1,1,1,0,0,0,2,5,1. domain expert,2,,,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,3. Before the deployment (During the development and refinement phrase ONLY),1,,
,,2020J083,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,3,,,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,4. After the deployment,0,,
598,351,2020J085,Attention Flows: Analyzing and Comparing Attention Mechanisms in Language Models,"DeRose, Joseph F. and Wang, Jiayao and Berger, Matthew",2020,2021,Task analysis;Analytical models;Bit error rate;Computational modeling;Visual analytics;Natural language processing;NLP;Transformer;Visual Analytics,"Advances in language modeling have led to the development of deep attention-based models that are performant across a wide variety of natural language processing (NLP) problems. These language models are typified by a pre-training process on large unlabeled text corpora and subsequently fine-tuned for specific tasks. Although considerable work has been devoted to understanding the attention mechanisms of pre-trained models, it is less understood how a model's attention mechanisms change when trained for a target NLP task. In this paper, we propose a visual analytics approach to understanding fine-tuning in attention-based language models. Our visualization, Attention Flows, is designed to support users in querying, tracing, and comparing attention within layers, across layers, and amongst attention heads in Transformer-based language models. To help users gain insight on how a classification decision is made, our design is centered on depicting classification-based attention at the deepest layer and how attention from prior layers flows throughout words in the input. Attention Flows supports the analysis of a single model, as well as the visual comparison between pre-trained and fine-tuned models via their similarities and differences. We use Attention Flows to study attention mechanisms in various sentence understanding tasks and highlight how attention evolves to address the nuances of solving these tasks.",10.1109/TVCG.2020.3028976,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
668,352,2020J086,Shared Surfaces and Spaces: Collaborative Data Visualisation in a Co-located Immersive Environment,"Lee, Benjamin and Hu, Xiaoyun and Cordeil, Maxime and Prouzeau, Arnaud and Jenny, Bernhard and Dwyer, Tim",2020,2021,Data visualization;Collaboration;Three-dimensional displays;Task analysis;Two dimensional displays;Microsoft Windows;Virtual environments;Immersive analytics;collaboration;virtual reality;qualitative study;multivariate data,"Immersive technologies offer new opportunities to support collaborative visual data analysis by providing each collaborator a personal, high-resolution view of a flexible shared visualisation space through a head mounted display. However, most prior studies of collaborative immersive analytics have focused on how groups interact with surface interfaces such as tabletops and wall displays. This paper reports on a study in which teams of three co-located participants are given flexible visualisation authoring tools to allow a great deal of control in how they structure their shared workspace. They do so using a prototype system we call FIESTA: the Free-roaming Immersive Environment to Support Team-based Analysis. Unlike traditional visualisation tools, FIESTA allows users to freely position authoring interfaces and visualisation artefacts anywhere in the virtual environment, either on virtual surfaces or suspended within the interaction space. Our participants solved visual analytics tasks on a multivariate data set, doing so individually and collaboratively by creating a large number of 2D and 3D visualisations. Their behaviours suggest that the usage of surfaces is coupled with the type of visualisation used, often using walls to organise 2D visualisations, but positioning 3D visualisations in the space around them. Outside of tightly-coupled collaboration, participants followed social protocols and did not interact with visualisations that did not belong to them even if outside of its owner's personal workspace.",10.1109/TVCG.2020.3030450,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2020J087,Personal Augmented Reality for Information Visualization on Large Interactive Displays,"Reipschlager, Patrick and Flemisch, Tamara and Dachselt, Raimund",2020,2021,Data visualization;Data analysis;Augmented reality;Three-dimensional displays;Navigation;Visualization;Augmented Reality;Information Visualization;InfoVis;Large Displays;Immersive Analytics;Physical Navigation;Multiple Coordinated Views,"In this work we propose the combination of large interactive displays with personal head-mounted Augmented Reality (AR) for information visualization to facilitate data exploration and analysis. Even though large displays provide more display space, they are challenging with regard to perception, effective multi-user support, and managing data density and complexity. To address these issues and illustrate our proposed setup, we contribute an extensive design space comprising first, the spatial alignment of display, visualizations, and objects in AR space. Next, we discuss which parts of a visualization can be augmented. Finally, we analyze how AR can be used to display personal views in order to show additional information and to minimize the mutual disturbance of data analysts. Based on this conceptual foundation, we present a number of exemplary techniques for extending visualizations with AR and discuss their relation to our design space. We further describe how these techniques address typical visualization problems that we have identified during our literature research. To examine our concepts, we introduce a generic AR visualization framework as well as a prototype implementing several example techniques. In order to demonstrate their potential, we further present a use case walkthrough in which we analyze a movie data set. From these experiences, we conclude that the contributed techniques can be useful in exploring and understanding multivariate data. We are convinced that the extension of large displays with AR for information visualization has a great potential for data analysis and sense-making.",10.1109/TVCG.2020.3030460,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
299,106,2020J088,Uplift: A Tangible and Immersive Tabletop System for Casual Collaborative Visual Analytics,"Ens, Barrett and Goodwin, Sarah and Prouzeau, Arnaud and Anderson, Fraser and Wang, Florence Y. and Gratzl, Samuel and Lucarelli, Zac and Moyle, Brendan and Smiley, Jim and Dwyer, Tim",2020,2021,Collaboration;Data visualization;Three-dimensional displays;Visual analytics;Stakeholders;Microgrids;Smart grids;Data visualisation;tangible and embedded interaction;augmented reality;immersive analytics,"Collaborative visual analytics leverages social interaction to support data exploration and sensemaking. These processes are typically imagined as formalised, extended activities, between groups of dedicated experts, requiring expertise with sophisticated data analysis tools. However, there are many professional domains that benefit from support for short 'bursts' of data exploration between a subset of stakeholders with a diverse breadth of knowledge. Such 'casual collaborative' scenarios will require engaging features to draw users' attention, with intuitive, 'walk-up and use' interfaces. This paper presents Uplift, a novel prototype system to support 'casual collaborative visual analytics' for a campus microgrid, co-designed with local stakeholders. An elicitation workshop with key members of the building management team revealed relevant knowledge is distributed among multiple experts in their team, each using bespoke analysis tools. Uplift combines an engaging 3D model on a central tabletop display with intuitive tangible interaction, as well as augmented-reality, mid-air data visualisation, in order to support casual collaborative visual analytics for this complex domain. Evaluations with expert stakeholders from the building management and energy domains were conducted during and following our prototype development and indicate that Uplift is successful as an engaging backdrop for casual collaboration. Experts see high potential in such a system to bring together diverse knowledge holders and reveal complex interactions between structural, operational, and financial aspects of their domain. Such systems have further potential in other domains that require collaborative discussion or demonstration of models, forecasts, or cost-benefit analyses to high-level stakeholders.",10.1109/TVCG.2020.3030334,,TRUE,TRUE,TRUE,T,T,F,C1,KEEP,1,,,,1,1,1,1,1,1,1,1,0,0,1,3,14,1. domain expert,7,4. visual expert,3,1,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,2. Before the deployment (Before or during design phase ONLY),0,,
,,2020J088,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,7,,,0,0,0,1,0,1,0,0,0,0,1,1,0,0,0,1,0,1,1,0,0,0,0,0,0,0,3. Before the deployment (During the development and refinement phrase ONLY),1,,
,,2020J088,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,4,,,0,0,0,1,0,1,0,0,0,0,1,1,0,0,0,1,0,1,1,0,0,0,0,0,0,0,3. Before the deployment (During the development and refinement phrase ONLY),0,,
706,353,2020J090,Embodied Navigation in Immersive Abstract Data Visualization: Is Overview+Detail or Zooming Better for 3D Scatterplots?,"Yang, Yalong and Cordeil, Maxime and Beyer, Johanna and Dwyer, Tim and Marriott, Kim and Pfister, Hanspeter",2020,2021,Navigation;Data visualization;Three-dimensional displays;Legged locomotion;Task analysis;Standards;Two dimensional displays;Immersive Analytics;Information Visualization;Virtual Reality;Navigation;Overview+Detail;Zooming;Scatterplot,"Abstract data has no natural scale and so interactive data visualizations must provide techniques to allow the user to choose their viewpoint and scale. Such techniques are well established in desktop visualization tools. The two most common techniques are zoom+pan and overview+detail. However, how best to enable the analyst to navigate and view abstract data at different levels of scale in immersive environments has not previously been studied. We report the findings of the first systematic study of immersive navigation techniques for 3D scatterplots. We tested four conditions that represent our best attempt to adapt standard 2D navigation techniques to data visualization in an immersive environment while still providing standard immersive navigation techniques through physical movement and teleportation. We compared room-sized visualization versus a zooming interface, each with and without an overview. We find significant differences in participants' response times and accuracy for a number of standard visual analysis tasks. Both zoom and overview provide benefits over standard locomotion support alone (i.e., physical movement and pointer teleportation). However, which variation is superior, depends on the task. We obtain a more nuanced understanding of the results by analyzing them in terms of a time-cost model for the different components of navigation: way-finding, travel, number of travel steps, and context switching.",10.1109/TVCG.2020.3030427,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
300,107,2020J093,Zoomless Maps: External Labeling Methods for the Interactive Exploration of Dense Point Sets at a Fixed Map Scale,"Gedicke, Sven and Bonerath, Annika and Niedermann, Benjamin and Haunert, Jan-Henrik",2020,2021,Labeling;Optimization;Stacking;Navigation;Task analysis;Smart phones;Tools;external labeling;interactive maps;map exploration;small screens;algorithms;optimization,"Visualizing spatial data on small-screen devices such as smartphones and smartwatches poses new challenges in computational cartography. The current interfaces for map exploration require their users to zoom in and out frequently. Indeed, zooming and panning are tools suitable for choosing the map extent corresponding to an area of interest. They are not as suitable, however, for resolving the graphical clutter caused by a high feature density since zooming in to a large map scale leads to a loss of context. Therefore, in this paper, we present new external labeling methods that allow a user to navigate through dense sets of points of interest while keeping the current map extent fixed. We provide a unified model, in which labels are placed at the boundary of the map and visually associated with the corresponding features via connecting lines, which are called leaders. Since the screen space is limited, labeling all features at the same time is impractical. Therefore, at any time, we label a subset of the features. We offer interaction techniques to change the current selection of features systematically and, thus, give the user access to all features. We distinguish three methods, which allow the user either to slide the labels along the bottom side of the map or to browse the labels based on pages or stacks. We present a generic algorithmic framework that provides us with the possibility of expressing the different variants of interaction techniques as optimization problems in a unified way. We propose both exact algorithms and fast and simple heuristics that solve the optimization problems taking into account different criteria such as the ranking of the labels, the total leader length as well as the distance between leaders. In experiments on real-world data we evaluate these algorithms and discuss the three variants with respect to their strengths and weaknesses proving the flexibility of the presented algorithmic framework.",10.1109/TVCG.2020.3030399,,TRUE,TRUE,TRUE,T,,F,C1,DROP-algorithm,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
302,108,2020J099,Interactive Visual Study of Multiple Attributes Learning Model of X-Ray Scattering Images,"Huang, Xinyi and Jamonnak, Suphanut and Zhao, Ye and Wang, Boyu and Hoai, Minh and Yager, Kevin and Xu, Wei",2020,2021,X-ray scattering;Deep learning;Visualization;Tools;Computational modeling;X-ray imaging;Aerospace electronics,"Existing interactive visualization tools for deep learning are mostly applied to the training, debugging, and refinement of neural network models working on natural images. However, visual analytics tools are lacking for the specific application of x-ray image classification with multiple structural attributes. In this paper, we present an interactive system for domain scientists to visually study the multiple attributes learning models applied to x-ray scattering images. It allows domain scientists to interactively explore this important type of scientific images in embedded spaces that are defined on the model prediction output, the actual labels, and the discovered feature space of neural networks. Users are allowed to flexibly select instance images, their clusters, and compare them regarding the specified visual representation of attributes. The exploration is guided by the manifestation of model performance related to mutual relationships among attributes, which often affect the learning accuracy and effectiveness. The system thus supports domain scientists to improve the training dataset and model, find questionable attributes labels, and identify outlier images or spurious data clusters. Case studies and scientists feedback demonstrate its functionalities and usefulness.",10.1109/TVCG.2020.3030384,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,14. Materials science and nanotechnology,1. AI (Machine Learning/Deep Learning/Data Mining),physical and material sciences,0,1,1,1,1,1,1,1,1,0,0,2,13,1. domain expert,2,,,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,1,0,0,1,0,0,0,0,0,4. After the deployment,0,,
,,2020J099,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,2. domain user,11,,,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,4. After the deployment,0,,
707,354,2020J100,PassVizor: Toward Better Understanding of the Dynamics of Soccer Passes,"Xie, Xiao and Wang, Jiachen and Liang, Hongye and Deng, Dazhen and Cheng, Shoubin and Zhang, Hui and Chen, Wei and Wu, Yingcai",2020,2021,Sports;Visual analytics;Data visualization;Interviews;Pattern matching;Navigation;Soccer Analysis;Passing Analysis,"In soccer, passing is the most frequent interaction between players and plays a significant role in creating scoring chances. Experts are interested in analyzing players' passing behavior to learn passing tactics, i.e., how players build up an attack with passing. Various approaches have been proposed to facilitate the analysis of passing tactics. However, the dynamic changes of a team's employed tactics over a match have not been comprehensively investigated. To address the problem, we closely collaborate with domain experts and characterize requirements to analyze the dynamic changes of a team's passing tactics. To characterize the passing tactic employed for each attack, we propose a topic-based approach that provides a high-level abstraction of complex passing behaviors. Based on the model, we propose a glyph-based design to reveal the multi-variate information of passing tactics within different phases of attacks, including player identity, spatial context, and formation. We further design and develop PassVizor, a visual analytics system, to support the comprehensive analysis of passing dynamics. With the system, users can detect the changing patterns of passing tactics and examine the detailed passing process for evaluating passing tactics. We invite experts to conduct analysis with PassVizor and demonstrate the usability of the system through an expert interview.",10.1109/TVCG.2020.3030359,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
303,109,2020J101,Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality,"Choudhry, Arjun and Sharma, Mandar and Chundury, Pramod and Kapler, Thomas and Gray, Derek W. S. and Ramakrishnan, Naren and Elmqvist, Niklas",2020,2021,Data visualization;Visualization;Natural languages;Pipelines;Task analysis;Correlation;Tools;Causality visualization;natural language generation;data-driven storytelling;temporal data;quantitative studies,"Causality visualization can help people understand temporal chains of events, such as messages sent in a distributed system, cause and effect in a historical conflict, or the interplay between political actors over time. However, as the scale and complexity of these event sequences grows, even these visualizations can become overwhelming to use. In this paper, we propose the use of textual narratives as a data-driven storytelling method to augment causality visualization. We first propose a design space for how textual narratives can be used to describe causal data. We then present results from a crowdsourced user study where participants were asked to recover causality information from two causality visualizations-causal graphs and Hasse diagrams-with and without an associated textual narrative. Finally, we describe Causeworks, a causality visualization system for understanding how specific interventions influence a causal model. The system incorporates an automatic textual narrative mechanism based on our design space. We validate Causeworks through interviews with experts who used the system for understanding complex events.",10.1109/TVCG.2020.3030358,,TRUE,TRUE,TRUE,,T,F,C1,DROP-empirical study,0,,,,1,0,1,1,0,0,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
304,110,2020J102,Visual Causality Analysis of Event Sequence Data,"Jin, Zhuochen and Guo, Shunan and Chen, Nan and Weiskopf, Daniel and Gotz, David and Cao, Nan",2020,2021,Analytical models;Visual analytics;Data visualization;Data models;Layout;Computational modeling;Event sequence data;causality analysis;visual analytics,"Causality is crucial to understanding the mechanisms behind complex systems and making decisions that lead to intended outcomes. Event sequence data is widely collected from many real-world processes, such as electronic health records, web clickstreams, and financial transactions, which transmit a great deal of information reflecting the causal relations among event types. Unfortunately, recovering causalities from observational event sequences is challenging, as the heterogeneous and high-dimensional event variables are often connected to rather complex underlying event excitation mechanisms that are hard to infer from limited observations. Many existing automated causal analysis techniques suffer from poor explainability and fail to include an adequate amount of human knowledge. In this paper, we introduce a visual analytics method for recovering causalities in event sequence data. We extend the Granger causality analysis algorithm on Hawkes processes to incorporate user feedback into causal model refinement. The visualization system includes an interactive causal analysis framework that supports bottom-up causal exploration, iterative causal verification and refinement, and causal comparison through a set of novel visualizations and interactions. We report two forms of evaluation: a quantitative evaluation of the model improvements resulting from the user-feedback mechanism, and a qualitative evaluation through case studies in different application domains to demonstrate the usefulness of the system.",10.1109/TVCG.2020.3030465,,TRUE,TRUE,TRUE,T,T,F,C1,KEEP,1,,,,1,1,1,1,1,1,1,1,0,0,0,1,2,1. domain expert,2,,,0,1,0,0,0,1,1,0,1,0,0,0,0,1,1,0,0,1,0,0,1,0,0,0,0,0,4. After the deployment,0,,
309,111,2020J104,CNNPruner: Pruning Convolutional Neural Networks with Visual Analytics,"Li, Guan and Wang, Junpeng and Shen, Han-Wei and Chen, Kaixin and Shan, Guihua and Lu, Zhonghua",2020,2021,Computational modeling;Numerical models;Analytical models;Visual analytics;Predictive models;Deep learning;visualization;model pruning;convolutional neural network;explainable artificial intelligence,"Convolutional neural networks (CNNs) have demonstrated extraordinarily good performance in many computer vision tasks. The increasing size of CNN models, however, prevents them from being widely deployed to devices with limited computational resources, e.g., mobile/embedded devices. The emerging topic of model pruning strives to address this problem by removing less important neurons and fine-tuning the pruned networks to minimize the accuracy loss. Nevertheless, existing automated pruning solutions often rely on a numerical threshold of the pruning criteria, lacking the flexibility to optimally balance the trade-off between efficiency and accuracy. Moreover, the complicated interplay between the stages of neuron pruning and model fine-tuning makes this process opaque, and therefore becomes difficult to optimize. In this paper, we address these challenges through a visual analytics approach, named CNNPruner. It considers the importance of convolutional filters through both instability and sensitivity, and allows users to interactively create pruning plans according to a desired goal on model size or accuracy. Also, CNNPruner integrates state-of-the-art filter visualization techniques to help users understand the roles that different filters played and refine their pruning plans. Through comprehensive case studies on CNNs with real-world sizes, we validate the effectiveness of CNNPruner.",10.1109/TVCG.2020.3030461,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,1. AI (Machine Learning/Deep Learning/Data Mining),,,0,1,1,0,1,1,1,1,1,0,0,1,2,1. domain expert,2,,,0,0,0,0,0,1,0,1,0,0,0,0,0,0,1,0,0,1,0,0,1,0,0,0,0,0,4. After the deployment,0,,
310,112,2020J107,CNN Explainer: Learning Convolutional Neural Networks with Interactive Visualization,"Wang, Zijie J. and Turko, Robert and Shaikh, Omar and Park, Haekyu and Das, Nilaksh and Hohman, Fred and Kahng, Minsuk and Polo Chau, Duen Horng",2020,2021,Deep learning;Tools;Visualization;Mathematical model;Neurons;Convolutional neural networks;Deep learning;machine learning;convolutional neural networks;visual analytics,"Deep learning's great success motivates many practitioners and students to learn about this exciting technology. However, it is often challenging for beginners to take their first step due to the complexity of understanding and applying deep learning. We present CNN Explainer, an interactive visualization tool designed for non-experts to learn and examine convolutional neural networks (CNNs), a foundational deep learning model architecture. Our tool addresses key challenges that novices face while learning about CNNs, which we identify from interviews with instructors and a survey with past students. CNN Explainer tightly integrates a model overview that summarizes a CNN's structure, and on-demand, dynamic visual explanation views that help users understand the underlying components of CNNs. Through smooth transitions across levels of abstraction, our tool enables users to inspect the interplay between low-level mathematical operations and high-level model structures. A qualitative user study shows that CNN Explainer helps users more easily understand the inner workings of CNNs, and is engaging and enjoyable to use. We also derive design lessons from our study. Developed using modern web technologies, CNN Explainer runs locally in users' web browsers without the need for installation or specialized hardware, broadening the public's education access to modern deep learning techniques.",10.1109/TVCG.2020.3030418,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,1. AI (Machine Learning/Deep Learning/Data Mining),,,0,1,1,1,1,1,1,1,1,0,0,3,39,1. domain expert,4,,,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,2. Before the deployment (Before or during design phase ONLY),0,,
,,2020J107,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,2. domain user,19,,,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,2. Before the deployment (Before or during design phase ONLY),0,,
,,2020J107,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,2. domain user,16,,,0,0,0,0,0,1,0,0,0,0,0,0,0,1,1,1,0,1,0,0,0,0,0,0,0,0,4. After the deployment,0,,
313,113,2020J108,HyperTendril: Visual Analytics for User-Driven Hyperparameter Optimization of Deep Neural Networks,"Park, Heungseok and Nam, Yoonsoo and Kim, Ji-Hoon and Choo, Jaegul",2020,2021,Analytical models;Optimization;Visual analytics;Task analysis;Computational modeling;Neural networks;Deep learning;Visual analytics;deep learning;machine learning;automated machine learning;human-centered computing,"To mitigate the pain of manually tuning hyperparameters of deep neural networks, automated machine learning (AutoML) methods have been developed to search for an optimal set of hyperparameters in large combinatorial search spaces. However, the search results of AutoML methods significantly depend on initial configurations, making it a non-trivial task to find a proper configuration. Therefore, human intervention via a visual analytic approach bears huge potential in this task. In response, we propose HyperTendril, a web-based visual analytics system that supports user-driven hyperparameter tuning processes in a model-agnostic environment. HyperTendril takes a novel approach to effectively steering hyperparameter optimization through an iterative, interactive tuning procedure that allows users to refine the search spaces and the configuration of the AutoML method based on their own insights from given results. Using HyperTendril, users can obtain insights into the complex behaviors of various hyperparameter search algorithms and diagnose their configurations. In addition, HyperTendril supports variable importance analysis to help the users refine their search spaces based on the analysis of relative importance of different hyperparameters and their interaction effects. We present the evaluation demonstrating how HyperTendril helps users steer their tuning processes via a longitudinal user study based on the analysis of interaction logs and in-depth interviews while we deploy our system in a professional industrial environment.",10.1109/TVCG.2020.3030380,,TRUE,TRUE,TRUE,T,T,F,C1,KEEP,1,1. AI (Machine Learning/Deep Learning/Data Mining),,,0,1,1,1,1,1,1,1,1,0,0,3,42,1. domain expert,10,,,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,2. Before the deployment (Before or during design phase ONLY),0,,
,,2020J108,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,2. domain user,32,,,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,4. After the deployment,0,,
,,2020J108,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,2. domain user,3,,,1,0,0,0,0,1,0,0,0,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,4. After the deployment,0,,
314,114,2020J111,DECE: Decision Explorer with Counterfactual Explanations for Machine Learning Models,"Cheng, Furui and Ming, Yao and Qu, Huamin",2020,2021,Machine learning;Analytical models;Predictive models;Tools;Computational modeling;Decision making;Data models;Tabular Data;Explainable Machine Learning;Counterfactual Explanation;Decision Making,"With machine learning models being increasingly applied to various decision-making scenarios, people have spent growing efforts to make machine learning models more transparent and explainable. Among various explanation techniques, counterfactual explanations have the advantages of being human-friendly and actionable-a counterfactual explanation tells the user how to gain the desired prediction with minimal changes to the input. Besides, counterfactual explanations can also serve as efficient probes to the models' decisions. In this work, we exploit the potential of counterfactual explanations to understand and explore the behavior of machine learning models. We design DECE, an interactive visualization system that helps understand and explore a model's decisions on individual instances and data subsets, supporting users ranging from decision-subjects to model developers. DECE supports exploratory analysis of model decisions by combining the strengths of counterfactual explanations at instance- and subgroup-levels. We also introduce a set of interactions that enable users to customize the generation of counterfactual explanations to find more actionable ones that can suit their needs. Through three use cases and an expert interview, we demonstrate the effectiveness of DECE in supporting decision exploration tasks and instance explanations.",10.1109/TVCG.2020.3030342,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,1. AI (Machine Learning/Deep Learning/Data Mining),,,1,1,1,1,1,0,1,1,1,0,0,2,6,2. domain user,3,,,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,4. After the deployment,0,,
,,2020J111,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,2. domain user,3,,,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,4. After the deployment,0,,
318,115,2020J112,"A Visual Analytics Approach for Exploratory Causal Analysis: Exploration, Validation, and Applications","Xie, Xiao and Du, Fan and Wu, Yingcai",2020,2021,Data visualization;Uncertainty;Decision making;Analytical models;Predictive models;Machine learning;Visual analytics;Exploratory causal analysis;correlation and causation;causal graph,"Using causal relations to guide decision making has become an essential analytical task across various domains, from marketing and medicine to education and social science. While powerful statistical models have been developed for inferring causal relations from data, domain practitioners still lack effective visual interface for interpreting the causal relations and applying them in their decision-making process. Through interview studies with domain experts, we characterize their current decision-making workflows, challenges, and needs. Through an iterative design process, we developed a visualization tool that allows analysts to explore, validate, and apply causal relations in real-world decision-making scenarios. The tool provides an uncertainty-aware causal graph visualization for presenting a large set of causal relations inferred from high-dimensional data. On top of the causal graph, it supports a set of intuitive user controls for performing what-if analyses and making action plans. We report on two case studies in marketing and student advising to demonstrate that users can effectively explore causal relations and design action plans for reaching their goals.",10.1109/TVCG.2020.3028957,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,,,,1,1,1,1,1,1,1,1,0,0,0,2,7,1. domain expert,5,,,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,2. Before the deployment (Before or during design phase ONLY),0,,
,,2020J112,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,5,,,0,0,0,0,0,1,0,0,1,0,0,0,0,0,1,0,0,1,0,0,1,0,0,0,0,0,4. After the deployment,0,,
319,116,2020J113,Auditing the Sensitivity of Graph-based Ranking with Visual Analytics,"Xie, Tiankai and Ma, Yuxin and Tong, Hanghang and Thai, My T. and Maciejewski, Ross",2020,2021,Sensitivity;Perturbation methods;Blogs;Visual analytics;Task analysis;Layout;Hypertext systems;Graph-based ranking;sensitivity analysis;visual analytics,"Graph mining plays a pivotal role across a number of disciplines, and a variety of algorithms have been developed to answer who/what type questions. For example, what items shall we recommend to a given user on an e-commerce platform? The answers to such questions are typically returned in the form of a ranked list, and graph-based ranking methods are widely used in industrial information retrieval settings. However, these ranking algorithms have a variety of sensitivities, and even small changes in rank can lead to vast reductions in product sales and page hits. As such, there is a need for tools and methods that can help model developers and analysts explore the sensitivities of graph ranking algorithms with respect to perturbations within the graph structure. In this paper, we present a visual analytics framework for explaining and exploring the sensitivity of any graph-based ranking algorithm by performing perturbation-based what-if analysis. We demonstrate our framework through three case studies inspecting the sensitivity of two classic graph-based ranking algorithms (PageRank and HITS) as applied to rankings in political news media and social networks.",10.1109/TVCG.2020.3028958,,TRUE,TRUE,TRUE,,T,F,C2,KEEP,1,19. Others,,Graph Mining,1,1,1,0,1,1,1,1,0,0,0,1,4,1. domain expert,4,,,1,1,0,0,0,1,0,0,1,0,1,0,0,0,1,0,0,1,0,1,1,0,0,0,0,0,4. After the deployment,0,,
328,117,2020J114,Visual Analysis of Discrimination in Machine Learning,"Wang, Qianwen and Xu, Zhenhua and Chen, Zhutian and Wang, Yong and Liu, Shixia and Qu, Huamin",2020,2021,Itemsets;Visualization;Data visualization;Tools;Machine learning;Data models;Predictive models;Machine Learning;Discrimination;Data Visualization,"The growing use of automated decision-making in critical applications, such as crime prediction and college admission, has raised questions about fairness in machine learning. How can we decide whether different treatments are reasonable or discriminatory? In this paper, we investigate discrimination in machine learning from a visual analytics perspective and propose an interactive visualization tool, DiscriLens, to support a more comprehensive analysis. To reveal detailed information on algorithmic discrimination, DiscriLens identifies a collection of potentially discriminatory itemsets based on causal modeling and classification rules mining. By combining an extended Euler diagram with a matrix-based visualization, we develop a novel set visualization to facilitate the exploration and interpretation of discriminatory itemsets. A user study shows that users can interpret the visually encoded information in DiscriLens quickly and accurately. Use cases demonstrate that DiscriLens provides informative guidance in understanding and reducing algorithmic discrimination.",10.1109/TVCG.2020.3030471,,TRUE,TRUE,TRUE,,T,F,C2,KEEP,1,1. AI (Machine Learning/Deep Learning/Data Mining),,Machine Learning,0,1,1,1,1,1,1,1,1,0,0,2,19,2. domain user,16,,,0,1,0,0,1,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,1,0,0,1,0,4. After the deployment,0,,
,,2020J114,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,2,1. domain expert,1,1,1,0,0,0,1,0,0,1,0,1,0,0,0,1,0,1,1,0,0,1,0,0,0,0,0,4. After the deployment,0,,
715,355,2020J115,Selection-Bias-Corrected Visualization via Dynamic Reweighting,"Borland, David and Zhang, Jonathan and Kaul, Smiti and Gotz, David",2020,2021,Data visualization;Visual analytics;Tools;Interviews;Data collection;Medical diagnostic imaging;Selection bias;bias mitigation;bias correction;high-dimensional visualization;cohort selection;medical informatics,"The collection and visual analysis of large-scale data from complex systems, such as electronic health records or clickstream data, has become increasingly common across a wide range of industries. This type of retrospective visual analysis, however, is prone to a variety of selection bias effects, especially for high-dimensional data where only a subset of dimensions is visualized at any given time. The risk of selection bias is even higher when analysts dynamically apply filters or perform grouping operations during ad hoc analyses. These bias effects threaten the validity and generalizability of insights discovered during visual analysis as the basis for decision making. Past work has focused on bias transparency, helping users understand when selection bias may have occurred. However, countering the effects of selection bias via bias mitigation is typically left for the user to accomplish as a separate process. Dynamic reweighting (DR) is a novel computational approach to selection bias mitigation that helps users craft bias-corrected visualizations. This paper describes the DR workflow, introduces key DR visualization designs, and presents statistical methods that support the DR process. Use cases from the medical domain, as well as findings from domain expert user interviews, are also reported.",10.1109/TVCG.2020.3030455,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
720,356,2020J116,What Makes a Data-GIF Understandable?,"Shu, Xinhuan and Wu, Aoyu and Tang, Junxiu and Bach, Benjamin and Wu, Yingcai and Qu, Huamin",2020,2021,Data visualization;Animation;Videos;Visualization;Social networking (online);Interviews;Data-GIFs;Data-driven Storytelling;Evaluation,"GIFs are enjoying increasing popularity on social media as a format for data-driven storytelling with visualization; simple visual messages are embedded in short animations that usually last less than 15 seconds and are played in automatic repetition. In this paper, we ask the question, â€œWhat makes a data-GIF understandable?â€ While other storytelling formats such as data videos, infographics, or data comics are relatively well studied, we have little knowledge about the design factors and principles for â€œdata-GIFsâ€. To close this gap, we provide results from semi-structured interviews and an online study with a total of 118 participants investigating the impact of design decisions on the understandability of data-GIFs. The study and our consequent analysis are informed by a systematic review and structured design space of 108 data-GIFs that we found online. Our results show the impact of design dimensions from our design space such as animation encoding, context preservation, or repetition on viewers understanding of the GIF's core message. The paper concludes with a list of suggestions for creating more effective Data-GIFs.",10.1109/TVCG.2020.3030396,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
742,357,2020J118,Composition and Configuration Patterns in Multiple-View Visualizations,"Chen, Xi and Zeng, Wei and Lin, Yanna and AI-maneea, Hayder Mahdi and Roberts, Jonathan and Chang, Remco",2020,2021,Data visualization;Layout;Visualization;Tools;Task analysis;Guidelines;Multiple views;design pattern;quantitative analysis;example-based design,"Multiple-view visualization (MV) is a layout design technique often employed to help users see a large number of data attributes and values in a single cohesive representation. Because of its generalizability, the MV design has been widely adopted by the visualization community to help users examine and interact with large, complex, and high-dimensional data. However, although ubiquitous, there has been little work to categorize and analyze MVs in order to better understand its design space. As a result, there has been little to no guideline in how to use the MV design effectively. In this paper, we present an in-depth study of how MVs are designed in practice. We focus on two fundamental measures of multiple-view patterns: composition, which quantifies what view types and how many are there; and configuration, which characterizes spatial arrangement of view layouts in the display space. We build a new dataset containing 360 images of MVs collected from IEEE VIS, EuroVis, and PacificVis publications 2011 to 2019, and make fine-grained annotations of view types and layouts for these visualization images. From this data we conduct composition and configuration analyses using quantitative metrics of term frequency and layout topology. We identify common practices around MVs, including relationship of view types, popular view layouts, and correlation between view types and layouts. We combine the findings into a MV recommendation system, providing interactive tools to explore the design space, and support example-based design.",10.1109/TVCG.2020.3030338,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
329,118,2020J119,"Comparative Layouts Revisited: Design Space, Guidelines, and Future Directions","LYi, Sehi and Jo, Jaemin and Seo, Jinwook",2020,2021,Layout;Visualization;Task analysis;Bars;Heating systems;Data visualization;Guidelines;Comparative layout;visual comparison;literature review;juxtaposition;superposition;explicit-encoding,"We present a systematic review on three comparative layouts-juxtaposition, superposition, and explicit-encoding-which are information visualization (InfoVis) layouts designed to support comparison tasks. For the last decade, these layouts have served as fundamental idioms in designing many visualization systems. However, we found that the layouts have been used with inconsistent terms and confusion, and the lessons from previous studies are fragmented. The goal of our research is to distill the results from previous studies into a consistent and reusable framework. We review 127 research papers, including 15 papers with quantitative user studies, which employed comparative layouts. We first alleviate the ambiguous boundaries in the design space of comparative layouts by suggesting lucid terminology (e.g., chart-wise and item-wise juxtaposition). We then identify the diverse aspects of comparative layouts, such as the advantages and concerns of using each layout in the real-world scenarios and researchers' approaches to overcome the concerns. Building our knowledge on top of the initial insights gained from the Gleicher et al.'s survey [19], we elaborate on relevant empirical evidence that we distilled from our survey (e.g., the actual effectiveness of the layouts in different study settings) and identify novel facets that the original work did not cover (e.g., the familiarity of the layouts to people). Finally, we show the consistent and contradictory results on the performance of comparative layouts and offer practical implications for using the layouts by suggesting trade-offs and seven actionable guidelines.",10.1109/TVCG.2020.3030419,,TRUE,TRUE,TRUE,,T,F,C2,DROP,0,,,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2020J121,"StackGenVis: Alignment of Data, Algorithms, and Models for Stacking Ensemble Learning Using Performance Metrics","Chatzimparmpas, Angelos and Martins, Rafael M. and Kucher, Kostiantyn and Kerren, Andreas",2020,,,,,,TRUE,TRUE,TRUE,T,,F,C2,KEEP,1,1. AI (Machine Learning/Deep Learning/Data Mining),,Machine Learning,0,1,1,1,1,0,1,1,1,0,0,2,3,1. domain expert,3,,,0,1,0,0,0,1,0,0,0,0,0,0,0,1,1,0,0,1,0,1,0,0,0,0,0,0,4. After the deployment,0,,
333,119,2020J121,,,,2021,Stacking;Measurement;Data models;Predictive models;Boosting;Prediction algorithms;Data visualization;Stacking;stacked generalization;ensemble learning;visual analytics;visualization,"In machine learning (ML), ensemble methods-such as bagging, boosting, and stacking-are widely-established approaches that regularly achieve top-notch predictive performance. Stacking (also called â€œstacked generalizationâ€) is an ensemble method that combines heterogeneous base models, arranged in at least one layer, and then employs another metamodel to summarize the predictions of those models. Although it may be a highly-effective approach for increasing the predictive performance of ML, generating a stack of models from scratch can be a cumbersome trial-and-error process. This challenge stems from the enormous space of available solutions, with different sets of data instances and features that could be used for training, several algorithms to choose from, and instantiations of these algorithms using diverse parameters (i.e., models) that perform differently according to various metrics. In this work, we present a knowledge generation model, which supports ensemble learning with the use of visualization, and a visual analytics system for stacked generalization. Our system, StackGenVis, assists users in dynamically adapting performance metrics, managing data instances, selecting the most important features for a given data set, choosing a set of top-performant and diverse algorithms, and measuring the predictive performance. In consequence, our proposed tool helps users to decide between distinct models and to reduce the complexity of the resulting stack by removing overpromising and underperforming models. The applicability and effectiveness of StackGenVis are demonstrated with two use cases: a real-world healthcare data set and a collection of data related to sentiment/stance detection in texts. Finally, the tool has been evaluated through interviews with three ML experts.",10.1109/TVCG.2020.3030352,,,,,,,,,,1,,,,,,,,,,,,,,,,,5. no participant,0,,,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,4. After the deployment,0,,
341,120,2020J127,Co-Bridges: Pair-wise Visual Connection and Comparison for Multi-item Data Streams,"Chen, Siming and Andrienko, Natalia and Andrienko, Gennady and Li, Jie and Yuan, Xiaoru",2020,2021,Rivers;Social networking (online);Data visualization;Task analysis;Bridges;Visual analytics;Visual Comparison;Pair-wise Analysis;Multi-item Data Stream;Social Media,"In various domains, there are abundant streams or sequences of multi-item data of various kinds, e.g. streams of news and social media texts, sequences of genes and sports events, etc. Comparison is an important and general task in data analysis. For comparing data streams involving multiple items (e.g., words in texts, actors or action types in action sequences, visited places in itineraries, etc.), we propose Co-Bridges, a visual design involving connection and comparison techniques that reveal similarities and differences between two streams. Co-Bridges use river and bridge metaphors, where two sides of a river represent data streams, and bridges connect temporally or sequentially aligned segments of streams. Commonalities and differences between these segments in terms of involvement of various items are shown on the bridges. Interactive query tools support the selection of particular stream subsets for focused exploration. The visualization supports both qualitative (common and distinct items) and quantitative (stream volume, amount of item involvement) comparisons. We further propose Comparison-of-Comparisons, in which two or more Co-Bridges corresponding to different selections are juxtaposed. We test the applicability of the Co-Bridges in different domains, including social media text streams and sports event sequences. We perform an evaluation of the users' capability to understand and use Co-Bridges. The results confirm that Co-Bridges is effective for supporting pair-wise visual comparisons in a wide range of applications.",10.1109/TVCG.2020.3030411,,TRUE,TRUE,TRUE,T,,F,C2,DROP,0,,,,1,1,1,1,1,0,1,0,0,0,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
754,358,2020J128,MultiSegVA: Using Visual Analytics to Segment Biologging Time Series on Multiple Scales,"Meschenmoser, Philipp and BuchmÃ¼ller, Juri F. and Seebacher, Daniel and Wikelski, Martin and Keim, Daniel A.",2020,2021,Time series analysis;Animals;Ecology;Task analysis;Hidden Markov models;Visualization;Visual analytics;time series segmentation;multi-scale analyses;movement ecology,"Segmenting biologging time series of animals on multiple temporal scales is an essential step that requires complex techniques with careful parameterization and possibly cross-domain expertise. Yet, there is a lack of visual-interactive tools that strongly support such multi-scale segmentation. To close this gap, we present our MultiSegVA platform for interactively defining segmentation techniques and parameters on multiple temporal scales. MultiSegVA primarily contributes tailored, visual-interactive means and visual analytics paradigms for segmenting unlabeled time series on multiple scales. Further, to flexibly compose the multi-scale segmentation, the platform contributes a new visual query language that links a variety of segmentation techniques. To illustrate our approach, we present a domain-oriented set of segmentation techniques derived in collaboration with movement ecologists. We demonstrate the applicability and usefulness of MultiSegVA in two real-world use cases from movement ecology, related to behavior analysis after environment-aware segmentation, and after progressive clustering. Expert feedback from movement ecologists shows the effectiveness of tailored visual-interactive means and visual analytics paradigms at segmenting multi-scale data, enabling them to perform semantically meaningful analyses. A third use case demonstrates that MultiSegVA is generalizable to other domains.",10.1109/TVCG.2020.3030386,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
851,359,2020J130,Responsive Matrix Cells: A Focus+Context Approach for Exploring and Editing Multivariate Graphs,"Horak, Tom and Berger, Philip and Schumann, Heidrun and Dachselt, Raimund and Tominski, Christian",2020,2021,Data visualization;Visualization;Task analysis;Layout;Lenses;Tools;Encoding;Multivariate graph visualization;matrix visualization;focus+context;embedded visualizations;responsive visualization;graph editing,"Matrix visualizations are a useful tool to provide a general overview of a graph's structure. For multivariate graphs, a remaining challenge is to cope with the attributes that are associated with nodes and edges. Addressing this challenge, we propose responsive matrix cells as a focus+context approach for embedding additional interactive views into a matrix. Responsive matrix cells are local zoomable regions of interest that provide auxiliary data exploration and editing facilities for multivariate graphs. They behave responsively by adapting their visual contents to the cell location, the available display space, and the user task. Responsive matrix cells enable users to reveal details about the graph, compare node and edge attributes, and edit data values directly in a matrix without resorting to external views or tools. We report the general design considerations for responsive matrix cells covering the visual and interactive means necessary to support a seamless data exploration and editing. Responsive matrix cells have been implemented in a web-based prototype based on which we demonstrate the utility of our approach. We describe a walk-through for the use case of analyzing a graph of soccer players and report on insights from a preliminary user feedback session.",10.1109/TVCG.2020.3030371,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
342,121,2020J131,Exemplar-based Layout Fine-tuning for Node-link Diagrams,"Pan, Jiacheng and Chen, Wei and Zhao, Xiaodong and Zhou, Shuyue and Zeng, Wei and Zhu, Minfeng and Chen, Jian and Fu, Siwei and Wu, Yingcai",2020,2021,Layout;Optimization;Merging;Topology;Two dimensional displays;Software algorithms;Measurement;Node-link diagram;graph layout;graph visualization;user interactions,"We design and evaluate a novel layout fine-tuning technique for node-link diagrams that facilitates exemplar-based adjustment of a group of substructures in batching mode. The key idea is to transfer user modifications on a local substructure to other substructures in the entire graph that are topologically similar to the exemplar. We first precompute a canonical representation for each substructure with node embedding techniques and then use it for on-the-fly substructure retrieval. We design and develop a light-weight interactive system to enable intuitive adjustment, modification transfer, and visual graph exploration. We also report some results of quantitative comparisons, three case studies, and a within-participant user study.",10.1109/TVCG.2020.3030393,,TRUE,TRUE,TRUE,T,T,F,C2,DROP,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
862,360,2020J134,SafetyLens: Visual Data Analysis of Functional Safety of Vehicles,"Narechania, Arpit and Qamar, Ahsan and Endert, Alex",2020,2021,Hazards;Acceleration;Visualization;Automotive engineering;Brakes;Tools;Visual data analysis;Design study;Network visualization;Functional safety;Automotive engineering,"Modern automobiles have evolved from just being mechanical machines to having full-fledged electronics systems that enhance vehicle dynamics and driver experience. However, these complex hardware and software systems, if not properly designed, can experience failures that can compromise the safety of the vehicle, its occupants, and the surrounding environment. For example, a system to activate the brakes to avoid a collision saves lives when it functions properly, but could lead to tragic outcomes if the brakes were applied in a way that's inconsistent with the design. Broadly speaking, the analysis performed to minimize such risks falls into a systems engineering domain called Functional Safety. In this paper, we present SafetyLens, a visual data analysis tool to assist engineers and analysts in analyzing automotive Functional Safety datasets. SafetyLens combines techniques including network exploration and visual comparison to help analysts perform domain-specific tasks. This paper presents the design study with domain experts that resulted in the design guidelines, the tool, and user feedback.",10.1109/TVCG.2020.3030382,,TRUE,TRUE,FALSE,,,T,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
343,122,2020J138,CAVA: A Visual Analytics System for Exploratory Columnar Data Augmentation Using Knowledge Graphs,"Cashman, Dylan and Xu, Shenyu and Das, Subhajit and Heimerl, Florian and Liu, Cong and Humayoun, Shah Rukh and Gleicher, Michael and Endert, Alex and Chang, Remco",2020,2021,Task analysis;Visual analytics;Machine learning;Data models;Data visualization;Google;Training;Visual Analytics;Information Foraging;Data Augmentation,"Most visual analytics systems assume that all foraging for data happens before the analytics process; once analysis begins, the set of data attributes considered is fixed. Such separation of data construction from analysis precludes iteration that can enable foraging informed by the needs that arise in-situ during the analysis. The separation of the foraging loop from the data analysis tasks can limit the pace and scope of analysis. In this paper, we present CAVA, a system that integrates data curation and data augmentation with the traditional data exploration and analysis tasks, enabling information foraging in-situ during analysis. Identifying attributes to add to the dataset is difficult because it requires human knowledge to determine which available attributes will be helpful for the ensuing analytical tasks. CAVA crawls knowledge graphs to provide users with a a broad set of attributes drawn from external data to choose from. Users can then specify complex operations on knowledge graphs to construct additional attributes. CAVA shows how visual analytics can help users forage for attributes by letting users visually explore the set of available data, and by serving as an interface for query construction. It also provides visualizations of the knowledge graph itself to help users understand complex joins such as multi-hop aggregations. We assess the ability of our system to enable users to perform complex data combinations without programming in a user study over two datasets. We then demonstrate the generalizability of CAVA through two additional usage scenarios. The results of the evaluation confirm that CAVA is effective in helping the user perform data foraging that leads to improved analysis outcomes, and offer evidence in support of integrating data augmentation as a part of the visual analytics pipeline.",10.1109/TVCG.2020.3030443,,TRUE,TRUE,TRUE,T,T,F,C2,KEEP,1,,,,1,1,1,1,1,1,1,1,0,0,0,1,6,2. domain user,6,,,0,1,0,0,1,1,0,0,1,0,1,0,0,1,1,1,1,1,0,0,0,0,0,0,0,0,4. After the deployment,0,,
865,361,2020J139,An Examination of Grouping and Spatial Organization Tasks for High-Dimensional Data Exploration,"Wenskovitch, John and North, Chris",2020,2021,Task analysis;Tools;Cognition;Dimensionality reduction;Visualization;Data analysis;Semantics;Clustering;dimension reduction;spatialization;grouping;cognitive study,"How do analysts think about grouping and spatial operations? This overarching research question incorporates a number of points for investigation, including understanding how analysts begin to explore a dataset, the types of grouping/spatial structures created and the operations performed on them, the relationship between grouping and spatial structures, the decisions analysts make when exploring individual observations, and the role of external information. This work contributes the design and results of such a study, in which a group of participants are asked to organize the data contained within an unfamiliar quantitative dataset. We identify several overarching approaches taken by participants to design their organizational space, discuss the interactions performed by the participants, and propose design recommendations to improve the usability of future high-dimensional data exploration tools that make use of grouping (clustering) and spatial (dimension reduction) operations.",10.1109/TVCG.2020.3028890,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
347,123,2020J141,Supporting the Problem-Solving Loop: Designing Highly Interactive Optimisation Systems,"Liu, Jie and Dwyer, Tim and Tack, Guido and Gratzl, Samuel and Marriott, Kim",2020,2021,Optimization;Tools;Task analysis;Mathematical model;Problem-solving;Visual analytics;Interactive optimisation;Interface design;Usability;Interactive systems and tools;Vehicle routing,"Efficient optimisation algorithms have become important tools for finding high-quality solutions to hard, real-world problems such as production scheduling, timetabling, or vehicle routing. These algorithms are typically â€œblack boxesâ€ that work on mathematical models of the problem to solve. However, many problems are difficult to fully specify, and require a â€œhuman in the loopâ€ who collaborates with the algorithm by refining the model and guiding the search to produce acceptable solutions. Recently, the Problem-Solving Loop was introduced as a high-level model of such interactive optimisation. Here, we present and evaluate nine recommendations for the design of interactive visualisation tools supporting the Problem-Solving Loop. They range from the choice of visual representation for solutions and constraints to the use of a solution gallery to support exploration of alternate solutions. We first examined the applicability of the recommendations by investigating how well they had been supported in previous interactive optimisation tools. We then evaluated the recommendations in the context of the vehicle routing problem with time windows (VRPTW). To do so we built a sophisticated interactive visual system for solving VRPTW that was informed by the recommendations. Ten participants then used this system to solve a variety of routing problems. We report on participant comments and interaction patterns with the tool. These showed the tool was regarded as highly usable and the results generally supported the usefulness of the underlying recommendations.",10.1109/TVCG.2020.3030364,,TRUE,TRUE,TRUE,T,,F,C2,DROP,0,,,Computer Optimization,0,1,1,1,1,0,1,0,0,0,0,,10,2. domain user,10,,,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,4. After the deployment,0,,
348,124,2020J142,Integrating Prior Knowledge in Mixed-Initiative Social Network Clustering,"Pister, Alexis and Buono, Paolo and Fekete, Jean-Daniel and Plaisant, Catherine and Valdivia, Paola",2020,2021,Clustering algorithms;Social networking (online);Tools;Visualization;Heuristic algorithms;Clustering methods;Inference algorithms;Social network analysis;network visualization;clustering;mixed-initiative;prior knowledge;user interface,"We propose a new approach-called PK-clustering-to help social scientists create meaningful clusters in social networks. Many clustering algorithms exist but most social scientists find them difficult to understand, and tools do not provide any guidance to choose algorithms, or to evaluate results taking into account the prior knowledge of the scientists. Our work introduces a new clustering approach and a visual analytics user interface that address this issue. It is based on a process that 1) captures the prior knowledge of the scientists as a set of incomplete clusters, 2) runs multiple clustering algorithms (similarly to clustering ensemble methods), 3) visualizes the results of all the algorithms ranked and summarized by how well each algorithm matches the prior knowledge, 4) evaluates the consensus between user-selected algorithms and 5) allows users to review details and iteratively update the acquired knowledge. We describe our approach using an initial functional prototype, then provide two examples of use and early feedback from social scientists. We believe our clustering approach offers a novel constructive method to iteratively build knowledge while avoiding being overly influenced by the results of often randomly selected black-box clustering algorithms.",10.1109/TVCG.2020.3030347,,TRUE,TRUE,TRUE,T,,F,C2,KEEP,1,11. Humanities and social sciences,,Social Networks,0,1,1,0,1,1,1,1,0,0,0,1,3,1. domain expert,3,,,1,1,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,4. After the deployment,0,,
,,2020J145,Uncertainty-Oriented Ensemble Data Visualization and Exploration using Variable Spatial Spreading,"Zhang, Mingdong and Chen, Li and Li, Quan and Yuan, Xiaoru and Yong, Junhai",2020,2021,Data visualization;Uncertainty;Analytical models;Computational modeling;Visualization;Data models;Stability analysis;Uncertainty visualization;ensemble visualization;spatial spreading;temporal analysis,"As an important method of handling potential uncertainties in numerical simulations, ensemble simulation has been widely applied in many disciplines. Visualization is a promising and powerful ensemble simulation analysis method. However, conventional visualization methods mainly aim at data simplification and highlighting important information based on domain expertise instead of providing a flexible data exploration and intervention mechanism. Trial-and-error procedures have to be repeatedly conducted by such approaches. To resolve this issue, we propose a new perspective of ensemble data analysis using the attribute variable dimension as the primary analysis dimension. Particularly, we propose a variable uncertainty calculation method based on variable spatial spreading. Based on this method, we design an interactive ensemble analysis framework that provides a flexible interactive exploration of the ensemble data. Particularly, the proposed spreading curve view, the region stability heat map view, and the temporal analysis view, together with the commonly used 2D map view, jointly support uncertainty distribution perception, region selection, and temporal analysis, as well as other analysis requirements. We verify our approach by analyzing a real-world ensemble simulation dataset. Feedback collected from domain experts confirms the efficacy of our framework.",10.1109/TVCG.2020.3030377,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
351,125,2020J147,Modeling the Influence of Visual Density on Cluster Perception in Scatterplots Using Topology,"Quadri, Ghulam Jilani and Rosen, Paul",2020,2021,Visualization;Task analysis;Data models;Encoding;Data visualization;Analytical models;Computational modeling;Scatterplot;clustering;perception;empirical evaluation;visual encoding;crowdsourcing;topological data analysis,"Scatterplots are used for a variety of visual analytics tasks, including cluster identification, and the visual encodings used on a scatterplot play a deciding role on the level of visual separation of clusters. For visualization designers, optimizing the visual encodings is crucial to maximizing the clarity of data. This requires accurately modeling human perception of cluster separation, which remains challenging. We present a multi-stage user study focusing on four factors-distribution size of clusters, number of points, size of points, and opacity of points-that influence cluster identification in scatterplots. From these parameters, we have constructed two models, a distance-based model, and a density-based model, using the merge tree data structure from Topological Data Analysis. Our analysis demonstrates that these factors play an important role in the number of clusters perceived, and it verifies that the distance-based and density-based models can reasonably estimate the number of clusters a user observes. Finally, we demonstrate how these models can be used to optimize visual encodings on real-world data.",10.1109/TVCG.2020.3030365,,TRUE,TRUE,TRUE,,T,F,C2,DROP,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
887,362,2021J001,IRVINE: A Design Study on Analyzing Correlation Patterns of Electrical Engines,"Eirich, Joscha and Bonart, Jakob and JÃ¤ckle, Dominik and Sedlmair, Michael and Schmid, Ute and Fischbach, Kai and Schreck, Tobias and Bernard, JÃ¼rgen",2021,2022,Engines;Acoustics;Labeling;Annotations;Task analysis;Automotive engineering;Data visualization;Design study;interactive labeling;interactive clustering;H.5.2 [Information Interfaces and Presentation];User Interfacesâ€”Graphical user interfaces (GUI);User-centered design,"In this design study, we present IRVINE, a Visual Analytics (VA) system, which facilitates the analysis of acoustic data to detect and understand previously unknown errors in the manufacturing of electrical engines. In serial manufacturing processes, signatures from acoustic data provide valuable information on how the relationship between multiple produced engines serves to detect and understand previously unknown errors. To analyze such signatures, IRVINE leverages interactive clustering and data labeling techniques, allowing users to analyze clusters of engines with similar signatures, drill down to groups of engines, and select an engine of interest. Furthermore, IRVINE allows to assign labels to engines and clusters and annotate the cause of an error in the acoustic raw measurement of an engine. Since labels and annotations represent valuable knowledge, they are conserved in a knowledge database to be available for other stakeholders. We contribute a design study, where we developed IRVINE in four main iterations with engineers from a company in the automotive sector. To validate IRVINE, we conducted a field study with six domain experts. Our results suggest a high usability and usefulness of IRVINE as part of the improvement of a real-world manufacturing process. Specifically, with IRVINE domain experts were able to label and annotate produced electrical engines more than 30% faster.",10.1109/TVCG.2021.3114797,,TRUE,TRUE,FALSE,,,T,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
352,126,2021J005,SightBi: Exploring Cross-View Data Relationships with Biclusters,"Sun, Maoyuan and Shaikh, Abdul Rahman and Alhoori, Hamed and Zhao, Jian",2021,2022,Visualization;Data visualization;Tools;Task analysis;Layout;Sun;Bioinformatics;Cross-view data relationship;multi-view visualization;bicluster;visual analytics,"Multiple-view visualization (MV) has been heavily used in visual analysis tools for sensemaking of data in various domains (e.g., bioinformatics, cybersecurity and text analytics). One common task of visual analysis with multiple views is to relate data across different views. For example, to identify threats, an intelligence analyst needs to link people from a social network graph with locations on a crime-map, and then search for and read relevant documents. Currently, exploring cross-view data relationships heavily relies on view-coordination techniques (e.g., brushing and linking), which may require significant user effort on many trial-and-error attempts, such as repetitiously selecting elements in one view, and then observing and following elements highlighted in other views. To address this, we present SightBi, a visual analytics approach for supporting cross-view data relationship explorations. We discuss the design rationale of SightBi in detail, with identified user tasks regarding the use of cross-view data relationships. SightBi formalizes cross-view data relationships as biclusters, computes them from a dataset, and uses a bi-context design that highlights creating stand-alone relationship-views. This helps preserve existing views and offers an overview of cross-view data relationships to guide user exploration. Moreover, SightBi allows users to interactively manage the layout of multiple views by using newly created relationship-views. With a usage scenario, we demonstrate the usefulness of SightBi for sensemaking of cross-view data relationships.",10.1109/TVCG.2021.3114801,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,,,,1,1,1,1,1,0,1,1,0,0,0,1,2,1. domain expert,2,,,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,1,1,1,0,0,0,0,0,0,0,4. After the deployment,0,,
354,127,2021J006,matExplorer: Visual Exploration on Predicting Ionic Conductivity for Solid-state Electrolytes,"Pu, Jiansu and Shao, Hui and Gao, Boyang and Zhu, Zhengguo and Zhu, Yanlin and Rao, Yunbo and Xiang, Yong",2021,2022,Electrolytes;Solids;Liquids;Conductivity;Batteries;Lithium;Thermal stability;Interactive visualization;machine learning;materials discovery;ionic conductivity;high-dimensional data;solid-state electrolytes,"Lithium ion batteries (LIBs) are widely used as important energy sources for mobile phones, electric vehicles, and drones. Experts have attempted to replace liquid electrolytes with solid electrolytes that have wider electrochemical window and higher stability due to the potential safety risks, such as electrolyte leakage, flammable solvents, poor thermal stability, and many side reactions caused by liquid electrolytes. However, finding suitable alternative materials using traditional approaches is very difficult due to the incredibly high cost in searching. Machine learning (ML)-based methods are currently introduced and used for material prediction. However, learning tools designed for domain experts to conduct intuitive performance comparison and analysis of ML models are rare. In this case, we propose an interactive visualization system for experts to select suitable ML models and understand and explore the predication results comprehensively. Our system uses a multifaceted visualization scheme designed to support analysis from various perspectives, such as feature distribution, data similarity, model performance, and result presentation. Case studies with actual lab experiments have been conducted by the experts, and the final results confirmed the effectiveness and helpfulness of our system.",10.1109/TVCG.2021.3114812,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,14. Materials science and nanotechnology,,,0,1,1,1,1,1,1,1,0,1,0,1,2,1. domain expert,2,,,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,4. After the deployment,0,,
,,2021J008,Propagating Visual Designs to Numerous Plots and Dashboards,"Khan, Saiful and Nguyen, Phong H. and Abdul-Rahman, Alfie and Bach, Benjamin and Chen, Min and Freeman, Euan and Turkay, Cagatay",2021,2022,Data visualization;Visualization;Ontologies;Tools;Programming;Analytical models;Time series analysis;Visualization system;propagation;infrastructure;ontology;quality assurance;pandemic;emergency response,"In the process of developing an infrastructure for providing visualization and visual analytics (VIS) tools to epidemiologists and modeling scientists, we encountered a technical challenge for applying a number of visual designs to numerous datasets rapidly and reliably with limited development resources. In this paper, we present a technical solution to address this challenge. Operationally, we separate the tasks of data management, visual designs, and plots and dashboard deployment in order to streamline the development workflow. Technically, we utilize: an ontology to bring datasets, visual designs, and deployable plots and dashboards under the same management framework; multi-criteria search and ranking algorithms for discovering potential datasets that match a visual design; and a purposely-design user interface for propagating each visual design to appropriate datasets (often in tens and hundreds) and quality-assuring the propagation before the deployment. This technical solution has been used in the development of the RAMPVIS infrastructure for supporting a consortium of epidemiologists and modeling scientists through visualization.",10.1109/TVCG.2021.3114828,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2021J009,Exploring the Personal Informatics Analysis Gap: â€œThere's a Lot of Baconâ€,"Moore, Jimmy and Goffin, Pascal and Wiese, Jason and Meyer, Miriah",2021,2022,Informatics;Tools;Data visualization;Data analysis;Task analysis;Context;Analytical models;Personal visualization;Personal visual analytics;Personal informatics;Interview methods,"Personal informatics research helps people track personal data for the purposes of self-reflection and gaining self-knowledge. This field, however, has predominantly focused on the data collection and insight-generation elements of self-tracking, with less attention paid to flexible data analysis. As a result, this inattention has led to inflexible analytic pipelines that do not reflect or support the diverse ways people want to engage with their data. This paper contributes a review of personal informatics and visualization research literature to expose a gap in our knowledge for designing flexible tools that assist people engaging with and analyzing personal data in personal contexts, what we call the personal informatics analysis gap. We explore this gap through a multistage longitudinal study on how asthmatics engage with personal air quality data, and we report how participants: were motivated by broad and diverse goals; exhibited patterns in the way they explored their data; engaged with their data in playful ways; discovered new insights through serendipitous exploration; and were reluctant to use analysis tools on their own. These results present new opportunities for visual analysis research and suggest the need for fundamental shifts in how and what we design when supporting personal data analysis.",10.1109/TVCG.2021.3114798,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
358,128,2021J011,TIVEE: Visual Exploration and Explanation of Badminton Tactics in Immersive Visualizations,"Chu, Xiangtong and Xie, Xiao and Ye, Shuainan and Lu, Haolin and Xiao, Hongguang and Yuan, Zeqing and Chen, Zhutian and Zhang, Hui and Wu, Yingcai",2021,2022,Trajectory;Sports;Three-dimensional displays;Data visualization;Visualization;Games;Layout;Tactic analysis;stroke sequence visualization;immersive visualization,"Tactic analysis is a major issue in badminton as the effective usage of tactics is the key to win. The tactic in badminton is defined as a sequence of consecutive strokes. Most existing methods use statistical models to find sequential patterns of strokes and apply 2D visualizations such as glyphs and statistical charts to explore and analyze the discovered patterns. However, in badminton, spatial information like the shuttle trajectory, which is inherently 3D, is the core of a tactic. The lack of sufficient spatial awareness in 2D visualizations largely limited the tactic analysis of badminton. In this work, we collaborate with domain experts to study the tactic analysis of badminton in a 3D environment and propose an immersive visual analytics system, TIVEE, to assist users in exploring and explaining badminton tactics from multi-levels. Users can first explore various tactics from the third-person perspective using an unfolded visual presentation of stroke sequences. By selecting a tactic of interest, users can turn to the first-person perspective to perceive the detailed kinematic characteristics and explain its effects on the game result. The effectiveness and usefulness of TIVEE are demonstrated by case studies and an expert interview.",10.1109/TVCG.2021.3114861,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,17. Sports and entertainment,,,0,1,1,1,1,1,1,1,0,0,1,1,3,1. domain expert,3,,,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,0,1,1,0,0,0,0,0,4. After the deployment,0,,
359,129,2021J014,THALIS: Human-Machine Analysis of Longitudinal Symptoms in Cancer Therapy,"Floricel, Carla and Nipu, Nafiul and Biggs, Mikayla and Wentzel, Andrew and Canahuate, Guadalupe and Van Dijk, Lisanne and Mohamed, Abdallah and Fuller, C.David and Marai, G.Elisabeta",2021,2022,Cancer;Visualization;Medical treatment;Data visualization;Encoding;Principal component analysis;Neck;Temporal Data;Application Motivated Visualization;Life Sciences;Mixed Initiative Human-Machine Analysis,"Although cancer patients survive years after oncologic therapy, they are plagued with long-lasting or permanent residual symptoms, whose severity, rate of development, and resolution after treatment vary largely between survivors. The analysis and interpretation of symptoms is complicated by their partial co-occurrence, variability across populations and across time, and, in the case of cancers that use radiotherapy, by further symptom dependency on the tumor location and prescribed treatment. We describe THALIS, an environment for visual analysis and knowledge discovery from cancer therapy symptom data, developed in close collaboration with oncology experts. Our approach leverages unsupervised machine learning methodology over cohorts of patients, and, in conjunction with custom visual encodings and interactions, provides context for new patients based on patients with similar diagnostic features and symptom evolution. We evaluate this approach on data collected from a cohort of head and neck cancer patients. Feedback from our clinician collaborators indicates that THALIS supports knowledge discovery beyond the limits of machines or humans alone, and that it serves as a valuable tool in both the clinic and symptom research.",10.1109/TVCG.2021.3114810,,TRUE,TRUE,TRUE,T,,F,C1,KEEP,1,2. Biology and life sciences,,,0,1,1,1,1,1,1,1,0,1,0,2,4,1. domain expert,4,,,0,1,0,0,0,1,0,0,0,0,0,0,0,1,0,0,1,1,0,1,1,0,0,0,0,0,4. After the deployment,0,,
,,2021J014,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,4,,,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,3. Before the deployment (During the development and refinement phrase ONLY),1,,
367,130,2021J015,MultiVision: Designing Analytical Dashboards with Deep Learning Based Recommendation,"Wu, Aoyu and Wang, Yun and Zhou, Mengyu and He, Xinyi and Zhang, Haidong and Qu, Huamin and Zhang, Dongmei",2021,2022,Data visualization;Visualization;Encoding;Deep learning;Tools;Measurement;Layout;Visualization Recommendation;Deep Learning;Multiple-View;Dashboard;Mixed-Initiative;Visualization Provenance,"We contribute a deep-learning-based method that assists in designing analytical dashboards for analyzing a data table. Given a data table, data workers usually need to experience a tedious and time-consuming process to select meaningful combinations of data columns for creating charts. This process is further complicated by the needs of creating dashboards composed of multiple views that unveil different perspectives of data. Existing automated approaches for recommending multiple-view visualizations mainly build on manually crafted design rules, producing sub-optimal or irrelevant suggestions. To address this gap, we present a deep learning approach for selecting data columns and recommending multiple charts. More importantly, we integrate the deep learning models into a mixed-initiative system. Our model could make recommendations given optional user-input selections of data columns. The model, in turn, learns from provenance data of authoring logs in an offline manner. We compare our deep learning model with existing methods for visualization recommendation and conduct a user study to evaluate the usefulness of the system.",10.1109/TVCG.2021.3114826,,TRUE,TRUE,TRUE,T,T,F,C1,DROP,0,,,,0,1,1,1,1,0,0,0,0,1,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
369,131,2021J017,Kori: Interactive Synthesis of Text and Charts in Data Documents,"Latif, Shahid and Zhou, Zheng and Kim, Yoon and Beck, Fabian and Kim, Nam Wook",2021,2022,Data visualization;Visualization;Tools;Programming;Bars;Syntactics;Natural language processing;Data-driven storytelling;interaction design;authoring;visualization-text linking;mixed-initiative interface;interactive documents,"Charts go hand in hand with text to communicate complex data and are widely adopted in news articles, online blogs, and academic papers. They provide graphical summaries of the data, while text explains the message and context. However, synthesizing information across text and charts is difficult; it requires readers to frequently shift their attention. We investigated ways to support the tight coupling of text and charts in data documents. To understand their interplay, we analyzed the design space of chart-text references through news articles and scientific papers. Informed by the analysis, we developed a mixed-initiative interface enabling users to construct interactive references between text and charts. It leverages natural language processing to automatically suggest references as well as allows users to manually construct other references effortlessly. A user study complemented with algorithmic evaluation of the system suggests that the interface provides an effective way to compose interactive data documents.",10.1109/TVCG.2021.3114802,,TRUE,TRUE,TRUE,T,T,F,C1,KEEP,1,12. Journalism and media,,visualization,1,1,1,1,1,0,1,1,0,0,0,2,11,2. domain user,6,1. domain expert,5,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,4. After the deployment,0,,
,,2021J017,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,5. no participant,0,,,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,4. After the deployment,0,,
,,2021J018,KG4Vis: A Knowledge Graph-Based Approach for Visualization Recommendation,"Li, Haotian and Wang, Yong and Zhang, Songheng and Song, Yangqiu and Qu, Huamin",2021,2022,Data visualization;Feature extraction;Tools;Manuals;Data models;Visualization;Interviews;Data visualization;Visualization recommendation;Knowledge graph,"Visualization recommendation or automatic visualization generation can significantly lower the barriers for general users to rapidly create effective data visualizations, especially for those users without a background in data visualizations. However, existing rule-based approaches require tedious manual specifications of visualization rules by visualization experts. Other machine learning-based approaches often work like black-box and are difficult to understand why a specific visualization is recommended, limiting the wider adoption of these approaches. This paper fills the gap by presenting KG4Vis, a knowledge graph (KG)-based approach for visualization recommendation. It does not require manual specifications of visualization rules and can also guarantee good explainability. Specifically, we propose a framework for building knowledge graphs, consisting of three types of entities (i.e., data features, data columns and visualization design choices) and the relations between them, to model the mapping rules between data and effective visualizations. A TransE-based embedding technique is employed to learn the embeddings of both entities and relations of the knowledge graph from existing dataset-visualization pairs. Such embeddings intrinsically model the desirable visualization rules. Then, given a new dataset, effective visualizations can be inferred from the knowledge graph with semantically meaningful rules. We conducted extensive evaluations to assess the proposed approach, including quantitative comparisons, case studies and expert interviews. The results demonstrate the effectiveness of our approach.",10.1109/TVCG.2021.3114863,,TRUE,TRUE,TRUE,T,T,F,C1,DROP,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
371,132,2021J019,VizLinter: A Linter and Fixer Framework for Data Visualization,"Chen, Qing and Sun, Fuling and Xu, Xinyue and Chen, Zui and Wang, Jiazhe and Cao, Nan",2021,2022,Data visualization;Encoding;Visualization;Optimization;Tools;Programming;Codes;Visualization Linting;Automated Visualization Design;Visualization Optimization,"Despite the rising popularity of automated visualization tools, existing systems tend to provide direct results which do not always fit the input data or meet visualization requirements. Therefore, additional specification adjustments are still required in real-world use cases. However, manual adjustments are difficult since most users do not necessarily possess adequate skills or visualization knowledge. Even experienced users might create imperfect visualizations that involve chart construction errors. We present a framework, VizLinter, to help users detect flaws and rectify already-built but defective visualizations. The framework consists of two components, (1) a visualization linter, which applies well-recognized principles to inspect the legitimacy of rendered visualizations, and (2) a visualization fixer, which automatically corrects the detected violations according to the linter. We implement the framework into an online editor prototype based on Vega-Lite specifications. To further evaluate the system, we conduct an in-lab user study. The results prove its effectiveness and efficiency in identifying and fixing errors for data visualizations.",10.1109/TVCG.2021.3114804,,TRUE,TRUE,TRUE,T,T,F,C1,KEEP,1,19. Others,,visualization,0,1,1,1,1,1,1,1,0,0,0,1,20,2. domain user,12,4. visual expert,8,0,1,0,0,1,1,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,1,1,4. After the deployment,0,,
375,133,2021J021,COVID-view: Diagnosis of COVID-19 using Chest CT,"Jadhav, Shreeraj and Deng, Gaofeng and Zawin, Marlene and Kaufman, Arie E.",2021,2022,COVID-19;Lung;Computed tomography;Visualization;Three-dimensional displays;Solid modeling;Lesions;visual-deep learning diagnosis;COVID-19;chest CT;volume rendering;MIP;classification model;explainable DL,"Significant work has been done towards deep learning (DL) models for automatic lung and lesion segmentation and classification of COVID-19 on chest CT data. However, comprehensive visualization systems focused on supporting the dual visual+DL diagnosis of COVID-19 are non-existent. We present COVID-view, a visualization application specially tailored for radiologists to diagnose COVID-19 from chest CT data. The system incorporates a complete pipeline of automatic lungs segmentation, localization/isolation of lung abnormalities, followed by visualization, visual and DL analysis, and measurement/quantification tools. Our system combines the traditional 2D workflow of radiologists with newer 2D and 3D visualization techniques with DL support for a more comprehensive diagnosis. COVID-view incorporates a novel DL model for classifying the patients into positive/negative COVID-19 cases, which acts as a reading aid for the radiologist using COVID-view and provides the attention heatmap as an explainable DL for the model output. We designed and evaluated COVID-view through suggestions, close feedback and conducting case studies of real-world patient data by expert radiologists who have substantial experience diagnosing chest CT scans for COVID-19, pulmonary embolism, and other forms of lung infections. We present requirements and task analysis for the diagnosis of COVID-19 that motivate our design choices and results in a practical system which is capable of handling real-world patient cases.",10.1109/TVCG.2021.3114851,,TRUE,TRUE,TRUE,T,T,F,C1,KEEP,1,10. Healthcare and medical imaging,1. AI (Machine Learning/Deep Learning/Data Mining),,0,1,1,0,1,0,1,1,1,0,0,2,3,1. domain expert,3,,,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,4. After the deployment,0,,
376,134,2021J022,ThreadStates: State-based Visual Analysis of Disease Progression,"Wang, Qianwen and Mazor, Tali and Harbig, Theresa A and Cerami, Ethan and Gehlenborg, Nils",2021,2022,Diseases;Data visualization;Hidden Markov models;Visual analytics;Cancer;Tools;Data mining;Disease Progression;State Identification;Sequence Visualization,"A growing number of longitudinal cohort studies are generating data with extensive patient observations across multiple timepoints. Such data offers promising opportunities to better understand the progression of diseases. However, these observations are usually treated as general events in existing visual analysis tools. As a result, their capabilities in modeling disease progression are not fully utilized. To fill this gap, we designed and implemented ThreadStates, an interactive visual analytics tool for the exploration of longitudinal patient cohort data. The focus of ThreadStates is to identify the states of disease progression by learning from observation data in a human-in-the-loop manner. We propose a novel Glyph Matrix design and combine it with a scatter plot to enable seamless identification, observation, and refinement of states. The disease progression patterns are then revealed in terms of state transitions using Sankey-based visualizations. We employ sequence clustering techniques to find patient groups with distinctive progression patterns, and to reveal the association between disease progression and patient-level features. The design and development were driven by a requirement analysis and iteratively refined based on feedback from domain experts over the course of a 10-month design study. Case studies and expert interviews demonstrate that ThreadStates can successively summarize disease states, reveal disease progression, and compare patient groups.",10.1109/TVCG.2021.3114840,,TRUE,TRUE,TRUE,,T,T,,,999,10. Healthcare and medical imaging,,0,1,1,1,1,1,,,,,,,,,1. Domain expert,2,,,0,0,0,0,0,1,0,0,0,,0,0,0,0,1,0,0,1,1,,,0,0,0,0,0,4. After the deployment,,,
,,2021J021,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,5. no participant,0,,,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,4. After the deployment,0,,
377,135,2021J024,Scope2Screen: Focus+Context Techniques for Pathology Tumor Assessment in Multivariate Image Data,"Jessup, Jared and Krueger, Robert and Warchol, Simon and Hoffer, John and Muhlich, Jeremy and Ritch, Cecily C. and Gaglia, Giorgio and Coy, Shannon and Chen, Yu-An and Lin, Jia-Ren and Santagata, Sandro and Sorger, Peter K. and Pfister, Hanspeter",2021,2022,Lenses;Tools;Task analysis;Data visualization;Annotations;Cancer;Rendering (computer graphics);Histopathology;Focus+Context;Image Analysis,"Inspection of tissues using a light microscope is the primary method of diagnosing many diseases, notably cancer. Highly multiplexed tissue imaging builds on this foundation, enabling the collection of up to 60 channels of molecular information plus cell and tissue morphology using antibody staining. This provides unique insight into disease biology and promises to help with the design of patient-specific therapies. However, a substantial gap remains with respect to visualizing the resulting multivariate image data and effectively supporting pathology workflows in digital environments on screen. We, therefore, developed Scope2Screen, a scalable software system for focus+context exploration and annotation of whole-slide, high-plex, tissue images. Our approach scales to analyzing 100GB images of 109 or more pixels per channel, containing millions of individual cells. A multidisciplinary team of visualization experts, microscopists, and pathologists identified key image exploration and annotation tasks involving finding, magnifying, quantifying, and organizing regions of interest (ROIs) in an intuitive and cohesive manner. Building on a scope-to-screen metaphor, we present interactive lensing techniques that operate at single-cell and tissue levels. Lenses are equipped with task-specific functionality and descriptive statistics, making it possible to analyze image features, cell types, and spatial arrangements (neighborhoods) across image channels and scales. A fast sliding-window search guides users to regions similar to those under the lens; these regions can be analyzed and considered either separately or as part of a larger image collection. A novel snapshot method enables linked lens configurations and image statistics to be saved, restored, and shared with these regions. We validate our designs with domain experts and apply Scope2Screen in two case studies involving lung and colorectal cancers to discover cancer-relevant image features.",10.1109/TVCG.2021.3114786,,TRUE,TRUE,TRUE,,T,F,C2,KEEP,1,10. Healthcare and medical imaging,,Healthcare,0,1,1,1,1,1,1,1,0,0,0,1,3,1. domain expert,3,,,1,1,0,0,0,1,0,0,1,0,1,0,0,1,0,1,0,1,0,1,1,0,0,0,0,0,4. After the deployment,0,,
378,136,2021J031,Interactive Visual Pattern Search on Graph Data via Graph Representation Learning,"Song, Huan and Dai, Zeng and Xu, Panpan and Ren, Liu",2021,2022,Task analysis;Semantics;Visual analytics;Graph neural networks;Computational modeling;Visual databases;Pattern matching;Graph;Graph Neural Network;Representation Learning;Visual Query Interface,"Graphs are a ubiquitous data structure to model processes and relations in a wide range of domains. Examples include control-flow graphs in programs and semantic scene graphs in images. Identifying subgraph patterns in graphs is an important approach to understand their structural properties. We propose a visual analytics system GraphQ to support human-in-the-loop, example-based, subgraph pattern search in a database containing many individual graphs. To support fast, interactive queries, we use graph neural networks (GNNs) to encode a graph as fixed-length latent vector representation, and perform subgraph matching in the latent space. Due to the complexity of the problem, it is still difficult to obtain accurate one-to-one node correspondences in the matching results that are crucial for visualization and interpretation. We, therefore, propose a novel GNN for node-alignment called NeuroAlign, to facilitate easy validation and interpretation of the query results. GraphQ provides a visual query interface with a query editor and a multi-scale visualization of the results, as well as a user feedback mechanism for refining the results with additional constraints. We demonstrate GraphQ through two example usage scenarios: analyzing reusable subroutines in program workflows and semantic scene graph search in images. Quantitative experiments show that NeuroAlign achieves 19%-29% improvement in node-alignment accuracy compared to baseline GNN and provides up to 100Ã— speedup compared to combinatorial algorithms. Our qualitative study with domain experts confirms the effectiveness for both usage scenarios.",10.1109/TVCG.2021.3114857,,TRUE,TRUE,TRUE,,T,F,C2,KEEP,1,19. Others,,Software Systems,1,1,1,1,1,1,1,1,0,1,0,1,6,1. domain expert,3,1. domain expert,3,1,1,0,0,0,1,0,0,1,0,0,0,0,0,1,0,1,1,0,1,1,0,0,0,0,0,4. After the deployment,0,,
,,2021J032,An Evaluation-Focused Framework for Visualization Recommendation Algorithms,"Zeng, Zehua and Moh, Phoebe and Du, Fan and Hoffswell, Jane and Lee, Tak Yeon and Malik, Sana and Koh, Eunyee and Battle, Leilani",2021,2022,Data visualization;Visualization;Machine learning algorithms;Approximation algorithms;Task analysis;Encoding;Clustering algorithms;Visualization Tools;Visualization Recommendation Algorithms,"Although we have seen a proliferation of algorithms for recommending visualizations, these algorithms are rarely compared with one another, making it difficult to ascertain which algorithm is best for a given visual analysis scenario. Though several formal frameworks have been proposed in response, we believe this issue persists because visualization recommendation algorithms are inadequately specified from an evaluation perspective. In this paper, we propose an evaluation-focused framework to contextualize and compare a broad range of visualization recommendation algorithms. We present the structure of our framework, where algorithms are specified using three components: (1) a graph representing the full space of possible visualization designs, (2) the method used to traverse the graph for potential candidates for recommendation, and (3) an oracle used to rank candidate designs. To demonstrate how our framework guides the formal comparison of algorithmic performance, we not only theoretically compare five existing representative recommendation algorithms, but also empirically compare four new algorithms generated based on our findings from the theoretical comparison. Our results show that these algorithms behave similarly in terms of user performance, highlighting the need for more rigorous formal comparisons of recommendation algorithms to further clarify their benefits in various analysis scenarios.",10.1109/TVCG.2021.3114814,,TRUE,TRUE,TRUE,T,T,F,C2,DROP,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
379,137,2021J033,Visual Analysis of Hyperproperties for Understanding Model Checking Results,"Horak, Tom and Coenen, Norine and Metzger, Niklas and Hahn, Christopher and Flemisch, Tamara and MÃ©ndez, JuliÃ¡n and Dimov, Dennis and Finkbeiner, Bernd and Dachselt, Raimund",2021,2022,Model checking;Visualization;Integrated circuit modeling;Tools;Computational modeling;Encoding;Process control;Analyzing Counterexamples;Hyperproperties;Multiple Coordinate Views;Explainable Formal Methods,"Model checkers provide algorithms for proving that a mathematical model of a system satisfies a given specification. In case of a violation, a counterexample that shows the erroneous behavior is returned. Understanding these counterexamples is challenging, especially for hyperproperty specifications, i.e., specifications that relate multiple executions of a system to each other. We aim to facilitate the visual analysis of such counterexamples through our HyperVis tool, which provides interactive visualizations of the given model, specification, and counterexample. Within an iterative and interdisciplinary design process, we developed visualization solutions that can effectively communicate the core aspects of the model checking result. Specifically, we introduce graphical representations of binary values for improving pattern recognition, color encoding for better indicating related aspects, visually enhanced textual descriptions, as well as extensive cross-view highlighting mechanisms. Further, through an underlying causal analysis of the counterexample, we are also able to identify values that contributed to the violation and use this knowledge for both improved encoding and highlighting. Finally, the analyst can modify both the specification of the hyperproperty and the system directly within HyperVis and initiate the model checking of the new version. In combination, these features notably support the analyst in understanding the error leading to the counterexample as well as iterating the provided system and specification. We ran multiple case studies with HyperVis and tested it with domain experts in qualitative feedback sessions. The participants' positive feedback confirms the considerable improvement over the manual, text-based status quo and the value of the tool for explaining hyperproperties.",10.1109/TVCG.2021.3114866,,TRUE,TRUE,TRUE,,T,F,C2,KEEP,1,19. Others,,Computer Systems,1,1,1,1,1,0,1,1,0,0,0,1,6,1. domain expert,6,,,0,1,0,0,0,1,0,0,1,0,0,0,0,1,0,1,1,1,0,1,1,0,0,0,0,0,4. After the deployment,0,,
383,138,2021J035,VBridge: Connecting the Dots Between Features and Data to Explain Healthcare Models,"Cheng, Furui and Liu, Dongyu and Du, Fan and Lin, Yanna and Zytek, Alexandra and Li, Haomin and Qu, Huamin and Veeramachaneni, Kalyan",2021,2022,Predictive models;Decision making;Tools;Computational modeling;Visual analytics;Hospitals;Task analysis;Explainable Artificial Intelligence;Healthcare;Visual Analytics;Decision Making,"Machine learning (ML) is increasingly applied to Electronic Health Records (EHRs) to solve clinical prediction tasks. Although many ML models perform promisingly, issues with model transparency and interpretability limit their adoption in clinical practice. Directly using existing explainable ML techniques in clinical settings can be challenging. Through literature surveys and collaborations with six clinicians with an average of 17 years of clinical experience, we identified three key challenges, including clinicians' unfamiliarity with ML features, lack of contextual information, and the need for cohort-level evidence. Following an iterative design process, we further designed and developed VBridge, a visual analytics tool that seamlessly incorporates ML explanations into clinicians' decision-making workflow. The system includes a novel hierarchical display of contribution-based feature explanations and enriched interactions that connect the dots between ML features, explanations, and data. We demonstrated the effectiveness of VBridge through two case studies and expert interviews with four clinicians, showing that visually associating model explanations with patients' situational records can help clinicians better interpret and use model predictions when making clinician decisions. We further derived a list of design implications for developing future explainable ML tools to support clinical decision-making.",10.1109/TVCG.2021.3114836,,TRUE,TRUE,TRUE,,T,F,C2,KEEP,1,1. AI (Machine Learning/Deep Learning/Data Mining),10. Healthcare and medical imaging,"Machine Learning, Healthcare",0,1,1,1,1,1,1,1,1,0,0,1,6,1. domain expert,2,1. domain expert,4,1,1,0,0,0,1,0,0,1,0,1,0,0,0,1,0,0,1,0,1,1,0,0,0,0,0,4. After the deployment,0,,
387,139,2021J037,GlyphCreator: Towards Example-based Automatic Generation of Circular Glyphs,"Ying, Lu and Tangl, Tan and Luo, Yuzhe and Shen, Lvkeshen and Xie, Xiao and Yu, Lingyun and Wu, Yingcai",2021,2022,Data visualization;Visualization;Layout;Deep learning;Data mining;Tools;Task analysis;Glyph-based visualization;machine learning;automatic visualization,"Circular glyphs are used across disparate fields to represent multidimensional data. However, although these glyphs are extremely effective, creating them is often laborious, even for those with professional design skills. This paper presents GlyphCreator, an interactive tool for the example-based generation of circular glyphs. Given an example circular glyph and multidimensional input data, GlyphCreator promptly generates a list of design candidates, any of which can be edited to satisfy the requirements of a particular representation. To develop GlyphCreator, we first derive a design space of circular glyphs by summarizing relationships between different visual elements. With this design space, we build a circular glyph dataset and develop a deep learning model for glyph parsing. The model can deconstruct a circular glyph bitmap into a series of visual elements. Next, we introduce an interface that helps users bind the input data attributes to visual elements and customize visual styles. We evaluate the parsing model through a quantitative experiment, demonstrate the use of GlyphCreator through two use scenarios, and validate its effectiveness through user interviews.",10.1109/TVCG.2021.3114877,,TRUE,TRUE,TRUE,T,T,F,C1,KEEP,1,,,,1,1,1,1,1,1,1,1,0,1,0,2,4,2. domain user,3,4. visual expert,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,4. After the deployment,0,,
,,2021J037,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,5. no participant,0,,,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,4. After the deployment,0,,
395,140,2021J045,VITALITY: Promoting Serendipitous Discovery of Academic Literature with Transformers & Visual Analytics,"Narechania, Arpit and Karduni, Alireza and Wesslen, Ryan and Wall, Emily",2021,2022,Bibliographies;Data visualization;Transformers;Keyword search;Internet;Tools;Visual analytics;transformers;word embeddings;literature review;web scraper;dataset;visual analytics,"There are a few prominent practices for conducting reviews of academic literature, including searching for specific keywords on Google Scholar or checking citations from some initial seed paper(s). These approaches serve a critical purpose for academic literature reviews, yet there remain challenges in identifying relevant literature when similar work may utilize different terminology (e.g., mixed-initiative visual analytics papers may not use the same terminology as papers on model-steering, yet the two topics are relevant to one another). In this paper, we introduce a system, VITALITY, intended to complement existing practices. In particular, VITALITY promotes serendipitous discovery of relevant literature using transformer language models, allowing users to find semantically similar papers in a word embedding space given (1) a list of input paper(s) or (2) a working abstract. VITALITY visualizes this document-level embedding space in an interactive 2-D scatterplot using dimension reduction. VITALITY also summarizes meta information about the document corpus or search query, including keywords and co-authors, and allows users to save and export papers for use in a literature review. We present qualitative findings from an evaluation of VITALITY, suggesting it can be a promising complementary technique for conducting academic literature reviews. Furthermore, we contribute data from 38 popular data visualization publication venues in VITALITY, and we provide scrapers for the open-source community to continue to grow the list of supported venues.",10.1109/TVCG.2021.3114820,,TRUE,TRUE,TRUE,T,,F,C1,KEEP,1,,,academic literature review,1,1,1,1,1,1,1,1,0,1,0,2,10,2. domain user,4,,,1,0,0,0,0,1,0,0,0,0,1,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,3. Before the deployment (During the development and refinement phrase ONLY),1,,
,,2021J045,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,6,,,0,0,0,0,0,1,0,0,0,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,4. After the deployment,0,,
396,141,2021J047,E-ffective: A Visual Analytic System for Exploring the Emotion and Effectiveness of Inspirational Speeches,"Maher, Kevin and Huang, Zeyuan and Song, Jiancheng and Deng, Xiaoming and Lai, Yu-Kun and Ma, Cuixia and Wang, Hao and Liu, Yong-Jin and Wang, Hongan",2021,2022,Speech;Public speaking;Interviews;Measurement;Data visualization;Visual analytics;Task analysis;Affective visualization;multimodal analysis;speech effectiveness,"What makes speeches effective has long been a subject for debate, and until today there is broad controversy among public speaking experts about what factors make a speech effective as well as the roles of these factors in speeches. Moreover, there is a lack of quantitative analysis methods to help understand effective speaking strategies. In this paper, we propose E-ffective, a visual analytic system allowing speaking experts and novices to analyze both the role of speech factors and their contribution in effective speeches. From interviews with domain experts and investigating existing literature, we identified important factors to consider in inspirational speeches. We obtained the generated factors from multi-modal data that were then related to effectiveness data. Our system supports rapid understanding of critical factors in inspirational speeches, including the influence of emotions by means of novel visualization methods and interaction. Two novel visualizations include E-spiral (that shows the emotional shifts in speeches in a visually compact way) and E-script (that connects speech content with key speech delivery information). In our evaluation we studied the influence of our system on experts' domain knowledge about speech factors. We further studied the usability of the system by speaking novices and experts on assisting analysis of inspirational speech effectiveness.",10.1109/TVCG.2021.3114789,,TRUE,TRUE,TRUE,T,,F,C1,KEEP,1,12. Journalism and media,,communication and rhetoric,0,1,1,1,1,1,1,1,0,0,0,2,23,1. domain expert,7,,,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,2. Before the deployment (Before or during design phase ONLY),0,,
,,2021J047,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,8,2. domain user,8,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,1,1,1,0,1,1,1,0,0,0,0,4. After the deployment,0,,
405,142,2021J048,Explanatory Journeys: Visualising to Understand and Explain Administrative Justice Paths of Redress,"Roberts, Jonathan C. and Butcher, Peter and Sherlock, Ann and Nason, Sarah",2021,2022,Data visualization;Law;Visualization;Conferences;Tools;Education;Navigation;Explanatory Visualisation;Administrative Justice;Law;Law Visualisation,"Administrative justice concerns the relationships between individuals and the state. It includes redress and complaints on decisions of a child's education, social care, licensing, planning, environment, housing and homelessness. However, if someone has a complaint or an issue, it is challenging for people to understand different possible redress paths and explore what path is suitable for their situation. Explanatory visualisation has the potential to display these paths of redress in a clear way, such that people can see, understand and explore their options. The visualisation challenge is further complicated because information is spread across many documents, laws, guidance and policies and requires judicial interpretation. Consequently, there is not a single database of paths of redress. In this work we present how we have co-designed a system to visualise administrative justice paths of redress. Simultaneously, we classify, collate and organise the underpinning data, from expert workshops, heuristic evaluation and expert critical reflection. We make four contributions: (i) an application design study of the explanatory visualisation tool (Artemus), (ii) coordinated and co-design approach to aggregating the data, (iii) two in-depth case studies in housing and education demonstrating explanatory paths of redress in administrative law, and (iv) reflections on the expert co-design process and expert data gathering and explanatory visualisation for administrative justice and law.",10.1109/TVCG.2021.3114818,,TRUE,TRUE,TRUE,T,T,T,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
407,143,2021J050,Attribute-based Explanation of Non-Linear Embeddings of High-Dimensional Data,"Sohns, Jan-Tobias and Schmitt, Michaela and Jirasek, Fabian and Hasse, Hans and Leitte, Heike",2021,2022,Data visualization;Visualization;Task analysis;Data analysis;Topology;Image color analysis;Dimensionality reduction;Dimensionality reduction;embedding;augmented projections;point set contours;explainable artificial intelligence,"Embeddings of high-dimensional data are widely used to explore data, to verify analysis results, and to communicate information. Their explanation, in particular with respect to the input attributes, is often difficult. With linear projects like PCA the axes can still be annotated meaningfully. With non-linear projections this is no longer possible and alternative strategies such as attribute-based color coding are required. In this paper, we review existing augmentation techniques and discuss their limitations. We present the Non-Linear Embeddings Surveyor (NoLiES) that combines a novel augmentation strategy for projected data (rangesets) with interactive analysis in a small multiples setting. Rangesets use a set-based visualization approach for binned attribute values that enable the user to quickly observe structure and detect outliers. We detail the link between algebraic topology and rangesets and demonstrate the utility of NoLiES in case studies with various challenges (complex attribute value distribution, many attributes, many data points) and a real-world application to understand latent features of matrix completion in thermodynamics.",10.1109/TVCG.2021.3114870,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,,,,1,1,1,0,1,0,1,1,1,0,0,1,5,1. domain expert,5,,,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,4. After the deployment,0,,
,,2021J059,Automatic Polygon Layout for Primal-Dual Visualization of Hypergraphs,"Qu, Botong and Zhang, Eugene and Zhang, Yue",2021,2022,Layout;Data visualization;Optimization;Visualization;Manuals;Linear programming;Electrical engineering;Hypergraph visualization;N-ary relationships;optimization;polygon layout;duality;primal-dual visualization,"N-ary relationships, which relate $N$ entities where $N$ is not necessarily two, can be visually represented as polygons whose vertices are the entities of the relationships. Manually generating a high-quality layout using this representation is labor-intensive. In this paper, we provide an automatic polygon layout generation algorithm for the visualization of N-ary relationships. At the core of our algorithm is a set of objective functions motivated by a number of design principles that we have identified. These objective functions are then used in an optimization framework that we develop to achieve high-quality layouts. Recognizing the duality between entities and relationships in the data, we provide a second visualization in which the roles of entities and relationships in the original data are reversed. This can lead to additional insight about the data. Furthermore, we enhance our framework for a joint optimization on the primal layout (original data) and the dual layout (where the roles of entities and relationships are reversed). This allows users to inspect their data using two complementary views. We apply our visualization approach to a number of datasets that include co-authorship data and social contact pattern data.",10.1109/TVCG.2021.3114759,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
408,144,2021J060,CoUX: Collaborative Visual Analysis of Think-Aloud Usability Test Videos for Digital Interfaces,"Soure, Ehsan Jahangirzadeh and Kuang, Emily and Fan, Mingming and Zhao, Jian",2021,2022,Collaboration;Usability;Videos;Feature extraction;Tools;Acoustics;Machine learning;User experience;usability problems;think-aloud;video analysis;machine learning;visual analytics;collaboration,"Reviewing a think-aloud video is both time-consuming and demanding as it requires UX (user experience) professionals to attend to many behavioral signals of the user in the video. Moreover, challenges arise when multiple UX professionals need to collaborate to reduce bias and errors. We propose a collaborative visual analytics tool, CoUX, to facilitate UX evaluators collectively reviewing think-aloud usability test videos of digital interfaces. CoUX seamlessly supports usability problem identification, annotation, and discussion in an integrated environment. To ease the discovery of usability problems, CoUX visualizes a set of problem-indicators based on acoustic, textual, and visual features extracted from the video and audio of a think-aloud session with machine learning. CoUX further enables collaboration amongst UX evaluators for logging, commenting, and consolidating the discovered problems with a chatbox-like user interface. We designed CoUX based on a formative study with two UX experts and insights derived from the literature. We conducted a user study with six pairs of UX practitioners on collaborative think-aloud video analysis tasks. The results indicate that CoUX is useful and effective in facilitating both problem identification and collaborative teamwork. We provide insights into how different features of CoUX were used to support both independent analysis and collaboration. Furthermore, our work highlights opportunities to improve collaborative usability test video analysis.",10.1109/TVCG.2021.3114822,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,7. Engineering and design,,ux,0,1,1,1,1,1,1,1,0,1,0,2,14,1. domain expert,2,,,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,2. Before the deployment (Before or during design phase ONLY),0,,
,,2021J060,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,2. domain user,12,,,0,1,0,1,1,1,0,0,0,0,1,1,0,0,1,1,1,1,0,0,0,0,0,0,0,1,4. After the deployment,0,,
,,2021J061,Professional Differences: A Comparative Study of Visualization Task Performance and Spatial Ability Across Disciplines,"Hall, Kyle Wm. and Kouroupis, Anthony and Bezerianos, Anastasia and Szafir, Danielle Albers and Collins, Christopher",2021,2022,Data visualization;Task analysis;Visualization;Cognition;Training;Three-dimensional displays;Navigation;visualization;spatial ability;perception;task performance;discipline;domain-specific;empirical evaluation,"Problem-driven visualization work is rooted in deeply understanding the data, actors, processes, and workflows of a target domain. However, an individual's personality traits and cognitive abilities may also influence visualization use. Diverse user needs and abilities raise natural questions for specificity in visualization design: Could individuals from different domains exhibit performance differences when using visualizations? Are any systematic variations related to their cognitive abilities? This study bridges domain-specific perspectives on visualization design with those provided by cognition and perception. We measure variations in visualization task performance across chemistry, computer science, and education, and relate these differences to variations in spatial ability. We conducted an online study with over 60 domain experts consisting of tasks related to pie charts, isocontour plots, and 3D scatterplots, and grounded by a well-documented spatial ability test. Task performance (correctness) varied with profession across more complex visualizations (isocontour plots and scatterplots), but not pie charts, a comparatively common visualization. We found that correctness correlates with spatial ability, and the professions differ in terms of spatial ability. These results indicate that domains differ not only in the specifics of their data and tasks, but also in terms of how effectively their constituent members engage with visualizations and their cognitive traits. Analyzing participants' confidence and strategy comments suggests that focusing on performance neglects important nuances, such as differing approaches to engage with even common visualizations and potential skill transference. Our findings offer a fresh perspective on discipline-specific visualization with specific recommendations to help guide visualization design that celebrates the uniqueness of the disciplines and individuals we seek to serve.",10.1109/TVCG.2021.3114805,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2021J064,Untidy Data: The Unreasonable Effectiveness of Tables,"Bartram, Lyn and Correll, Michael and Tory, Melanie",2021,2022,Tools;Data visualization;Visual analytics;Cleaning;Annotations;Affordances;Organizations;Data practices;Tabular data;Interview study;Visualization;Analytics;Data workers;Sensemaking,"Working with data in table form is usually considered a preparatory and tedious step in the sensemaking pipeline; a way of getting the data ready for more sophisticated visualization and analytical tools. But for many people, spreadsheets â€” the quintessential table tool â€” remain a critical part of their information ecosystem, allowing them to interact with their data in ways that are hidden or abstracted in more complex tools. This is particularly true for data workers [61], people who work with data as part of their job but do not identify as professional analysts or data scientists. We report on a qualitative study of how these workers interact with and reason about their data. Our findings show that data tables serve a broader purpose beyond data cleanup at the initial stage of a linear analytic flow: users want to see and â€œget their hands onâ€ the underlying data throughout the analytics process, reshaping and augmenting it to support sensemaking. They reorganize, mark up, layer on levels of detail, and spawn alternatives within the context of the base data. These direct interactions and human-readable table representations form a rich and cognitively important part of building understanding of what the data mean and what they can do with it. We argue that interactive tables are an important visualization idiom in their own right; that the direct data interaction they afford offers a fertile design space for visual analytics; and that sense making can be enriched by more flexible human-data interaction than is currently supported in visual analytics tools.",10.1109/TVCG.2021.3114830,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2021J066,Rethinking the Ranks of Visual Channels,"McColeman, Caitlyn M. and Yang, Fumeng and Brady, Timothy F. and Franconeri, Steven",2021,2022,"Task analysis;Visualization;Bars;Data visualization;Memory management;Measurement uncertainty;Correlation;DataType Agnostic;Human-Subjects Quantitative Studies;Perception & Cognition;Charts, Diagrams, and Plots","Data can be visually represented using visual channels like position, length or luminance. An existing ranking of these visual channels is based on how accurately participants could report the ratio between two depicted values. There is an assumption that this ranking should hold for different tasks and for different numbers of marks. However, there is surprisingly little existing work that tests this assumption, especially given that visually computing ratios is relatively unimportant in real-world visualizations, compared to seeing, remembering, and comparing trends and motifs, across displays that almost universally depict more than two values. To simulate the information extracted from a glance at a visualization, we instead asked participants to immediately reproduce a set of values from memory after they were shown the visualization. These values could be shown in a bar graph (position (bar)), line graph (position (line)), heat map (luminance), bubble chart (area), misaligned bar graph (length), or â€˜wind mapâ€™ (angle). With a Bayesian multilevel modeling approach, we show how the rank positions of visual channels shift across different numbers of marks (2, 4 or 8) and for bias, precision, and error measures. The ranking did not hold, even for reproductions of only 2 marks, and the new probabilistic ranking was highly inconsistent for reproductions of different numbers of marks. Other factors besides channel choice had an order of magnitude more influence on performance, such as the number of values in the series (e.g., more marks led to larger errors), or the value of each mark (e.g., small values were systematically overestimated). Every visual channel was worse for displays with 8 marks than 4, consistent with established limits on visual memory. These results point to the need for a body of empirical studies that move beyond two-value ratio judgments as a baseline for reliably ranking the quality of a visual channel, including testing new tasks (detection of trends or motifs), timescales (immediate computation, or later comparison), and the number of values (from a handful, to thousands).",10.1109/TVCG.2021.3114684,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
409,145,2021J069,DIEL: Interactive Visualization Beyond the Here and Now,"Wu, Yifan and Chang, Remco and Hellerstein, Joseph M. and Satyanarayan, Arvind and Wu, Eugene",2021,2022,Data visualization;Distributed databases;Databases;Programming;Libraries;Visual databases;Servers;Interactive Visualization Toolkit/Library;Scalability;Asynchrony,"Interactive visualization design and research have primarily focused on local data and synchronous events. However, for more complex use cases-e.g., remote database access and streaming data sources-developers must grapple with distributed data and asynchronous events. Currently, constructing these use cases is difficult and time-consuming; developers are forced to operationally program low-level details like asynchronous database querying and reactive event handling. This approach is in stark contrast to modern methods for browser-based interactive visualization, which feature high-level declarative specifications. In response, we present DIEL, a declarative framework that supports asynchronous events over distributed data. As in many declarative languages, DIEL developers specify only what data they want, rather than procedural steps for how to assemble it. Uniquely, DIEL models asynchronous events (e.g., user interactions, server responses) as streams of data that are captured in event logs. To specify the state of a visualization at any time, developers write declarative queries over the data and event logs; DIEL compiles and optimizes a corresponding dataflow graph, and automatically generates necessary low-level distributed systems details. We demonstrate DIEL'S performance and expressivity through example interactive visualizations that make diverse use of remote data and asynchronous events. We further evaluate DIEL'S usability using the Cognitive Dimensions of Notations framework, revealing wins such as ease of change, and compromises such as premature commitments.",10.1109/TVCG.2021.3114796,,TRUE,TRUE,TRUE,T,,F,C1,DROP,0,,,,0,1,1,0,0,0,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2021J070,VizSnippets: Compressing Visualization Bundles Into Representative Previews for Browsing Visualization Collections,"Oppermann, Michael and Munzner, Tamara",2021,2022,Data visualization;Visualization;Tools;Pipelines;Layout;Inspection;Image coding;visualization collections;visualization bundles;result snippets;visual inspection,"Visualization collections, accessed by platforms such as Tableau Online or Power Bl, are used by millions of people to share and access diverse analytical knowledge in the form of interactive visualization bundles. Result snippets, compact previews of these bundles, are presented to users to help them identify relevant content when browsing collections. Our engagement with Tableau product teams and review of existing snippet designs on five platforms showed us that current practices fail to help people judge the relevance of bundles because they include only the title and one image. Users frequently need to undertake the time-consuming endeavour of opening a bundle within its visualization system to examine its many views and dashboards. In response, we contribute the first systematic approach to visualization snippet design. We propose a framework for snippet design that addresses eight key challenges that we identify. We present a computational pipeline to compress the visual and textual content of bundles into representative previews that is adaptive to a provided pixel budget and provides high information density with multiple images and carefully chosen keywords. We also reflect on the method of visual inspection through random sampling to gain confidence in model and parameter choices.",10.1109/TVCG.2021.3114841,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
410,146,2021J073,Human-in-the-loop Extraction of Interpretable Concepts in Deep Learning Models,"Zhao, Zhenge and Xu, Panpan and Scheidegger, Carlos and Ren, Liu",2021,2022,Visualization;Data models;Analytical models;Predictive models;Computational modeling;Deep learning;Task analysis;Visual Data Exploration;Deep Neural Network;Model Interpretation;Explainable AI,"The interpretation of deep neural networks (DNNs) has become a key topic as more and more people apply them to solve various problems and making critical decisions. Concept-based explanations have recently become a popular approach for post-hoc interpretation of DNNs. However, identifying human-understandable visual concepts that affect model decisions is a challenging task that is not easily addressed with automatic approaches. We present a novel human-in-the-Ioop approach to generate user-defined concepts for model interpretation and diagnostics. Central to our proposal is the use of active learning, where human knowledge and feedback are combined to train a concept extractor with very little human labeling effort. We integrate this process into an interactive system, ConceptExtract. Through two case studies, we show how our approach helps analyze model behavior and extract human-friendly concepts for different machine learning tasks and datasets and how to use these concepts to understand the predictions, compare model performance and make suggestions for model refinement. Quantitative experiments show that our active learning approach can accurately extract meaningful visual concepts. More importantly, by identifying visual concepts that negatively affect model performance, we develop the corresponding data augmentation strategy that consistently improves model performance.",10.1109/TVCG.2021.3114837,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,1. AI (Machine Learning/Deep Learning/Data Mining),,xai,0,1,1,0,1,0,1,1,1,0,0,2,1,1. domain expert,1,,,0,1,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,0,0,1,1,0,1,0,0,4. After the deployment,0,,
,,2021J073,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,5. no participant,0,,,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,4. After the deployment,0,,
421,147,2021J075,M2Lens: Visualizing and Explaining Multimodal Models for Sentiment Analysis,"Wang, Xingbo and He, Jianben and Jin, Zhihua and Yang, Muqiao and Wang, Yong and Qu, Huamin",2021,2022,Analytical models;Sentiment analysis;Computational modeling;Predictive models;Data models;Lenses;Communication channels;Multimodal models;sentiment analysis;explainable machine learning,"Multimodal sentiment analysis aims to recognize people's attitudes from multiple communication channels such as verbal content (i.e., text), voice, and facial expressions. It has become a vibrant and important research topic in natural language processing. Much research focuses on modeling the complex intra- and inter-modal interactions between different communication channels. However, current multimodal models with strong performance are often deep-learning-based techniques and work like black boxes. It is not clear how models utilize multimodal information for sentiment predictions. Despite recent advances in techniques for enhancing the explainability of machine learning models, they often target unimodal scenarios (e.g., images, sentences), and little research has been done on explaining multimodal models. In this paper, we present an interactive visual analytics system, M2 Lens, to visualize and explain multimodal models for sentiment analysis. M2 Lens provides explanations on intra- and inter-modal interactions at the global, subset, and local levels. Specifically, it summarizes the influence of three typical interaction types (i.e., dominance, complement, and conflict) on the model predictions. Moreover, M2 Lens identifies frequent and influential multimodal features and supports the multi-faceted exploration of model behaviors from language, acoustic, and visual modalities. Through two case studies and expert interviews, we demonstrate our system can help users gain deep insights into the multimodal models for sentiment analysis.",10.1109/TVCG.2021.3114794,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,1. AI (Machine Learning/Deep Learning/Data Mining),,explainable machine learning,0,1,1,1,1,1,1,1,1,0,0,1,3,1. domain expert,3,,,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,0,1,1,0,0,1,0,0,0,0,0,4. After the deployment,0,,
422,148,2021J077,Augmenting Sports Videos with VisCommentator,"Chen, Zhutian and Ye, Shuainan and Chu, Xiangtong and Xia, Haijun and Zhang, Hui and Qu, Huamin and Wu, Yingcai",2021,2022,Sports;Data visualization;Visualization;Tools;Data mining;TV;Data models;Augmented Sports Videos;Video-based Visualization;Sports visualization;Intelligent Design Tool;Storytelling,"Visualizing data in sports videos is gaining traction in sports analytics, given its ability to communicate insights and explicate player strategies engagingly. However, augmenting sports videos with such data visualizations is challenging, especially for sports analysts, as it requires considerable expertise in video editing. To ease the creation process, we present a design space that characterizes augmented sports videos at an element-level (what the constituents are) and clip-level (how those constituents are organized). We do so by systematically reviewing 233 examples of augmented sports videos collected from TV channels, teams, and leagues. The design space guides selection of data insights and visualizations for various purposes. Informed by the design space and close collaboration with domain experts, we design VisCommentator, a fast prototyping tool, to eases the creation of augmented table tennis videos by leveraging machine learning-based data extractors and design space-based visualization recommendations. With VisCommentator, sports analysts can create an augmented video by selecting the data to visualize instead of manually drawing the graphical marks. Our system can be generalized to other racket sports (e.g., tennis, badminton) once the underlying datasets and models are available. A user study with seven domain experts shows high satisfaction with our system, confirms that the participants can reproduce augmented sports videos in a short period, and provides insightful implications into future improvements and opportunities.",10.1109/TVCG.2021.3114806,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,17. Sports and entertainment,,,0,1,1,1,1,1,1,1,0,0,0,2,12,3. general public,5,,,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2. Before the deployment (Before or during design phase ONLY),0,,
,,2021J077,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,2. domain user,7,,,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,1,0,1,0,1,1,0,0,0,0,0,4. After the deployment,0,,
423,149,2021J078,TacticFlow: Visual Analytics of Ever-Changing Tactics in Racket Sports,"Wu, Jiang and Liu, Dongyu and Guo, Ziyang and Xu, Qingyang and Wu, Yingcai",2021,2022,Sports;Data visualization;Visual analytics;Data models;Usability;Task analysis;Pipelines;Sports Analytics;Multivariate Event Sequence;Sequential Pattern Mining;Progression Analysis,"Event sequence mining is often used to summarize patterns from hundreds of sequences but faces special challenges when handling racket sports data. In racket sports (e.g., tennis and badminton), a player hitting the ball is considered a multivariate event consisting of multiple attributes (e.g., hit technique and ball position). A rally (i.e., a series of consecutive hits beginning with one player serving the ball and ending with one player winning a point) thereby can be viewed as a multivariate event sequence. Mining frequent patterns and depicting how patterns change over time is instructive and meaningful to players who want to learn more short-term competitive strategies (i.e., tactics) that encompass multiple hits. However, players in racket sports usually change their tactics rapidly according to the opponent's reaction, resulting in ever-changing tactic progression. In this work, we introduce a tailored visualization system built on a novel multivariate sequence pattern mining algorithm to facilitate explorative identification and analysis of various tactics and tactic progression. The algorithm can mine multiple non-overlapping multivariate patterns from hundreds of sequences effectively. Based on the mined results, we propose a glyph-based Sankey diagram to visualize the ever-changing tactic progression and support interactive data exploration. Through two case studies with four domain experts in tennis and badminton, we demonstrate that our system can effectively obtain insights about tactic progression in most racket sports. We further discuss the strengths and the limitations of our system based on domain experts' feedback.",10.1109/TVCG.2021.3114832,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,17. Sports and entertainment,,,0,1,1,1,1,1,1,1,0,0,0,2,4,5. no participant,0,,,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,4. After the deployment,0,,
,,2021J078,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,4,,,0,1,0,0,0,1,0,0,0,0,1,1,0,0,1,0,0,1,0,0,1,0,0,0,0,0,4. After the deployment,0,,
,,2021J079,VideoModerator: A Risk-aware Framework for Multimodal Video Moderation in E-Commerce,"Tang, Tan and Wu, Yanhong and Wu, Yingcai and Yu, Lingyun and Li, Yuhong",2021,2022,Visualization;Task analysis;Visual analytics;Machine learning;Motion pictures;Feature extraction;Data mining;video moderation;video visualization;e-commerce livestreaming,"Video moderation, which refers to remove deviant or explicit content from e-commerce livestreams, has become prevalent owing to social and engaging features. However, this task is tedious and time consuming due to the difficulties associated with watching and reviewing multimodal video content, including video frames and audio clips. To ensure effective video moderation, we propose VideoModerator, a risk-aware framework that seamlessly integrates human knowledge with machine insights. This framework incorporates a set of advanced machine learning models to extract the risk-aware features from multimodal video content and discover potentially deviant videos. Moreover, this framework introduces an interactive visualization interface with three views, namely, a video view, a frame view, and an audio view. In the video view, we adopt a segmented timeline and highlight high-risk periods that may contain deviant information. In the frame view, we present a novel visual summarization method that combines risk-aware features and video context to enable quick video navigation. In the audio view, we employ a storyline-based design to provide a multi-faceted overview which can be used to explore audio content. Furthermore, we report the usage of VideoModerator through a case scenario and conduct experiments and a controlled user study to validate its effectiveness.",10.1109/TVCG.2021.3114781,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,12. Journalism and media,,e-commerce,0,1,1,1,1,1,1,1,0,1,0,4,93,2. domain user,80,,,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,3. Before the deployment (During the development and refinement phrase ONLY),1,,
,,2021J079,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,1,,,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,1,1,0,1,0,0,0,0,0,4. After the deployment,0,,
,,2021J079,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,5. no participant,0,,,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,4. After the deployment,0,,
,,2021J079,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,2. domain user,12,,,0,1,0,0,1,1,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,1,0,0,0,0,4. After the deployment,0,,
427,150,2021J080,A Visualization Approach for Monitoring Order Processing in E-Commerce Warehouse,"Tang, Junxiu and Zhou, Yuhua and Tang, Tan and Weng, Di and Xie, Boyang and Yu, Lingyun and Zhang, Huaqiang and Wu, Yingcai",2021,2022,Data visualization;Monitoring;Real-time systems;Schedules;Delays;Warehousing;Visual analytics;Streaming data;time-series data;e-commerce warehouse;order processing,"The efficiency of warehouses is vital to e-commerce. Fast order processing at the warehouses ensures timely deliveries and improves customer satisfaction. However, monitoring, analyzing, and manipulating order processing in the warehouses in real time are challenging for traditional methods due to the sheer volume of incoming orders, the fuzzy definition of delayed order patterns, and the complex decision-making of order handling priorities. In this paper, we adopt a data-driven approach and propose OrderMonitor, a visual analytics system that assists warehouse managers in analyzing and improving order processing efficiency in real time based on streaming warehouse event data. Specifically, the order processing pipeline is visualized with a novel pipeline design based on the sedimentation metaphor to facilitate real-time order monitoring and suggest potentially abnormal orders. We also design a novel visualization that depicts order timelines based on the Gantt charts and Marey's graphs. Such a visualization helps the managers gain insights into the performance of order processing and find major blockers for delayed orders. Furthermore, an evaluating view is provided to assist users in inspecting order details and assigning priorities to improve the processing performance. The effectiveness of OrderMonitor is evaluated with two case studies on a real-world warehouse dataset.",10.1109/TVCG.2021.3114878,,TRUE,TRUE,TRUE,T,T,F,C1,KEEP,1,12. Journalism and media,,e-commerce,0,1,1,1,1,1,1,1,0,0,0,2,5,1. domain expert,2,,,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,2. Before the deployment (Before or during design phase ONLY),1,,
,,2021J080,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,2,4. visual expert,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,0,0,1,0,0,0,0,0,4. After the deployment,0,,
428,151,2021J081,MiningVis: Visual Analytics of the Bitcoin Mining Economy,"Tovanich, Natkamon and SouliÃ©, Nicolas and Heulot, Nicolas and Isenberg, Petra",2021,2022,Bitcoin;Tools;Economics;Data mining;Visual analytics;Hardware;Security;Visual analytics;Bitcoin;Bitcoin mining;mining pools;pool hopping,"We present a visual analytics tool, MiningVis, to explore the long-term historical evolution and dynamics of the Bitcoin mining ecosystem. Bitcoin is a cryptocurrency that attracts much attention but remains difficult to understand. Particularly important to the success, stability, and security of Bitcoin is a component of the system called â€œmining.â€ Miners are responsible for validating transactions and are incentivized to participate by the promise of a monetary reward. Mining pools have emerged as collectives of miners that ensure a more stable and predictable income. MiningVis aims to help analysts understand the evolution and dynamics of the Bitcoin mining ecosystem, including mining market statistics, multi-measure mining pool rankings, and pool hopping behavior. Each of these features can be compared to external data concerning pool characteristics and Bitcoin news. In order to assess the value of MiningVis, we conducted online interviews and insight-based user studies with Bitcoin miners. We describe research questions tackled and insights made by our participants and illustrate practical implications for visual analytics systems for Bitcoin mining.",10.1109/TVCG.2021.3114821,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,3. Business and finance,,bitcoin,0,1,1,1,1,1,1,1,0,0,0,1,8,2. domain user,8,,,1,1,0,0,0,1,0,0,0,1,0,0,0,1,1,1,1,1,0,0,0,0,0,0,0,1,4. After the deployment,0,,
432,152,2021J084,Sequen-C: A Multilevel Overview of Temporal Event Sequences,"Magallanes, Jessica and Stone, Tony and Morris, Paul D and Mason, Suzanne and Wood, Steven and Villa-Uriol, Maria-Cruz",2021,2022,Aggregates;Visual analytics;Feature extraction;Measurement;Data visualization;Scalability;MIMICs;Temporal event sequence visualization;clustering;hierarchical aggregation;multiple sequence alignment,"Building a visual overview of temporal event sequences with an optimal level-of-detail (i.e. simplified but informative) is an ongoing challenge - expecting the user to zoom into every important aspect of the overview can lead to missing insights. We propose a technique to build a multilevel overview of event sequences, whose granularity can be transformed across sequence clusters (vertical level-of-detail) or longitudinally (horizontal level-of-detail), using hierarchical aggregation and a novel cluster data representation Align-Score-Simplify. By default, the overview shows an optimal number of sequence clusters obtained through the average silhouette width metric - then users are able to explore alternative optimal sequence clusterings. The vertical level-of-detail of the overview changes along with the number of clusters, whilst the horizontal level-of-detail refers to the level of summarization applied to each cluster representation. The proposed technique has been implemented into a visualization system called Sequence Cluster Explorer (Sequen-C) that allows multilevel and detail-on-demand exploration through three coordinated views, and the inspection of data attributes at cluster, unique sequence, and individual sequence level. We present two case studies using real-world datasets in the healthcare domain: CUREd and MIMIC-III; which demonstrate how the technique can aid users to obtain a summary of common and deviating pathways, and explore data attributes for selected patterns.",10.1109/TVCG.2021.3114868,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,,,,1,1,1,0,1,1,1,1,0,0,0,1,3,1. domain expert,3,,,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,1,1,0,0,0,0,0,4. After the deployment,0,,
435,153,2021J085,EVis: Visually Analyzing Environmentally Driven Events,"Feng, Tinghao and Yang, Jing and Eppes, Martha-Cary and Yang, Zhaocong and Moser, Faye",2021,2022,Time series analysis;Rocks;Earth;Visual analytics;Trajectory;Heating systems;Data visualization;Multivariate Time Series;RadViz;Event Data;Visual Analytics;Earth Sciences,"Earth scientists are increasingly employing time series data with multiple dimensions and high temporal resolution to study the impacts of climate and environmental changes on Earth's atmosphere, biosphere, hydrosphere, and lithosphere. However, the large number of variables and varying time scales of antecedent conditions contributing to natural phenomena hinder scientists from completing more than the most basic analyses. In this paper, we present EVis (Environmental Visualization), a new visual analytics prototype to help scientists analyze and explore recurring environmental events (e.g. rock fracture, landslides, heat waves, floods) and their relationships with high dimensional time series of continuous numeric environmental variables, such as ambient temperature and precipitation. EVis provides coordinated scatterplots, heatmaps, histograms, and RadViz for foundational analyses. These features allow users to interactively examine relationships between events and one, two, three, or more environmental variables. EVis also provides a novel visual analytics approach to allowing users to discover temporally lagging relationships related to antecedent conditions between events and multiple variables, a critical task in Earth sciences. In particular, this latter approach projects multivariate time series onto trajectories in a 2D space using RadViz, and clusters the trajectories for temporal pattern discovery. Our case studies with rock cracking data and interviews with domain experts from a range of sub-disciplines within Earth sciences illustrate the extensive applicability and usefulness of EVis.",10.1109/TVCG.2021.3114867,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,8. Environmental sciences,,earth sciences,0,1,1,1,1,1,1,1,0,0,0,3,15,1. domain expert,1,,,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1. Before the deployment (General),1,,
,,2021J085,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,1,,,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,1,0,1,1,0,0,0,0,0,4. After the deployment,0,,
,,2021J085,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,2. domain user,13,,,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,4. After the deployment,0,,
437,154,2021J086,A Design Space for Applying the Freytag's Pyramid Structure to Data Stories,"Yang, Leni and Xu, Xian and Lan, XingYu and Liu, Ziyan and Guo, Shunan and Shi, Yang and Qu, Huamin and Cao, Nan",2021,2022,Data visualization;Visualization;Videos;Animation;Visual communication;Systematics;Data models;Freytag's Pyramid;Narrative Structure;Narrative Visualization;Data Storytelling;Data Video,"Data stories integrate compelling visual content to communicate data insights in the form of narratives. The narrative structure of a data story serves as the backbone that determines its expressiveness, and it can largely influence how audiences perceive the insights. Freytag's Pyramid is a classic narrative structure that has been widely used in film and literature. While there are continuous recommendations and discussions about applying Freytag's Pyramid to data stories, little systematic and practical guidance is available on how to use Freytag's Pyramid for creating structured data stories. To bridge this gap, we examined how existing practices apply Freytag's Pyramid by analyzing stories extracted from 103 data videos. Based on our findings, we proposed a design space of narrative patterns, data flows, and visual communications to provide practical guidance on achieving narrative intents, organizing data facts, and selecting visual design techniques through story creation. We evaluated the proposed design space through a workshop with 25 participants. Results show that our design space provides a clear framework for rapid storyboarding of data stories with Freytag's Pyramid.",10.1109/TVCG.2021.3114774,,TRUE,TRUE,TRUE,T,,F,C1,DROP,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
438,155,2021J087,Kineticharts: Augmenting Affective Expressiveness of Charts in Data Stories with Animation Design,"Lan, Xingyu and Shi, Yang and Wu, Yanqiu and Jiao, Xiaohan and Cao, Nan",2021,2022,Animation;Data visualization;Videos;Visualization;Interviews;Mood;Journalism;Animation;Storytelling;Affective Design,"Data stories often seek to elicit affective feelings from viewers. However, how to design affective data stories remains under-explored. In this work, we investigate one specific design factor, animation, and present Kineticharts, an animation design scheme for creating charts that express five positive affects: joy, amusement, surprise, tenderness, and excitement. These five affects were found to be frequently communicated through animation in data stories. Regarding each affect, we designed varied kinetic motions represented by bar charts, line charts, and pie charts, resulting in 60 animated charts for the five affects. We designed Kineticharts by first conducting a need-finding study with professional practitioners from data journalism and then analyzing a corpus of affective motion graphics to identify salient kinetic patterns. We evaluated Kineticharts through two user studies. The results suggest that Kineticharts can accurately convey affects, and improve the expressiveness of data stories, as well as enhance user engagement without hindering data comprehension compared to the animation design from DataClips, an authoring tool for data videos.",10.1109/TVCG.2021.3114775,,TRUE,TRUE,TRUE,T,T,F,C1,DROP,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2021J088,Interactive Data Comics,"Wang, Zezhong and Romat, Hugo and Chevalier, Fanny and Riche, Nathalie Henry and Murray-Rust, Dave and Bach, Benjamin",2021,2022,Data visualization;Tools;Layout;Visualization;Media;Space exploration;Navigation;Data comics;Non-linear narrative;interactive storytelling,"This paper investigates how to make data comics interactive. Data comics are an effective and versatile means for visual communication, leveraging the power of sequential narration and combined textual and visual content, while providing an overview of the storyline through panels assembled in expressive layouts. While a powerful static storytelling medium that works well on paper support, adding interactivity to data comics can enable non-linear storytelling, personalization, levels of details, explanations, and potentially enriched user experiences. This paper introduces a set of operations tailored to support data comics narrative goals that go beyond the traditional linear, immutable storyline curated by a story author. The goals and operations include adding and removing panels into pre-defined layouts to support branching, change of perspective, or access to detail-on-demand, as well as providing and modifying data, and interacting with data representation, to support personalization and reader-defined data focus. We propose a lightweight specification language, COMICSCRIPT, for designers to add such interactivity to static comics. To assess the viability of our authoring process, we recruited six professional illustrators, designers and data comics enthusiasts and asked them to craft an interactive comic, allowing us to understand authoring workflow and potential of our approach. We present examples of interactive comics in a gallery. This initial step towards understanding the design space of interactive comics can inform the design of creation tools and experiences for interactive storytelling.",10.1109/TVCG.2021.3114849,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
439,156,2021J089,Visual Arrangements of Bar Charts Influence Comparisons in Viewer Takeaways,"Xiong, Cindy and Setlur, Vidya and Bach, Benjamin and Koh, Eunyee and Lin, Kylie and Franconeri, Steven",2021,2022,Bars;Data visualization;Visualization;Tools;Semantics;Affordances;Task analysis;Comparison;perception;visual grouping;bar charts;recommendation systems;natural language interaction,"Well-designed data visualizations can lead to more powerful and intuitive processing by a viewer. To help a viewer intuitively compare values to quickly generate key takeaways, visualization designers can manipulate how data values are arranged in a chart to afford particular comparisons. Using simple bar charts as a case study, we empirically tested the comparison affordances of four common arrangements: vertically juxtaposed, horizontally juxtaposed, overlaid, and stacked. We asked participants to type out what patterns they perceived in a chart and we coded their takeaways into types of comparisons. In a second study, we asked data visualization design experts to predict which arrangement they would use to afford each type of comparison and found both alignments and mismatches with our findings. These results provide concrete guidelines for how both human designers and automatic chart recommendation systems can make visualizations that help viewers extract the â€œrightâ€ takeaway.",10.1109/TVCG.2021.3114823,,TRUE,TRUE,TRUE,,T,F,C1,DROP-empirical study,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
441,157,2021J090,"Left, Right, and Gender: Exploring Interaction Traces to Mitigate Human Biases","Wall, Emily and Narechania, Arpit and Coscia, Adam and Paden, Jamal and Endert, Alex",2021,2022,Measurement;Decision making;Task analysis;Data visualization;Visualization;History;Motion pictures;Human bias;bias mitigation;decision making;visual data analysis,"Human biases impact the way people analyze data and make decisions. Recent work has shown that some visualization designs can better support cognitive processes and mitigate cognitive biases (i.e., errors that occur due to the use of mental â€œshortcutsâ€). In this work, we explore how visualizing a user's interaction history (i.e., which data points and attributes a user has interacted with) can be used to mitigate potential biases that drive decision making by promoting conscious reflection of one's analysis process. Given an interactive scatterplot-based visualization tool, we showed interaction history in real-time while exploring data (by coloring points in the scatterplot that the user has interacted with), and in a summative format after a decision has been made (by comparing the distribution of user interactions to the underlying distribution of the data). We conducted a series of in-lab experiments and a crowd-sourced experiment to evaluate the effectiveness of interaction history interventions toward mitigating bias. We contextualized this work in a political scenario in which participants were instructed to choose a committee of 10 fictitious politicians to review a recent bill passed in the U.S. state of Georgia banning abortion after 6 weeks, where things like gender bias or political party bias may drive one's analysis process. We demonstrate the generalizability of this approach by evaluating a second decision making scenario related to movies. Our results are inconclusive for the effectiveness of interaction history (henceforth referred to as interaction traces) toward mitigating biased decision making. However, we find some mixed support that interaction traces, particularly in a summative format, can increase awareness of potential unconscious biases.",10.1109/TVCG.2021.3114862,,TRUE,TRUE,TRUE,T,T,F,C2,DROP,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
450,158,2021J091,VisQA: X-raying Vision and Language Reasoning in Transformers,"Jaunet, ThÃ©o and Kervadec, Corentin and Vuillemot, Romain and Antipov, Grigory and Baccouche, Moez and Wolf, Christian",2021,2022,Cognition;Transformers;Analytical models;Task analysis;Magnetic heads;Head;Biological system modeling;Transformers;Visual Question Answering;Visual analytics,"Visual Question Answering systems target answering open-ended textual questions given input images. They are a testbed for learning high-level reasoning with a primary use in HCI, for instance assistance for the visually impaired. Recent research has shown that state-of-the-art models tend to produce answers exploiting biases and shortcuts in the training data, and sometimes do not even look at the input image, instead of performing the required reasoning steps. We present VisQA, a visual analytics tool that explores this question of reasoning vs. bias exploitation. It exposes the key element of state-of-the-art neural models â€” attention maps in transformers. Our working hypothesis is that reasoning steps leading to model predictions are observable from attention distributions, which are particularly useful for visualization. The design process of VisQA was motivated by well-known bias examples from the fields of deep learning and vision-language reasoning and evaluated in two ways. First, as a result of a collaboration of three fields, machine learning, vision and language reasoning, and data analytics, the work lead to a better understanding of bias exploitation of neural models for VQA, which eventually resulted in an impact on its design and training through the proposition of a method for the transfer of reasoning patterns from an oracle model. Second, we also report on the design of VisQA, and a goal-oriented evaluation of VisQA targeting the analysis of a model decision process from multiple experts, providing evidence that it makes the inner workings of models accessible to users.",10.1109/TVCG.2021.3114683,,TRUE,TRUE,TRUE,T,,F,C2,KEEP,1,1. AI (Machine Learning/Deep Learning/Data Mining),,Machine Learning,0,1,1,1,1,1,1,1,1,0,0,1,6,1. domain expert,6,,,1,1,0,0,0,1,0,0,0,0,0,0,0,1,1,0,1,1,0,1,0,0,0,0,0,0,4. After the deployment,0,,
453,159,2021J094,Lumos: Increasing Awareness of Analytic Behavior during Visual Data Analysis,"Narechania, Arpit and Coscia, Adam and Wall, Emily and Endert, Alex",2021,2022,Data visualization;Visualization;Data analysis;Measurement;History;Hidden Markov models;Data models;visual data analysis;interaction traces;analytic provenance;awareness;human bias,"Visual data analysis tools provide people with the agency and flexibility to explore data using a variety of interactive functionalities. However, this flexibility may introduce potential consequences in situations where users unknowingly overemphasize or underemphasize specific subsets of the data or attribute space they are analyzing. For example, users may overemphasize specific attributes and/or their values (e.g., Gender is always encoded on the X axis), underemphasize others (e.g., Religion is never encoded), ignore a subset of the data (e.g., older people are filtered out), etc. In response, we present Lumos, a visual data analysis tool that captures and shows the interaction history with data to increase awareness of such analytic behaviors. Using in-situ (at the place of interaction) and ex-situ (in an external view) visualization techniques, Lumos provides real-time feedback to users for them to reflect on their activities. For example, Lumos highlights datapoints that have been previously examined in the same visualization (in-situ) and also overlays them on the underlying data distribution (i.e., baseline distribution) in a separate visualization (ex-situ). Through a user study with 24 participants, we investigate how Lumos helps users' data exploration and decision-making processes. We found that Lumos increases users' awareness of visual data analysis practices in real-time, promoting reflection upon and acknowledgement of their intentions and potentially influencing subsequent interactions.",10.1109/TVCG.2021.3114827,,TRUE,TRUE,TRUE,,T,F,C2,DROP,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
454,160,2021J095,Geo-Context Aware Study of Vision-Based Autonomous Driving Models and Spatial Video Data,"Jamonnak, Suphanut and Zhao, Ye and Huang, Xinyi and Amiruzzaman, Md",2021,2022,Predictive models;Data models;Autonomous vehicles;Computational modeling;Analytical models;Data visualization;Tools;Visualization System;Spatial Video;Autonomous Driving;Vision-based Deep Learning Models,"Vision-based deep learning (DL) methods have made great progress in learning autonomous driving models from large-scale crowd-sourced video datasets. They are trained to predict instantaneous driving behaviors from video data captured by on-vehicle cameras. In this paper, we develop a geo-context aware visualization system for the study of Autonomous Driving Model (ADM) predictions together with large-scale ADM video data. The visual study is seamlessly integrated with the geographical environment by combining DL model performance with geospatial visualization techniques. Model performance measures can be studied together with a set of geospatial attributes over map views. Users can also discover and compare prediction behaviors of multiple DL models in both city-wide and street-level analysis, together with road images and video contents. Therefore, the system provides a new visual exploration platform for DL model designers in autonomous driving. Use cases and domain expert evaluation show the utility and effectiveness of the visualization system.",10.1109/TVCG.2021.3114853,,TRUE,TRUE,TRUE,T,,F,C2,KEEP,1,1. AI (Machine Learning/Deep Learning/Data Mining),9. Geosciences and geospatial data,,0,1,1,1,1,0,1,1,0,0,0,1,5,1. domain expert,2,1. domain expert,3,1,1,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,0,1,0,0,0,0,0,0,4. After the deployment,0,,
458,161,2021J096,Visual Evaluation for Autonomous Driving,"Hou, Yijie and Wang, Chengshun and Wang, Junhong and Xue, Xiangyang and Zhang, Xiaolong Luke and Zhu, Jun and Wang, Dongliang and Chen, Siming",2021,2022,Autonomous vehicles;Data visualization;Tools;Visual analytics;Planning;Mathematical models;Testing;Autonomous Driving;Spatiotemporal Visual Analytics;Visual Evaluation,"Autonomous driving technologies often use state-of-the-art artificial intelligence algorithms to understand the relationship between the vehicle and the external environment, to predict the changes of the environment, and then to plan and control the behaviors of the vehicle accordingly. The complexity of such technologies makes it challenging to evaluate the performance of autonomous driving systems and to find ways to improve them. The current approaches to evaluating such autonomous driving systems largely use a single score to indicate the overall performance of a system, but domain experts have difficulties in understanding how individual components or algorithms in an autonomous driving system may contribute to the score. To address this problem, we collaborate with domain experts on autonomous driving algorithms, and propose a visual evaluation method for autonomous driving. Our method considers the data generated in all components during the whole process of autonomous driving, including perception results, planning routes, prediction of obstacles, various controlling parameters, and evaluation of comfort. We develop a visual analytics workflow to integrate an evaluation mathematical model with adjustable parameters, support the evaluation of the system from the level of the overall performance to the level of detailed measures of individual components, and to show both evaluation scores and their contributing factors. Our implemented visual analytics system provides an overview evaluation score at the beginning and shows the animation of the dynamic change of the scores at each period. Experts can interactively explore the specific component at different time periods and identify related factors. With our method, domain experts not only learn about the performance of an autonomous driving system, but also identify and access the problematic parts of each component. Our visual evaluation system can be applied to the autonomous driving simulation system and used for various evaluation cases. The results of using our system in some simulation cases and the feedback from involved domain experts confirm the usefulness and efficiency of our method in helping people gain in-depth insight into autonomous driving systems.",10.1109/TVCG.2021.3114777,,TRUE,TRUE,TRUE,T,,F,C2,KEEP,1,1. AI (Machine Learning/Deep Learning/Data Mining),,"Machine Learning, Autonomous Driving",0,1,1,1,1,1,1,1,1,0,0,1,5,1. domain expert,5,,,0,1,0,0,0,1,0,0,1,0,0,1,0,0,0,1,1,1,0,1,1,0,0,0,0,0,4. After the deployment,0,,
463,162,2021J098,Compass: Towards Better Causal Analysis of Urban Time Series,"Deng, Zikun and Weng, Di and Xie, Xiao and Bao, Jie and Zheng, Yu and Xu, Mingliang and Chen, Wei and Wu, Yingcai",2021,2022,Time series analysis;Visual analytics;Compass;Air pollution;Correlation;Urban planning;Indexes;Visual causal analysis;urban time series;causal graph analysis,"The spatial time series generated by city sensors allow us to observe urban phenomena like environmental pollution and traffic congestion at an unprecedented scale. However, recovering causal relations from these observations to explain the sources of urban phenomena remains a challenging task because these causal relations tend to be time-varying and demand proper time series partitioning for effective analyses. The prior approaches extract one causal graph given long-time observations, which cannot be directly applied to capturing, interpreting, and validating dynamic urban causality. This paper presents Compass, a novel visual analytics approach for in-depth analyses of the dynamic causality in urban time series. To develop Compass, we identify and address three challenges: detecting urban causality, interpreting dynamic causal relations, and unveiling suspicious causal relations. First, multiple causal graphs over time among urban time series are obtained with a causal detection framework extended from the Granger causality test. Then, a dynamic causal graph visualization is designed to reveal the time-varying causal relations across these causal graphs and facilitate the exploration of the graphs along the time. Finally, a tailored multi-dimensional visualization is developed to support the identification of spurious causal relations, thereby improving the reliability of causal analyses. The effectiveness of Compass is evaluated with two case studies conducted on the real-world urban datasets, including the air pollution and traffic speed datasets, and positive feedback was received from domain experts.",10.1109/TVCG.2021.3114875,,TRUE,TRUE,TRUE,T,T,F,C2,KEEP,1,9. Geosciences and geospatial data,,Urban time series data,0,1,1,1,1,1,1,1,0,0,0,1,3,1. domain expert,3,,,1,1,0,0,0,1,0,0,1,0,1,0,0,0,1,0,1,1,0,1,1,0,0,0,0,0,4. After the deployment,0,,
,,2021J103,GenNI: Human-AI Collaboration for Data-Backed Text Generation,"Strobelt, Hendrik and Kinley, Jambay and Krueger, Robert and Beyer, Johanna and Pfister, Hanspeter and Rush, Alexander M.",2021,2022,Computational modeling;Visualization;Tools;Data models;Collaboration;Task analysis;Deep learning;Tabular Data;Text/Document Data;Machine Learning;Statistics;Modelling;Simulation Applications,"Table2Text systems generate textual output based on structured data utilizing machine learning. These systems are essential for fluent natural language interfaces in tools such as virtual assistants; however, left to generate freely these ML systems often produce misleading or unexpected outputs. GenNI (Generation Negotiation Interface) is an interactive visual system for high-level human-AI collaboration in producing descriptive text. The tool utilizes a deep learning model designed with explicit control states. These controls allow users to globally constrain model generations, without sacrificing the representation power of the deep learning models. The visual interface makes it possible for users to interact with AI systems following a Refine-Forecast paradigm to ensure that the generation system acts in a manner human users find suitable. We report multiple use cases on two experiments that improve over uncontrolled generation approaches, while at the same time providing fine-grained control. A demo and source code are available at https://genni.vizhub.ai.",10.1109/TVCG.2021.3114845,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
465,163,2021J104,Knowledge Rocks: Adding Knowledge Assistance to Visualization Systems,"Lohfink, Anna-Pia and Duque Anton, Simon D. and Leitte, Heike and Garth, Christoph",2021,2022,Data visualization;Ontologies;Knowledge based systems;Lesions;Computer architecture;Rocks;Security;Knowledge-Assisted Visualization;Ontology;IT-Security,"We present Knowledge Rocks, an implementation strategy and guideline for augmenting visualization systems to knowledge-assisted visualization systems, as defined by the KAVA model. Visualization systems become more and more sophisticated. Hence, it is increasingly important to support users with an integrated knowledge base in making constructive choices and drawing the right conclusions. We support the effective reactivation of visualization software resources by augmenting them with knowledge-assistance. To provide a general and yet supportive implementation strategy, we propose an implementation process that bases on an application-agnostic architecture. This architecture is derived from existing knowledge-assisted visualization systems and the KAVA model. Its centerpiece is an ontology that is able to automatically analyze and classify input data, linked to a database to store classified instances. We discuss design decisions and advantages of the KR framework and illustrate its broad area of application in diverse integration possibilities of this architecture into an existing visualization system. In addition, we provide a detailed case study by augmenting an it-security system with knowledge-assistance facilities.",10.1109/TVCG.2021.3114687,,TRUE,TRUE,TRUE,,T,F,C2,KEEP,1,,,,1,1,1,0,1,0,1,1,0,0,0,1,1,1. domain expert,1,,,0,0,0,0,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,0,0,4. After the deployment,0,,
467,164,2021J105,A Critical Reflection on Visualization Research: Where Do Decision Making Tasks Hide?,"Dimara, Evanthia and Stasko, John",2021,2022,Data visualization;Decision making;Visualization;Task analysis;Taxonomy;Systematics;Libraries;decision making;data;visualization;visual analytics;taxonomies;task,"It has been widely suggested that a key goal of visualization systems is to assist decision making, but is this true? We conduct a critical investigation on whether the activity of decision making is indeed central to the visualization domain. By approaching decision making as a user task, we explore the degree to which decision tasks are evident in visualization research and user studies. Our analysis suggests that decision tasks are not commonly found in current visualization task taxonomies and that the visualization field has yet to leverage guidance from decision theory domains on how to study such tasks. We further found that the majority of visualizations addressing decision making were not evaluated based on their ability to assist decision tasks. Finally, to help expand the impact of visual analytics in organizational as well as casual decision making activities, we initiate a research agenda on how decision making assistance could be elevated throughout visualization research.",10.1109/TVCG.2021.3114813,,TRUE,TRUE,TRUE,T,T,F,C2,DROP,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
469,165,2021J107,Causal Support: Modeling Causal Inferences with Visualizations,"Kale, Alex and Wu, Yifan and Hullman, Jessica",2021,2022,Data visualization;Data models;Diseases;Cognition;Bars;Analytical models;Benchmark testing;Causal inference;visualization;contingency tables;data cognition,"Analysts often make visual causal inferences about possible data-generating models. However, visual analytics (VA) software tends to leave these models implicit in the mind of the analyst, which casts doubt on the statistical validity of informal visual â€œinsightsâ€. We formally evaluate the quality of causal inferences from visualizations by adopting causal supportâ€”a Bayesian cognition model that learns the probability of alternative causal explanations given some dataâ€”as a normative benchmark for causal inferences. We contribute two experiments assessing how well crowdworkers can detect (1) a treatment effect and (2) a confounding relationship. We find that chart users' causal inferences tend to be insensitive to sample size such that they deviate from our normative benchmark. While interactively cross-filtering data in visualizations can improve sensitivity, on average users do not perform reliably better with common visualizations than they do with textual contingency tables. These experiments demonstrate the utility of causal support as an evaluation framework for inferences in VA and point to opportunities to make analysts' mental models more explicit in VA software.",10.1109/TVCG.2021.3114824,,TRUE,TRUE,TRUE,T,,F,C2,DROP,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
479,166,2021J108,Sibyl: Understanding and Addressing the Usability Challenges of Machine Learning In High-Stakes Decision Making,"Zytek, Alexandra and Liu, Dongyu and Vaithianathan, Rhema and Veeramachaneni, Kalyan",2021,2022,Usability;Pediatrics;Tools;Predictive models;Decision making;Context modeling;Prediction algorithms;Machine learning;XAI;Usability;child welfare;visualization,"Machine learning (ML) is being applied to a diverse and ever-growing set of domains. In many cases, domain experts - who often have no expertise in ML or data science - are asked to use ML predictions to make high-stakes decisions. Multiple ML usability challenges can appear as result, such as lack of user trust in the model, inability to reconcile human-ML disagreement, and ethical concerns about oversimplification of complex problems to a single algorithm output. In this paper, we investigate the ML usability challenges that present in the domain of child welfare screening through a series of collaborations with child welfare screeners. Following the iterative design process between the ML scientists, visualization researchers, and domain experts (child screeners), we first identified four key ML challenges and honed in on one promising explainable ML technique to address them (local factor contributions). Then we implemented and evaluated our visual analytics tool, Sibyl, to increase the interpretability and interactivity of local factor contributions. The effectiveness of our tool is demonstrated by two formal user studies with 12 non-expert participants and 13 expert participants respectively. Valuable feedback was collected, from which we composed a list of design implications as a useful guideline for researchers who aim to develop an interpretable and interactive visualization tool for ML prediction models deployed for child welfare screeners and other similar domain experts.",10.1109/TVCG.2021.3114864,,TRUE,TRUE,TRUE,T,T,F,C2,KEEP,1,1. AI (Machine Learning/Deep Learning/Data Mining),16. Public safety and emergency management,"Machine Learning, Child Welfare",0,1,1,1,1,1,1,1,1,0,0,1,25,1. domain expert,13,2. domain user,12,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0,1,0,0,0,0,0,0,4. After the deployment,0,,
480,167,2022J004,ErgoExplorer: Interactive Ergonomic Risk Assessment from Video Collections,"FernÃ¡ndez, Manlio Massiris and RadoÅ¡, Sanjin and MatkoviÄ‡, KreÅ¡imir and GrÃ¶ller, M. Eduard and Delrieux, Claudio",2022,2023,Ergonomics;Task analysis;Employment;Monitoring;Risk management;Data visualization;Visualization;Ergonomic assessment;workplace safety;visual analysis,"Ergonomic risk assessment is now, due to an increased awareness, carried out more often than in the past. The conventional risk assessment evaluation, based on expert-assisted observation of the workplaces and manually filling in score tables, is still predominant. Data analysis is usually done with a focus on critical moments, although without the support of contextual information and changes over time. In this paper we introduce ErgoExplorer, a system for the interactive visual analysis of risk assessment data. In contrast to the current practice, we focus on data that span across multiple actions and multiple workers while keeping all contextual information. Data is automatically extracted from video streams. Based on carefully investigated analysis tasks, we introduce new views and their corresponding interactions. These views also incorporate domain-specific score tables to guarantee an easy adoption by domain experts. All views are integrated into ErgoExplorer, which relies on coordinated multiple views to facilitate analysis through interaction. ErgoExplorer makes it possible for the first time to examine complex relationships between risk assessments of individual body parts over long sessions that span multiple operations. The newly introduced approach supports analysis and exploration at several levels of detail, ranging from a general overview, down to inspecting individual frames in the video stream, if necessary. We illustrate the usefulness of the newly proposed approach applying it to several datasets.",10.1109/TVCG.2022.3209432,,TRUE,TRUE,TRUE,T,,F,C1,DROP-design study,0,10. Healthcare and medical imaging,,,0,0,0,0,1,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
481,168,2022J005,TrafficVis: Visualizing Organized Activity and Spatio-Temporal Patterns for Detecting and Labeling Human Trafficking,"Vajiac, Catalina and Chau, Duen Horng and Olligschlaeger, Andreas and Mackenzie, Rebecca and Nair, Pratheeksha and Lee, Meng-Chieh and Li, Yifei and Park, Namyong and Rabbany, Reihaneh and Faloutsos, Christos",2022,2023,Labeling;Task analysis;Law enforcement;Clustering algorithms;Metadata;Classification algorithms;Behavioral sciences;Human trafficking;Labeling;Visualization;Infoshield,"Law enforcement and domain experts can detect human trafficking (HT) in online escort websites by analyzing suspicious clusters of connected ads. How can we explain clustering results intuitively and interactively, visualizing potential evidence for experts to analyze? We present TrafficVis, the first interface for cluster-level HT detection and labeling. Developed through months of participatory design with domain experts, TrafficVis provides coordinated views in conjunction with carefully chosen backend algorithms to effectively show spatio-temporal and text patterns to a wide variety of anti-HT stakeholders. We build upon state-of-the-art text clustering algorithms by incorporating shared metadata as a signal of connected and possibly suspicious activity, then visualize the results. Domain experts can use TrafficVis to label clusters as HT, or other, suspicious, but non-HT activity such as spam and scam, quickly creating labeled datasets to enable further HT research. Through domain expert feedback and a usage scenario, we demonstrate TRAFFICVIS's efficacy. The feedback was overwhelmingly positive, with repeated high praises for the usability and explainability of our tool, the latter being vital for indicting possible criminals.",10.1109/TVCG.2022.3209403,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,16. Public safety and emergency management,,human trafficking,0,1,1,1,1,1,1,1,0,0,0,1,4,1. domain expert,4,,,0,0,0,0,1,1,0,0,0,0,0,0,0,1,1,1,0,1,0,0,0,0,0,0,1,1,4. After the deployment,0,,
483,169,2022J006,MedChemLens: An Interactive Visual Tool to Support Direction Selection in Interdisciplinary Experimental Research of Medicinal Chemistry,"Shi, Chuhan and Nie, Fei and Hu, Yicheng and Xu, Yige and Chen, Lei and Ma, Xiaojuan and Luo, Qiong",2022,2023,Drugs;Chemistry;Compounds;Visualization;Chemicals;Biomedical imaging;Data visualization;Interdisciplinary experimental science;interactive visual analysis;scientific literature data,"Interdisciplinary experimental science (e.g., medicinal chemistry) refers to the disciplines that integrate knowledge from different scientific backgrounds and involve experiments in the research process. Deciding â€œin what direction to proceedâ€ is critical for the success of the research in such disciplines, since the time, money, and resource costs of the subsequent research steps depend largely on this decision. However, such a direction identification task is challenging in that researchers need to integrate information from large-scale, heterogeneous materials from all associated disciplines and summarize the related publications of which the core contributions are often showcased in diverse formats. The task also requires researchers to estimate the feasibility and potential in future experiments in the selected directions. In this work, we selected medicinal chemistry as a case and presented an interactive visual tool, MedChemLens, to assist medicinal chemists in choosing their intended directions of research. This task is also known as drug target (i.e., disease-linked proteins) selection. Given a candidate target name, MedChemLens automatically extracts the molecular features of drug compounds from chemical papers and clinical trial records, organizes them based on the drug structures, and interactively visualizes factors concerning subsequent experiments. We evaluated MedChemLens through a within-subjects study (N=16). Compared with the control condition (i.e., unrestricted online search without using our tool), participants who only used MedChemLens reported faster search, better-informed selections, higher confidence in their selections, and lower cognitive load.",10.1109/TVCG.2022.3209434,,TRUE,TRUE,TRUE,T,,F,C1,KEEP,1,2. Biology and life sciences,,,0,1,1,1,1,1,1,1,0,0,0,2,22,1. domain expert,6,,,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,2. Before the deployment (Before or during design phase ONLY),0,,
,,2022J006,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,16,,,0,0,0,0,1,1,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,1,0,1,1,0,4. After the deployment,0,,
484,170,2022J007,Visual Concept Programming: A Visual Analytics Approach to Injecting Human Intelligence at Scale,"Hoque, Md Naimul and He, Wenbin and Shekar, Arvind Kumar and Gou, Liang and Ren, Liu",2022,2023,Visualization;Programming;Labeling;Data models;Artificial intelligence;Task analysis;Visual analytics;Visual concept programming;data-centric AI;data programming;self-supervised learning;semantic segmentation,"Data-centric AI has emerged as a new research area to systematically engineer the data to land AI models for real-world applications. As a core method for data-centric AI, data programming helps experts inject domain knowledge into data and label data at scale using carefully designed labeling functions (e.g., heuristic rules, logistics). Though data programming has shown great success in the NLP domain, it is challenging to program image data because of a) the challenge to describe images using visual vocabulary without human annotations and b) lacking efficient tools for data programming of images. We present Visual Concept Programming, a first-of-its-kind visual analytics approach of using visual concepts to program image data at scale while requiring a few human efforts. Our approach is built upon three unique components. It first uses a self-supervised learning approach to learn visual representation at the pixel level and extract a dictionary of visual concepts from images without using any human annotations. The visual concepts serve as building blocks of labeling functions for experts to inject their domain knowledge. We then design interactive visualizations to explore and understand visual concepts and compose labeling functions with concepts without writing code. Finally, with the composed labeling functions, users can label the image data at scale and use the labeled data to refine the pixel-wise visual representation and concept quality. We evaluate the learned pixel-wise visual representation for the downstream task of semantic segmentation to show the effectiveness and usefulness of our approach. In addition, we demonstrate how our approach tackles real-world problems of image retrieval for autonomous driving.",10.1109/TVCG.2022.3209466,,TRUE,TRUE,TRUE,T,,F,C1,KEEP,1,1. AI (Machine Learning/Deep Learning/Data Mining),,data-centric AI,0,1,1,1,1,0,1,1,1,0,0,1,3,1. domain expert,3,,,0,0,0,0,0,1,1,0,1,0,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,4. After the deployment,0,,
,,2022J008,A Design Space for Surfacing Content Recommendations in Visual Analytic Platforms,"Zhou, Zhilan and Wang, Wenyuan and Guo, Mengtian and Wang, Yue and Gotz, David",2022,2023,Libraries;Recommender systems;Visual analytics;Data visualization;Task analysis;Search problems;Human computer interaction;Adaptive Visualization;Recommendation;Literature Survey;Design Space,"Recommendation algorithms have been leveraged in various ways within visualization systems to assist users as they perform of a range of information tasks. One common focus for these techniques has been the recommendation of content, rather than visual form, as a means to assist users in the identification of information that is relevant to their task context. A wide variety of techniques have been proposed to address this general problem, with a range of design choices in how these solutions surface relevant information to users. This paper reviews the state-of-the-art in how visualization systems surface recommended content to users during users' visual analysis; introduces a four-dimensional design space for visual content recommendation based on a characterization of prior work; and discusses key observations regarding common patterns and future research opportunities.",10.1109/TVCG.2022.3209445,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
485,171,2022J009,Diverse Interaction Recommendation for Public Users Exploring Multi-view Visualization using Deep Learning,"Li, Yixuan and Qi, Yusheng and Shi, Yang and Chen, Qing and Cao, Nan and Chen, Siming",2022,2023,Data visualization;Visualization;Numerical models;Hidden Markov models;Education;Museums;Data models;Interaction Recommendation;Visualization for public education;Mixed-initiative Exploration,"Interaction is an important channel to offer users insights in interactive visualization systems. However, which interaction to operate and which part of data to explore are hard questions for public users facing a multi-view visualization for the first time. Making these decisions largely relies on professional experience and analytic abilities, which is a huge challenge for non-professionals. To solve the problem, we propose a method aiming to provide diverse, insightful, and real-time interaction recommendations for novice users. Building on the Long-Short Term Memory Model (LSTM) structure, our model captures users' interactions and visual states and encodes them in numerical vectors to make further recommendations. Through an illustrative example of a visualization system about Chinese poets in the museum scenario, the model is proven to be workable in systems with multi-views and multiple interaction types. A further user study demonstrates the method's capability to help public users conduct more insightful and diverse interactive explorations and gain more accurate data insights.",10.1109/TVCG.2022.3209461,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,5. Education and e-learning,11. Humanities and social sciences,,0,1,1,1,1,1,1,1,0,1,0,2,45,3. general public,42,,,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,1,0,1,0,0,4. After the deployment,0,,
,,2022J009,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,3,,,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,4. After the deployment,0,,
486,172,2022J010,Visinity: Visual Spatial Neighborhood Analysis for Multiplexed Tissue Imaging Data,"Warchol, Simon and Krueger, Robert and Nirmal, Ajit Johnson and Gaglia, Giorgio and Jessup, Jared and Ritch, Cecily C. and Hoffer, John and Muhlich, Jeremy and Burger, Megan L. and Jacks, Tyler and Santagata, Sandro and Sorger, Peter K. and Pfister, Hanspeter",2022,2023,Cancer;Biological tissues;Immune system;Tumors;Task analysis;Multiplexing;Data visualization;Visual analytics;spatial analysis;tissue imaging,"New highly-multiplexed imaging technologies have enabled the study of tissues in unprecedented detail. These methods are increasingly being applied to understand how cancer cells and immune response change during tumor development, progression, and metastasis, as well as following treatment. Yet, existing analysis approaches focus on investigating small tissue samples on a per-cell basis, not taking into account the spatial proximity of cells, which indicates cell-cell interaction and specific biological processes in the larger cancer microenvironment. We present Visinity, a scalable visual analytics system to analyze cell interaction patterns across cohorts of whole-slide multiplexed tissue images. Our approach is based on a fast regional neighborhood computation, leveraging unsupervised learning to quantify, compare, and group cells by their surrounding cellular neighborhood. These neighborhoods can be visually analyzed in an exploratory and confirmatory workflow. Users can explore spatial patterns present across tissues through a scalable image viewer and coordinated views highlighting the neighborhood composition and spatial arrangements of cells. To verify or refine existing hypotheses, users can query for specific patterns to determine their presence and statistical significance. Findings can be interactively annotated, ranked, and compared in the form of small multiples. In two case studies with biomedical experts, we demonstrate that Visinity can identify common biological processes within a human tonsil and uncover novel white-blood cell networks and immune-tumor interactions.",10.1109/TVCG.2022.3209378,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,10. Healthcare and medical imaging,,,0,1,1,0,1,1,1,1,0,0,0,3,12,1. domain expert,9,,,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,2. Before the deployment (Before or during design phase ONLY),1,,
,,2022J010,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,4,,,0,1,0,0,0,1,0,0,0,0,0,0,0,1,0,1,0,0,1,1,1,0,0,0,0,0,4. After the deployment,0,,
493,173,2022J012,Rigel: Transforming Tabular Data by Declarative Mapping,"Chen, Ran and Weng, Di and Huang, Yanwei and Shu, Xinhuan and Zhou, Jiayi and Sun, Guodao and Wu, Yingcai",2022,2023,Transforms;Task analysis;Data models;Usability;Economic indicators;Data visualization;Writing;Data transformation;self-service data transformation;programming by example;declarative specification,"We present Rigel, an interactive system for rapid transformation of tabular data. Rigel implements a new declarative mapping approach that formulates the data transformation procedure as direct mappings from data to the row, column, and cell channels of the target table. To construct such mappings, Rigel allows users to directly drag data attributes from input data to these three channels and indirectly drag or type data values in a spreadsheet, and possible mappings that do not contradict these interactions are recommended to achieve efficient and straightforward data transformation. The recommended mappings are generated by enumerating and composing data variables based on the row, column, and cell channels, thereby revealing the possibility of alternative tabular forms and facilitating open-ended exploration in many data transformation scenarios, such as designing tables for presentation. In contrast to existing systems that transform data by composing operations (like transposing and pivoting), Rigel requires less prior knowledge on these operations, and constructing tables from the channels is more efficient and results in less ambiguity than generating operation sequences as done by the traditional by-example approaches. User study results demonstrated that Rigel is significantly less demanding in terms of time and interactions and suits more scenarios compared to the state-of-the-art by-example approach. A gallery of diverse transformation cases is also presented to show the potential of Rigel's expressiveness.",10.1109/TVCG.2022.3209385,,TRUE,TRUE,TRUE,,T,F,C1,DROP-case study but with no domain expert,0,,,,1,0,1,1,1,0,1,0,0,0,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
494,174,2022J013,HiTailor: Interactive Transformation and Visualization for Hierarchical Tabular Data,"Li, Guozheng and Li, Runfei and Wang, Zicheng and Liu, Chi Harold and Lu, Min and Wang, Guoren",2022,2023,Data visualization;Transforms;Computer architecture;TV;Prototypes;Visualization;Microprocessors;data transformation;tabular data;hierarchical tabular data;tabular visualization,"Tabular visualization techniques integrate visual representations with tabular data to avoid additional cognitive load caused by splitting users' attention. However, most of the existing studies focus on simple flat tables instead of hierarchical tables, whose complex structure limits the expressiveness of visualization results and affects users' efficiency in visualization construction. We present HiTailor, a technique for presenting and exploring hierarchical tables. HiTailor constructs an abstract model, which defines row/column headings as biclustering and hierarchical structures. Based on our abstract model, we identify three pairs of operators, Swap/Transpose, ToStacked/ToLinear, Fold/Unfold, for transformations of hierarchical tables to support users' comprehensive explorations. After transformation, users can specify a cell or block of interest in hierarchical tables as a TableUnit for visualization, and HiTailor recommends other related TableUnits according to the abstract model using different mechanisms. We demonstrate the usability of the HiTailor system through a comparative study and a case study with domain experts, showing that HiTailor can present and explore hierarchical tables from different viewpoints. HiTailor is available at https://github.com/bitvis2021/HiTailor.",10.1109/TVCG.2022.3209354,,TRUE,TRUE,TRUE,,T,F,C1,DROP-case study but with no domain expert,0,,,,1,1,1,1,1,0,1,0,0,0,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2022J013,,,,,,,,,,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
497,175,2022J014,Animated Vega-Lite: Unifying Animation with a Grammar of Interactive Graphics,"Zong, Jonathan and Pollock, Josh and Wootton, Dylan and Satyanarayan, Arvind",2022,2023,Animation;Data visualization;Encoding;Grammar;Taxonomy;Switches;Facial animation;Information visualization;Animation;Interaction;Toolkits;Systems;Declarative Specification,"We present Animated Vega-Lite, a set of extensions to Vega-Lite that model animated visualizations as time-varying data queries. In contrast to alternate approaches for specifying animated visualizations, which prize a highly expressive design space, Animated Vega-Lite prioritizes unifying animation with the language's existing abstractions for static and interactive visualizations to enable authors to smoothly move between or combine these modalities. Thus, to compose animation with static visualizations, we represent time as an encoding channel. Time encodings map a data field to animation keyframes, providing a lightweight specification for animations without interaction. To compose animation and interaction, we also represent time as an event stream; Vega-Lite selections, which provide dynamic data queries, are now driven not only by input events but by timer ticks as well. We evaluate the expressiveness of our approach through a gallery of diverse examples that demonstrate coverage over taxonomies of both interaction and animation. We also critically reflect on the conceptual affordances and limitations of our contribution by interviewing five expert developers of existing animation grammars. These reflections highlight the key motivating role of in-the-wild examples, and identify three central tradeoffs: the language design process, the types of animated transitions supported, and how the systems model keyframes.",10.1109/TVCG.2022.3209369,,TRUE,TRUE,TRUE,T,,F,C1,DROP,0,,,,1,1,1,1,0,0,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2022J017,Constrained Dynamic Mode Decomposition,"Krake, Tim and KlÃ¶tzl, Daniel and Eberhardt, Bernhard and Weiskopf, Daniel",2022,2023,Time series analysis;Market research;Data visualization;Human in the loop;Heuristic algorithms;Minimization;Eigenvalues and eigenfunctions;Dynamic Mode Decomposition;time series analysis;spectral decomposition;frequency-based constraints;human-in-the-loop,"Frequency-based decomposition of time series data is used in many visualization applications. Most of these decomposition methods (such as Fourier transform or singular spectrum analysis) only provide interaction via pre- and post-processing, but no means to influence the core algorithm. A method that also belongs to this class is Dynamic Mode Decomposition (DMD), a spectral decomposition method that extracts spatio-temporal patterns from data. In this paper, we incorporate frequency-based constraints into DMD for an adaptive decomposition that leads to user-controllable visualizations, allowing analysts to include their knowledge into the process. To accomplish this, we derive an equivalent reformulation of DMD that implicitly provides access to the eigenvalues (and therefore to the frequencies) identified by DMD. By utilizing a constrained minimization problem customized to DMD, we can guarantee the existence of desired frequencies by minimal changes to DMD. We complement this core approach by additional techniques for constrained DMD to facilitate explorative visualization and investigation of time series data. With several examples, we demonstrate the usefulness of constrained DMD and compare it to conventional frequency-based decomposition methods.",10.1109/TVCG.2022.3209437,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
502,176,2022J019,LargeNetVis: Visual Exploration of Large Temporal Networks Based on Community Taxonomies,"Linhares, Claudio D. G. and Ponciano, Jean R. and Pedro, Diogenes S. and Rocha, Luis E. C. and Traina, Agma J. M. and Poco, Jorge",2022,2023,Taxonomy;Layout;Animation;Stars;Visual analytics;Task analysis;Scalability;temporal networks;dynamic graphs;network visualization;visual scalability;community taxonomy,"Temporal (or time-evolving) networks are commonly used to model complex systems and the evolution of their components throughout time. Although these networks can be analyzed by different means, visual analytics stands out as an effective way for a pre-analysis before doing quantitative/statistical analyses to identify patterns, anomalies, and other behaviors in the data, thus leading to new insights and better decision-making. However, the large number of nodes, edges, and/or timestamps in many real-world networks may lead to polluted layouts that make the analysis inefficient or even infeasible. In this paper, we propose LargeNetVis, a web-based visual analytics system designed to assist in analyzing small and large temporal networks. It successfully achieves this goal by leveraging three taxonomies focused on network communities to guide the visual exploration process. The system is composed of four interactive visual components: the first (Taxonomy Matrix) presents a summary of the network characteristics, the second (Global View) gives an overview of the network evolution, the third (a node-link diagram) enables community- and node-level structural analysis, and the fourth (a Temporal Activity Map â€“ TAM) shows the community- and node-level activity under a temporal perspective. We demonstrate the usefulness and effectiveness of LargeNetVis through two usage scenarios and a user study with 14 participants.",10.1109/TVCG.2022.3209477,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,,,,1,1,1,1,1,0,1,1,0,0,0,2,14,1. domain expert,6,2. domain user,8,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0,0,4. After the deployment,0,,
,,2022J019,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,5. no participant,0,,,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,4. After the deployment,0,,
504,177,2022J022,Supporting Expressive and Faithful Pictorial Visualization Design with Visual Style Transfer,"Shi, Yang and Liu, Pei and Chen, Siji and Sun, Mengdi and Cao, Nan",2022,2023,Data visualization;Visualization;Interviews;Image color analysis;Artificial intelligence;Libraries;Authoring systems;Pictorial visualization;data-driven design,"Pictorial visualizations portray data with figurative messages and approximate the audience to the visualization. Previous research on pictorial visualizations has developed authoring tools or generation systems, but their methods are restricted to specific visualization types and templates. Instead, we propose to augment pictorial visualization authoring with visual style transfer, enabling a more extensible approach to visualization design. To explore this, our work presents Vistylist, a design support tool that disentangles the visual style of a source pictorial visualization from its content and transfers the visual style to one or more intended pictorial visualizations. We evaluated Vistylist through a survey of example pictorial visualizations, a controlled user study, and a series of expert interviews. The results of our evaluation indicated that Vistylist is useful for creating expressive and faithful pictorial visualizations.",10.1109/TVCG.2022.3209486,,TRUE,TRUE,TRUE,T,T,F,C2,KEEP,1,,,visualization,1,1,1,1,1,1,1,1,0,0,0,3,98,1. domain expert,4,,,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,2. Before the deployment (Before or during design phase ONLY),0,,
,,2022J022,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,2. domain user,80,,,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,4. After the deployment,0,,
,,2022J022,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,2. domain user,14,,,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,4. After the deployment,0,,
505,178,2022J028,NAS-Navigator: Visual Steering for Explainable One-Shot Deep Neural Network Synthesis,"Tyagi, Anjul and Xie, Cong and Mueller, Klaus",2022,2023,Artificial neural networks;Computer architecture;Visual analytics;Deep learning;Training;Human in the loop;Search problems;Deep Learning;Neural Network Architecture Search;Visual Analytics;Explainability,"The success of DL can be attributed to hours of parameter and architecture tuning by human experts. Neural Architecture Search (NAS) techniques aim to solve this problem by automating the search procedure for DNN architectures making it possible for non-experts to work with DNNs. Specifically, One-shot NAS techniques have recently gained popularity as they are known to reduce the search time for NAS techniques. One-Shot NAS works by training a large template network through parameter sharing which includes all the candidate NNs. This is followed by applying a procedure to rank its components through evaluating the possible candidate architectures chosen randomly. However, as these search models become increasingly powerful and diverse, they become harder to understand. Consequently, even though the search results work well, it is hard to identify search biases and control the search progression, hence a need for explainability and human-in-the-loop (HIL) One-Shot NAS. To alleviate these problems, we present NAS-Navigator, a visual analytics (VA) system aiming to solve three problems with One-Shot NAS; explainability, HIL design, and performance improvements compared to existing state-of-the-art (SOTA) techniques. NAS-Navigator gives full control of NAS back in the hands of the users while still keeping the perks of automated search, thus assisting non-expert users. Analysts can use their domain knowledge aided by cues from the interface to guide the search. Evaluation results confirm the performance of our improved One-Shot NAS algorithm is comparable to other SOTA techniques. While adding Visual Analytics (VA) using NAS-Navigator shows further improvements in search time and performance. We designed our interface in collaboration with several deep learning researchers and evaluated NAS-Navigator through a control experiment and expert interviews.",10.1109/TVCG.2022.3209361,,TRUE,TRUE,TRUE,T,,F,C2,KEEP,1,1. AI (Machine Learning/Deep Learning/Data Mining),,xai,1,1,1,1,1,1,1,1,1,0,0,2,16,2. domain user,10,,,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,4. After the deployment,0,,
,,2022J028,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,3,2. domain user,3,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,1,0,1,0,0,1,1,0,1,0,1,4. After the deployment,0,,
506,179,2022J029,HetVis: A Visual Analysis Approach for Identifying Data Heterogeneity in Horizontal Federated Learning,"Wang, Xumeng and Chen, Wei and Xia, Jiazhi and Wen, Zhen and Zhu, Rongchen and Schreck, Tobias",2022,2023,Data models;Analytical models;Distributed databases;Training;Federated learning;Data visualization;Convergence;Federated learning;data heterogeneity;cluster analysis;visual analysis,"Horizontal federated learning (HFL) enables distributed clients to train a shared model and keep their data privacy. In training high-quality HFL models, the data heterogeneity among clients is one of the major concerns. However, due to the security issue and the complexity of deep learning models, it is challenging to investigate data heterogeneity across different clients. To address this issue, based on a requirement analysis we developed a visual analytics tool, HetVis, for participating clients to explore data heterogeneity. We identify data heterogeneity through comparing prediction behaviors of the global federated model and the stand-alone model trained with local data. Then, a context-aware clustering of the inconsistent records is done, to provide a summary of data heterogeneity. Combining with the proposed comparison techniques, we develop a novel set of visualizations to identify heterogeneity issues in HFL. We designed three case studies to introduce how HetVis can assist client analysts in understanding different types of heterogeneity issues. Expert reviews and a comparative study demonstrate the effectiveness of HetVis.",10.1109/TVCG.2022.3209347,,TRUE,TRUE,TRUE,,T,F,C2,KEEP,1,1. AI (Machine Learning/Deep Learning/Data Mining),,,1,1,1,1,1,1,1,1,1,0,0,2,3,1. domain expert,3,,,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,0,0,1,0,0,0,0,0,4. After the deployment,0,,
,,2022J029,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,5. no participant,0,,,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,4. After the deployment,0,,
509,180,2022J031,MetaGlyph: Automatic Generation of Metaphoric Glyph-based Visualization,"Ying, Lu and Shu, Xinhuan and Deng, Dazhen and Yang, Yuchen and Tang, Tan and Yu, Lingyun and Wu, Yingcai",2022,2023,Data visualization;Visualization;Semantics;Layout;Authoring systems;Task analysis;Shape;Glyph-based visualization;metaphor;machine learning;automatic visualization,"Glyph-based visualization achieves an impressive graphic design when associated with comprehensive visual metaphors, which help audiences effectively grasp the conveyed information through revealing data semantics. However, creating such metaphoric glyph-based visualization (MGV) is not an easy task, as it requires not only a deep understanding of data but also professional design skills. This paper proposes MetaGlyph, an automatic system for generating MGVs from a spreadsheet. To develop MetaGlyph, we first conduct a qualitative analysis to understand the design of current MGVs from the perspectives of metaphor embodiment and glyph design. Based on the results, we introduce a novel framework for generating MGVs by metaphoric image selection and an MGV construction. Specifically, MetaGlyph automatically selects metaphors with corresponding images from online resources based on the input data semantics. We then integrate a Monte Carlo tree search algorithm that explores the design of an MGV by associating visual elements with data dimensions given the data importance, semantic relevance, and glyph non-overlap. The system also provides editing feedback that allows users to customize the MGVs according to their design preferences. We demonstrate the use of MetaGlyph through a set of examples, one usage scenario, and validate its effectiveness through a series of expert interviews.",10.1109/TVCG.2022.3209447,,TRUE,TRUE,TRUE,T,T,F,C2,DROP,0,,,,1,1,1,1,1,0,1,0,0,1,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
512,181,2022J032,Dashboard Design Patterns,"Bach, Benjamin and Freeman, Euan and Abdul-Rahman, Alfie and Turkay, Cagatay and Khan, Saiful and Fan, Yulei and Chen, Min",2022,2023,Visualization;Data visualization;Conferences;Guidelines;Encoding;Task analysis;Monitoring;Dashboards;Design Patterns;Data Visualization;Storytelling;Visual Analytics;Qualitative Evaluation;Education,"This paper introduces design patterns for dashboards to inform dashboard design processes. Despite a growing number of public examples, case studies, and general guidelines there is surprisingly little design guidance for dashboards. Such guidance is necessary to inspire designs and discuss tradeoffs in, e.g., screenspace, interaction, or information shown. Based on a systematic review of 144 dashboards, we report on eight groups of design patterns that provide common solutions in dashboard design. We discuss combinations of these patterns in â€œdashboard genresâ€ such as narrative, analytical, or embedded dashboard. We ran a 2-week dashboard design workshop with 23 participants of varying expertise working on their own data and dashboards. We discuss the application of patterns for the dashboard design processes, as well as general design tradeoffs and common challenges. Our work complements previous surveys and aims to support dashboard designers and researchers in co-creation, structured design decisions, as well as future user evaluations about dashboard design guidelines. Detailed pattern descriptions and workshop material can be found online: https://dashboarddesignpatterns.github.io",10.1109/TVCG.2022.3209448,,TRUE,TRUE,TRUE,T,T,F,C2,DROP,0,,,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2022J033,A Framework for Multiclass Contour Visualization,"Li, Sihang and Yu, Jiacheng and Li, Mingxuan and Liu, Le and Zhang, Xiaolong Luke and Yuan, Xiaoru",2022,2023,Data visualization;Visualization;Filling;DSL;Domain specific languages;Task analysis;Image color analysis;Contour;multiclass visualization;visualization framework;domain-specific language;visualization design,"Multiclass contour visualization is often used to interpret complex data attributes in such fields as weather forecasting, computational fluid dynamics, and artificial intelligence. However, effective and accurate representations of underlying data patterns and correlations can be challenging in multiclass contour visualization, primarily due to the inevitable visual cluttering and occlusions when the number of classes is significant. To address this issue, visualization design must carefully choose design parameters to make visualization more comprehensible. With this goal in mind, we proposed a framework for multiclass contour visualization. The framework has two components: a set of four visualization design parameters, which are developed based on an extensive review of literature on contour visualization, and a declarative domain-specific language (DSL) for creating multiclass contour rendering, which enables a fast exploration of those design parameters. A task-oriented user study was conducted to assess how those design parameters affect users' interpretations of real-world data. The study results offered some suggestions on the value choices of design parameters in multiclass contour visualization.",10.1109/TVCG.2022.3209482,,TRUE,TRUE,TRUE,,T,F,C1,DROP-empirical study,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
513,182,2022J039,Exploring Interactions with Printed Data Visualizations in Augmented Reality,"Tong, Wai and Chen, Zhutian and Xia, Meng and Lo, Leo Yu-Ho and Yuan, Linping and Bach, Benjamin and Qu, Huamin",2022,2023,Data visualization;Task analysis;Augmented reality;Affordances;Three-dimensional displays;Navigation;Human computer interaction;Interaction design;augmented reality;paper interaction;tangible user interface;printed data visualization,"This paper presents a design space of interaction techniques to engage with visualizations that are printed on paper and augmented through Augmented Reality. Paper sheets are widely used to deploy visualizations and provide a rich set of tangible affordances for interactions, such as touch, folding, tilting, or stacking. At the same time, augmented reality can dynamically update visualization content to provide commands such as pan, zoom, filter, or detail on demand. This paper is the first to provide a structured approach to mapping possible actions with the paper to interaction commands. This design space and the findings of a controlled user study have implications for future designs of augmented reality systems involving paper sheets and visualizations. Through workshops ($\mathrm",10.1109/TVCG.2022.3209386,,TRUE,TRUE,TRUE,,T,F,C1,DROP-theory,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2022J034,BeauVis: A Validated Scale for Measuring the Aesthetic Pleasure of Visual Representations,"He, Tingying and Isenberg, Petra and Dachselt, Raimund and Isenberg, Tobias",2022,2023,Visualization;Particle measurements;Data visualization;Atmospheric measurements;Instruments;Systematics;Usability;Aesthetics;aesthetic pleasure;validated scale;scale development;visual representations,"We developed and validated a rating scale to assess the aesthetic pleasure (or beauty) of a visual data representation: the BeauVis scale. With our work we offer researchers and practitioners a simple instrument to compare the visual appearance of different visualizations, unrelated to data or context of use. Our rating scale can, for example, be used to accompany results from controlled experiments or be used as informative data points during in-depth qualitative studies. Given the lack of an aesthetic pleasure scale dedicated to visualizations, researchers have mostly chosen their own terms to study or compare the aesthetic pleasure of visualizations. Yet, many terms are possible and currently no clear guidance on their effectiveness regarding the judgment of aesthetic pleasure exists. To solve this problem, we engaged in a multi-step research process to develop the first validated rating scale specifically for judging the aesthetic pleasure of a visualization (osf.io/fxs76). Our final BeauVis scale consists of five items, â€œenjoyable,â€ â€œlikable,â€ â€œpleasing,â€ â€œnice,â€ and â€œappealing.â€ Beyond this scale itself, we contribute (a) a systematic review of the terms used in past research to capture aesthetics, (b) an investigation with visualization experts who suggested terms to use for judging the aesthetic pleasure of a visualization, and (c) a confirmatory survey in which we used our terms to study the aesthetic pleasure of a set of 3 visualizations.",10.1109/TVCG.2022.3209390,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2022J035,Photosensitive Accessibility for Interactive Data Visualizations,"South, Laura and Borkin, Michelle A.",2022,2023,Data visualization;Recording;Image color analysis;Videos;Testing;Visualization;Epilepsy;accessibility;photosensitive epilepsy;photosensitivity;interaction;data visualization,"Accessibility guidelines place restrictions on the use of animations and interactivity on webpages to lessen the likelihood of webpages inadvertently producing sequences with flashes, patterns, or color changes that may trigger seizures for individuals with photosensitive epilepsy. Online data visualizations often incorporate elements of animation and interactivity to create a narrative, engage users, or encourage exploration. These design guidelines have been empirically validated by perceptual studies in visualization literature, but the impact of animation and interaction in visualizations on users with photosensitivity, who may experience seizures in response to certain visual stimuli, has not been considered. We systematically gathered and tested 1,132 interactive and animated visualizations for seizure-inducing risk using established methods and found that currently available methods for determining photosensitive risk are not reliable when evaluating interactive visualizations, as risk scores varied significantly based on the individual interacting with the visualization. To address this issue, we introduce a theoretical model defining the degree of control visualization designers have over three determinants of photosensitive risk in potentially seizure-inducing sequences: the size, frequency, and color of flashing content. Using an analysis of 375 visualizations hosted on bl.ocks.org, we created a theoretical model of photosensitive risk in visualizations by arranging the photosensitive risk determinants according to the degree of control visualization authors have over whether content exceeds photosensitive accessibility thresholds. We then use this model to propose a new method of testing for photosensitive risk that focuses on elements of visualizations that are subject to greater authorial control - and are therefore more robust to variations in the individual user - producing more reliable risk assessments than existing methods when applied to interactive visualizations. A full copy of this paper and all study materials are available at https://osf.io/8kzmg/.",10.1109/TVCG.2022.3209359,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2022J036,Unifying Effects of Direct and Relational Associations for Visual Communication,"Schoenlein, Melissa A. and Campos, Johnny and Lande, Kevin J. and Lessard, Laurent and Schloss, Karen B.",2022,2023,Image color analysis;Data visualization;Semantics;Encoding;Visualization;Color;Observers;Visual reasoning;information visualization;colormap data visualizations;visual encoding;color cognition,"People have expectations about how colors map to concepts in visualizations, and they are better at interpreting visualizations that match their expectations. Traditionally, studies on these expectations (inferred mappings) distinguished distinct factors relevant for visualizations of categorical vs. continuous information. Studies on categorical information focused on direct associations (e.g., mangos are associated with yellows) whereas studies on continuous information focused on relational associations (e.g., darker colors map to larger quantities; dark-is-more bias). We unite these two areas within a single framework of assignment inference. Assignment inference is the process by which people infer mappings between perceptual features and concepts represented in encoding systems. Observers infer globally optimal assignments by maximizing the â€œmerit,â€ or â€œgoodness,â€ of each possible assignment. Previous work on assignment inference focused on visualizations of categorical information. We extend this approach to visualizations of continuous data by (a) broadening the notion of merit to include relational associations and (b) developing a method for combining multiple (sometimes conflicting) sources of merit to predict people's inferred mappings. We developed and tested our model on data from experiments in which participants interpreted colormap data visualizations, representing fictitious data about environmental concepts (sunshine, shade, wild fire, ocean water, glacial ice). We found both direct and relational associations contribute independently to inferred mappings. These results can be used to optimize visualization design to facilitate visual communication.",10.1109/TVCG.2022.3209443,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
519,183,2022J040,PuzzleFixer: A Visual Reassembly System for Immersive Fragments Restoration,"Ye, Shuainan and Chen, Zhutian and Chu, Xiangtong and Li, Kang and Luo, Juntong and Li, Yi and Geng, Guohua and Wu, Yingcai",2022,2023,Three-dimensional displays;Visualization;Shape;Manuals;Faces;Optimization;Cultural differences;Immersive visualization;interactive exploration;fragment reassembly;cultural heritage,"We present PuzzleFixer, an immersive interactive system for experts to rectify defective reassembled 3D objects. Reassembling the fragments of a broken object to restore its original state is the prerequisite of many analytical tasks such as cultural relics analysis and forensics reasoning. While existing computer-aided methods can automatically reassemble fragments, they often derive incorrect objects due to the complex and ambiguous fragment shapes. Thus, experts usually need to refine the object manually. Prior advances in immersive technologies provide benefits for realistic perception and direct interactions to visualize and interact with 3D fragments. However, few studies have investigated the reassembled object refinement. The specific challenges include: 1) the fragment combination set is too large to determine the correct matches, and 2) the geometry of the fragments is too complex to align them properly. To tackle the first challenge, PuzzleFixer leverages dimensionality reduction and clustering techniques, allowing users to review possible match categories, select the matches with reasonable shapes, and drill down to shapes to correct the corresponding faces. For the second challenge, PuzzleFixer embeds the object with node-link networks to augment the perception of match relations. Specifically, it instantly visualizes matches with graph edges and provides force feedback to facilitate the efficiency of alignment interactions. To demonstrate the effectiveness of PuzzleFixer, we conducted an expert evaluation based on two cases on real-world artifacts and collected feedback through post-study interviews. The results suggest that our system is suitable and efficient for experts to refine incorrect reassembled objects.",10.1109/TVCG.2022.3209388,,TRUE,TRUE,TRUE,T,,F,C1,KEEP,1,11. Humanities and social sciences,,cultural heritage,0,1,1,1,1,1,1,1,0,0,1,1,6,1. domain expert,6,,,0,0,0,0,1,1,0,0,0,0,1,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,4. After the deployment,0,,
520,184,2022J041,Effects of View Layout on Situated Analytics for Multiple-View Representations in Immersive Visualization,"Wen, Zhen and Zeng, Wei and Weng, Luoxuan and Liu, Yihan and Xu, Mingliang and Chen, Wei",2022,2023,Layout;Data visualization;Three-dimensional displays;Visualization;Task analysis;Data analysis;Prototypes;Situated analytics;multiple-view representations;view layout;immersive visualization,"Multiple-view (MV) representations enabling multi-perspective exploration of large and complex data are often employed on 2D displays. The technique also shows great potential in addressing complex analytic tasks in immersive visualization. However, although useful, the design space of MV representations in immersive visualization lacks in deep exploration. In this paper, we propose a new perspective to this line of research, by examining the effects of view layout for MV representations on situated analytics. Specifically, we disentangle situated analytics in perspectives of situatedness regarding spatial relationship between visual representations and physical referents, and analytics regarding cross-view data analysis including filtering, refocusing, and connecting tasks. Through an in-depth analysis of existing layout paradigms, we summarize design trade-offs for achieving high situatedness and effective analytics simultaneously. We then distill a list of design requirements for a desired layout that balances situatedness and analytics, and develop a prototype system with an automatic layout adaptation method to fulfill the requirements. The method mainly includes a cylindrical paradigm for egocentric reference frame, and a force-directed method for proper view-view, view-user, and view-referent proximities and high view visibility. We conducted a formal user study that compares layouts by our method with linked and embedded layouts. Quantitative results show that participants finished filtering- and connecting-centered tasks significantly faster with our layouts, and user feedback confirms high usability of the prototype system.",10.1109/TVCG.2022.3209475,,TRUE,TRUE,TRUE,,T,F,C1,DROP-design study,0,,,,1,1,1,1,1,0,0,0,0,0,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
522,185,2022J043,VACSEN: A Visualization Approach for Noise Awareness in Quantum Computing,"Ruan, Shaolun and Wang, Yong and Jiang, Weiwen and Mao, Ying and Guan, Qiang",2022,2023,Quantum computing;Qubit;Visualization;Logic gates;Quantum algorithm;Quantum circuit;Reliability;Data visualization;quantum computing;noise awareness,"Quantum computing has attracted considerable public attention due to its exponential speedup over classical computing. Despite its advantages, today's quantum computers intrinsically suffer from noise and are error-prone. To guarantee the high fidelity of the execution result of a quantum algorithm, it is crucial to inform users of the noises of the used quantum computer and the compiled physical circuits. However, an intuitive and systematic way to make users aware of the quantum computing noise is still missing. In this paper, we fill the gap by proposing a novel visualization approach to achieve noise-aware quantum computing. It provides a holistic picture of the noise of quantum computing through multiple interactively coordinated views: a Computer Evolution View with a circuit-like design overviews the temporal evolution of the noises of different quantum computers, a Circuit Filtering View facilitates quick filtering of multiple compiled physical circuits for the same quantum algorithm, and a Circuit Comparison View with a coupled bar chart enables detailed comparison of the filtered compiled circuits. We extensively evaluate the performance of VACSEN through two case studies on quantum algorithms of different scales and in-depth interviews with 12 quantum computing users. The results demonstrate the effectiveness and usability of VACSEN in achieving noise-aware quantum computing.",10.1109/TVCG.2022.3209455,,TRUE,TRUE,TRUE,T,T,F,C1,KEEP,1,4. Computer networks and security,,quantum computing,0,1,1,1,1,1,1,1,0,0,0,2,17,2. domain user,5,,,1,0,0,0,0,1,0,0,0,0,1,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,1. Before the deployment (General),1,,
,,2022J043,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,2. domain user,12,,,0,1,0,0,0,1,0,0,1,0,0,0,0,1,1,1,1,1,0,0,1,0,0,0,0,0,4. After the deployment,0,,
528,186,2022J044,D-BIAS: A Causality-Based Human-in-the-Loop System for Tackling Algorithmic Bias,"Ghai, Bhavya and Mueller, Klaus",2022,2023,Measurement;Visualization;Mathematical models;Human in the loop;Distortion;Data models;Machine learning algorithms;Algorithmic Fairness;Causality;Debiasing;Human-in-the-loop;Visual Analytics,"With the rise of AI, algorithms have become better at learning underlying patterns from the training data including ingrained social biases based on gender, race, etc. Deployment of such algorithms to domains such as hiring, healthcare, law enforcement, etc. has raised serious concerns about fairness, accountability, trust and interpretability in machine learning algorithms. To alleviate this problem, we propose D-BIAS, a visual interactive tool that embodies human-in-the-loop AI approach for auditing and mitigating social biases from tabular datasets. It uses a graphical causal model to represent causal relationships among different features in the dataset and as a medium to inject domain knowledge. A user can detect the presence of bias against a group, say females, or a subgroup, say black females, by identifying unfair causal relationships in the causal network and using an array of fairness metrics. Thereafter, the user can mitigate bias by refining the causal model and acting on the unfair causal edges. For each interaction, say weakening/deleting a biased causal edge, the system uses a novel method to simulate a new (debiased) dataset based on the current causal model while ensuring a minimal change from the original dataset. Users can visually assess the impact of their interactions on different fairness metrics, utility metrics, data distortion, and the underlying data distribution. Once satisfied, they can download the debiased dataset and use it for any downstream application for fairer predictions. We evaluate D-BIAS by conducting experiments on 3 datasets and also a formal user study. We found that D-BIAS helps reduce bias significantly compared to the baseline debiasing approach across different fairness metrics while incurring little data distortion and a small loss in utility. Moreover, our human-in-the-loop based approach significantly outperforms an automated approach on trust, interpretability and accountability.",10.1109/TVCG.2022.3209484,,TRUE,TRUE,TRUE,T,T,F,C1,KEEP,1,1. AI (Machine Learning/Deep Learning/Data Mining),,,0,1,1,1,1,0,1,1,1,0,0,3,10,2. domain user,10,,,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,1,0,0,0,0,4. After the deployment,0,,
530,187,2022J045,A Unified Comparison of User Modeling Techniques for Predicting Data Interaction and Detecting Exploration Bias,"Ha, Sunwoo and Monadjemi, Shayan and Garnett, Roman and Ottley, Alvitta",2022,2023,Data models;Prediction algorithms;Analytical models;Hidden Markov models;Visual analytics;Task analysis;Predictive models;Visual Analytics;Analytic Provenance;User Interaction Modeling;Machine Learning;Benchmark Study,"The visual analytics community has proposed several user modeling algorithms to capture and analyze users' interaction behavior in order to assist users in data exploration and insight generation. For example, some can detect exploration biases while others can predict data points that the user will interact with before that interaction occurs. Researchers believe this collection of algorithms can help create more intelligent visual analytics tools. However, the community lacks a rigorous evaluation and comparison of these existing techniques. As a result, there is limited guidance on which method to use and when. Our paper seeks to fill in this missing gap by comparing and ranking eight user modeling algorithms based on their performance on a diverse set of four user study datasets. We analyze exploration bias detection, data interaction prediction, and algorithmic complexity, among other measures. Based on our findings, we highlight open challenges and new directions for analyzing user interactions and visualization provenance.",10.1109/TVCG.2022.3209476,,TRUE,TRUE,TRUE,T,T,F,C1,DROP-evaluation,0,,,,,1,1,1,0,0,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
531,188,2022J048,FoVolNet: Fast Volume Rendering using Foveated Deep Neural Networks,"Bauer, David and Wu, Qi and Ma, Kwan-Liu",2022,2023,Rendering (computer graphics);Image reconstruction;Visualization;Data visualization;Kernel;Image quality;Deep learning;Volume data;volume visualization;deep learning;foveated rendering;neural reconstruction,"Volume data is found in many important scientific and engineering applications. Rendering this data for visualization at high quality and interactive rates for demanding applications such as virtual reality is still not easily achievable even using professional-grade hardware. We introduce FoVolNetâ€”a method to significantly increase the performance of volume data visualization. We develop a cost-effective foveated rendering pipeline that sparsely samples a volume around a focal point and reconstructs the full-frame using a deep neural network. Foveated rendering is a technique that prioritizes rendering computations around the user's focal point. This approach leverages properties of the human visual system, thereby saving computational resources when rendering data in the periphery of the user's field of vision. Our reconstruction network combines direct and kernel prediction methods to produce fast, stable, and perceptually convincing output. With a slim design and the use of quantization, our method outperforms state-of-the-art neural reconstruction techniques in both end-to-end frame times and visual quality. We conduct extensive evaluations of the system's rendering performance, inference speed, and perceptual properties, and we provide comparisons to competing neural image reconstruction techniques. Our test results show that FoVolNet consistently achieves significant time saving over conventional rendering while preserving perceptual quality.",10.1109/TVCG.2022.3209498,,TRUE,TRUE,TRUE,T,,F,C1,DROP-algorithm,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
532,189,2022J049,GRay: Ray Casting for Visualization and Interactive Data Exploration of Gaussian Mixture Models,"Lawonn, Kai and Meuschke, Monique and Eulzer, Pepe and Mitterreiter, Matthias and Giesen, Joachim and GÃ¼nther, Tobias",2022,2023,Data visualization;Statistics;Gaussian mixture model;Task analysis;Visualization;Three-dimensional displays;Shape;Scientific visualization;Gaussian mixture models;ray casting;volume visualization,"The Gaussian mixture model (GMM) describes the distribution of random variables from several different populations. GMMs have widespread applications in probability theory, statistics, machine learning for unsupervised cluster analysis and topic modeling, as well as in deep learning pipelines. So far, few efforts have been made to explore the underlying point distribution in combination with the GMMs, in particular when the data becomes high-dimensional and when the GMMs are composed of many Gaussians. We present an analysis tool comprising various GPU-based visualization techniques to explore such complex GMMs. To facilitate the exploration of high-dimensional data, we provide a novel navigation system to analyze the underlying data. Instead of projecting the data to 2D, we utilize interactive 3D views to better support users in understanding the spatial arrangements of the Gaussian distributions. The interactive system is composed of two parts: (1) raycasting-based views that visualize cluster memberships, spatial arrangements, and support the discovery of new modes. (2) overview visualizations that enable the comparison of Gaussians with each other, as well as small multiples of different choices of basis vectors. Users are supported in their exploration with customization tools and smooth camera navigations. Our tool was developed and assessed by five domain experts, and its usefulness was evaluated with 23 participants. To demonstrate the effectiveness, we identify interesting features in several data sets.",10.1109/TVCG.2022.3209374,,TRUE,TRUE,TRUE,T,,F,C1,DROP-algorithm,0,,,,1,1,1,1,1,1,1,,0,0,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2022J049,,,,,,,,,,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2022J049,,,,,,,,,,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
533,190,2022J053,GenoREC: A Recommendation System for Interactive Genomics Data Visualization,"Pandey, Aditeya and L'Yi, Sehi and Wang, Qianwen and Borkin, Michelle A. and Gehlenborg, Nils",2022,2023,Data visualization;Genomics;Bioinformatics;Task analysis;Recommender systems;Visualization;Knowledge based systems;genomics;visualization;recommendation systems;data;tasks,"Interpretation of genomics data is critically reliant on the application of a wide range of visualization tools. A large number of visualization techniques for genomics data and different analysis tasks pose a significant challenge for analysts: which visualization technique is most likely to help them generate insights into their data? Since genomics analysts typically have limited training in data visualization, their choices are often based on trial and error or guided by technical details, such as data formats that a specific tool can load. This approach prevents them from making effective visualization choices for the many combinations of data types and analysis questions they encounter in their work. Visualization recommendation systems assist non-experts in creating data visualization by recommending appropriate visualizations based on the data and task characteristics. However, existing visualization recommendation systems are not designed to handle domain-specific problems. To address these challenges, we designed GenoREC, a novel visualization recommendation system for genomics. GenoREC enables genomics analysts to select effective visualizations based on a description of their data and analysis tasks. Here, we present the recommendation model that uses a knowledge-based method for choosing appropriate visualizations and a web application that enables analysts to input their requirements, explore recommended visualizations, and export them for their usage. Furthermore, we present the results of two user studies demonstrating that GenoREC recommends visualizations that are both accepted by domain experts and suited to address the given genomics analysis problem. All supplemental materials are available at https://osf.io/y73pt/.",10.1109/TVCG.2022.3209407,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,2. Biology and life sciences,,geomics,0,1,1,1,1,1,1,1,0,0,0,3,18,1. domain expert,5,,,1,1,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,4. After the deployment,0,,
,,2022J053,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,2. domain user,13,,,0,1,0,0,0,1,1,0,0,0,0,0,0,0,1,1,1,1,0,0,0,1,0,0,0,0,4. After the deployment,0,,
,,2022J060,Multivariate Probabilistic Range Queries for Scalable Interactive 3D Visualization,"Ageeli, Amani and Jaspe-Villanueva, Alberto and Sicat, Ronell and Mannuss, Florian and Rautek, Peter and Hadwiger, Markus",2022,2023,Data visualization;Histograms;Probabilistic logic;Data structures;Rendering (computer graphics);Query processing;Humidity;High-dimensional filtering;multivariate filtering;output-sensitivity;multivariate attribute queries;progressive culling,"Large-scale scientific data, such as weather and climate simulations, often comprise a large number of attributes for each data sample, like temperature, pressure, humidity, and many more. Interactive visualization and analysis require filtering according to any desired combination of attributes, in particular logical AND operations, which is challenging for large data and many attributes. Many general data structures for this problem are built for and scale with a fixed number of attributes, and scalability of joint queries with arbitrary attribute subsets remains a significant problem. We propose a flexible probabilistic framework for multivariate range queries that decouples all attribute dimensions via projection, allowing any subset of attributes to be queried with full efficiency. Moreover, our approach is output-sensitive, mainly scaling with the cardinality of the query result rather than with the input data size. This is particularly important for joint attribute queries, where the query output is usually much smaller than the whole data set. Additionally, our approach can split query evaluation between user interaction and rendering, achieving much better scalability for interactive visualization than the previous state of the art. Furthermore, even when a multi-resolution strategy is used for visualization, queries are jointly evaluated at the finest data granularity, because our framework does not limit query accuracy to a fixed spatial subdivision.",10.1109/TVCG.2022.3209439,,TRUE,TRUE,TRUE,T,,F,C1,DROP-algorithm,0,,,,,0,0,0,0,0,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2022J055,Polyphony: an Interactive Transfer Learning Framework for Single-Cell Data Analysis,"Cheng, Furui and Keller, Mark S and Qu, Huamin and Gehlenborg, Nils and Wang, Qianwen",2022,2023,Data visualization;Annotations;Biology;Biological system modeling;Cells (biology);Statistics;Sociology;Interactive Machine Learning;Transfer Learning;Single-cell Data Analysis;Human-AI Interaction,"Reference-based cell-type annotation can significantly reduce time and effort in single-cell analysis by transferring labels from a previously-annotated dataset to a new dataset. However, label transfer by end-to-end computational methods is challenging due to the entanglement of technical (e.g., from different sequencing batches or techniques) and biological (e.g., from different cellular microenvironments) variations, only the first of which must be removed. To address this issue, we propose Polyphony, an interactive transfer learning (ITL) framework, to complement biologists' knowledge with advanced computational methods. Polyphony is motivated and guided by domain experts' needs for a controllable, interactive, and algorithm-assisted annotation process, identified through interviews with seven biologists. We introduce anchors, i.e., analogous cell populations across datasets, as a paradigm to explain the computational process and collect user feedback for model improvement. We further design a set of visualizations and interactions to empower users to add, delete, or modify anchors, resulting in refined cell type annotations. The effectiveness of this approach is demonstrated through quantitative experiments, two hypothetical use cases, and interviews with two biologists. The results show that our anchor-based ITL method takes advantage of both human and machine intelligence in annotating massive single-cell datasets.",10.1109/TVCG.2022.3209408,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2022J056,Evaluating the Use of Uncertainty Visualisations for Imputations of Data Missing At Random in Scatterplots,"Sarma, Abhraneel and Guo, Shunan and Hoffswell, Jane and Rossi, Ryan and Du, Fan and Koh, Eunyee and Kay, Matthew",2022,2023,Uncertainty;Data visualization;Task analysis;Bars;Market research;Visual analytics;Mobile ad hoc networks;Uncertainty visualisations;missing values;data imputation;multivariate data,"Most real-world datasets contain missing values yet most exploratory data analysis (EDA) systems only support visualising data points with complete cases. This omission may potentially lead the user to biased analyses and insights. Imputation techniques can help estimate the value of a missing data point, but introduces additional uncertainty. In this work, we investigate the effects of visualising imputed values in charts using different ways of representing data imputations and imputation uncertaintyâ€”no imputation, mean, 95% confidence intervals, probability density plots, gradient intervals, and hypothetical outcome plots. We focus on scatterplots, which is a commonly used chart type, and conduct a crowdsourced study with 202 participants. We measure users' bias and precision in performing two tasksâ€”estimating average and detecting trendâ€”and their self-reported confidence in performing these tasks. Our results suggest that, when estimating averages, uncertainty representations may reduce bias but at the cost of decreasing precision. When estimating trend, only hypothetical outcome plots may lead to a small probability of reducing bias while increasing precision. Participants in every uncertainty representation were less certain about their response when compared to the baseline. The findings point towards potential trade-offs in using uncertainty encodings for datasets with a large number of missing values. This paper and the associated analysis materials are available at: https://osf.io/q4y5r/",10.1109/TVCG.2022.3209348,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
534,191,2022J064,DashBot: Insight-Driven Dashboard Generation Based on Deep Reinforcement Learning,"Deng, Dazhen and Wu, Aoyu and Qu, Huamin and Wu, Yingcai",2022,2023,Data visualization;Visualization;Deep learning;Training;Neural networks;Encoding;Q-learning;Reinforcement Learning;Visualization Recommendation;Multiple-View Visualization,"Analytical dashboards are popular in business intelligence to facilitate insight discovery with multiple charts. However, creating an effective dashboard is highly demanding, which requires users to have adequate data analysis background and be familiar with professional tools, such as Power BI. To create a dashboard, users have to configure charts by selecting data columns and exploring different chart combinations to optimize the communication of insights, which is trial-and-error. Recent research has started to use deep learning methods for dashboard generation to lower the burden of visualization creation. However, such efforts are greatly hindered by the lack of large-scale and high-quality datasets of dashboards. In this work, we propose using deep reinforcement learning to generate analytical dashboards that can use well-established visualization knowledge and the estimation capacity of reinforcement learning. Specifically, we use visualization knowledge to construct a training environment and rewards for agents to explore and imitate human exploration behavior with a well-designed agent network. The usefulness of the deep reinforcement learning model is demonstrated through ablation studies and user studies. In conclusion, our work opens up new opportunities to develop effective ML-based visualization recommenders without beforehand training datasets.",10.1109/TVCG.2022.3209468,,TRUE,TRUE,TRUE,,T,F,C1,DROP,0,,,,1,1,1,1,1,0,0,0,0,1,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2022J062,Measuring Effects of Spatial Visualization and Domain on Visualization Task Performance: A Comparative Study,"Tandon, Sara and Abdul-Rahman, Alfie and Borgo, Rita",2022,2023,Data visualization;Visualization;Task analysis;Education;Psychology;Bars;Time factors;Human-subjects quantitative studies;visualization;perception;bar chart;discipline;domain-specific;education;empirical evaluation;spatial ability;cognitive abilities,"Understanding one's audience is foundational to creating high impact visualization designs. However, individual differences and cognitive abilities influence interactions with information visualization. Different user needs and abilities suggest that an individual's background could influence cognitive performance and interactions with visuals in a systematic way. This study builds on current research in domain-specific visualization and cognition to address if domain and spatial visualization ability combine to affect performance on information visualization tasks. We measure spatial visualization and visual task performance between those with tertiary education and professional profile in business, law & political science, and math & computer science. We conducted an online study with 90 participants using an established psychometric test to assess spatial visualization ability, and bar chart layouts rotated along Cartesian and polar coordinates to assess performance on spatially rotated data. Accuracy and response times varied with domain across chart types and task difficulty. We found that accuracy and time correlate with spatial visualization level, and education in math & computer science can indicate higher spatial visualization. Additionally, we found that motivational differences between domains could contribute to increased levels of accuracy. Our findings indicate discipline not only affects user needs and interactions with data visualization, but also cognitive traits. Our results can advance inclusive practices in visualization design and add to knowledge in domain-specific visual research that can empower designers across disciplines to create effective visualizations.",10.1109/TVCG.2022.3209491,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2022J064,,,,,,,,,,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
536,192,2022J065,RankAxis: Towards a Systematic Combination of Projection and Ranking in Multi-Attribute Data Exploration,"Liu, Qiangqiang and Ren, Yukun and Zhu, Zhihua and Li, Dai and Ma, Xiaojuan and Li, Quan",2022,2023,Semantics;Layout;Data visualization;Space exploration;Dimensionality reduction;Visual analytics;Task analysis;Ranking;projection;multi-attribute data exploration,"Projection and ranking are frequently used analysis techniques in multi-attribute data exploration. Both families of techniques help analysts with tasks such as identifying similarities between observations and determining ordered subgroups, and have shown good performances in multi-attribute data exploration. However, they often exhibit problems such as distorted projection layouts, obscure semantic interpretations, and non-intuitive effects produced by selecting a subset of (weighted) attributes. Moreover, few studies have attempted to combine projection and ranking into the same exploration space to complement each other's strengths and weaknesses. For this reason, we propose RankAxis, a visual analytics system that systematically combines projection and ranking to facilitate the mutual interpretation of these two techniques and jointly support multi-attribute data exploration. A real-world case study, expert feedback, and a user study demonstrate the efficacy of RankAxis.",10.1109/TVCG.2022.3209463,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,,,,1,1,1,1,1,1,1,1,0,0,0,2,23,2. domain user,18,,,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,1,0,0,0,0,4. After the deployment,0,,
,,2022J065,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,5,,,0,1,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,4. After the deployment,0,,
538,193,2022J066,PC-Expo: A Metrics-Based Interactive Axes Reordering Method for Parallel Coordinate Displays,"Tyagi, Anjul and Estro, Tyler and Kuenning, Geoff and Zadok, Erez and Mueller, Klaus",2022,2023,Data visualization;Measurement;Optimization;Task analysis;Real-time systems;Data analysis;Correlation;High dimensional data visualization;Parallel Coordinates Chart;Data Storytelling;Data Analysis,"Parallel coordinate plots (PCPs) have been widely used for high-dimensional (HD) data storytelling because they allow for presenting a large number of dimensions without distortions. The axes ordering in PCP presents a particular story from the data based on the user perception of PCP polylines. Existing works focus on directly optimizing for PCP axes ordering based on some common analysis tasks like clustering, neighborhood, and correlation. However, direct optimization for PCP axes based on these common properties is restrictive because it does not account for multiple properties occurring between the axes, and for local properties that occur in small regions in the data. Also, many of these techniques do not support the human-in-the-loop (HIL) paradigm, which is crucial (i) for explainability and (ii) in cases where no single reordering scheme fits the users' goals. To alleviate these problems, we present PC-Expo, a real-time visual analytics framework for all-in-one PCP line pattern detection and axes reordering. We studied the connection of line patterns in PCPs with different data analysis tasks and datasets. PC-Expo expands prior work on PCP axes reordering by developing real-time, local detection schemes for the 12 most common analysis tasks (properties). Users can choose the story they want to present with PCPs by optimizing directly over their choice of properties. These properties can be ranked, or combined using individual weights, creating a custom optimization scheme for axes reordering. Users can control the granularity at which they want to work with their detection scheme in the data, allowing exploration of local regions. PC-Expo also supports HIL axes reordering via local-property visualization, which shows the regions of granular activity for every axis pair. Local-property visualization is helpful for PCP axes reordering based on multiple properties, when no single reordering scheme fits the user goals. A comprehensive evaluation was done with real users and diverse datasets confirm the efficacy of PC-Expo in data storytelling with PCPs.",10.1109/TVCG.2022.3209392,,TRUE,TRUE,TRUE,T,,F,C1,KEEP,1,,,,1,0,1,1,1,1,1,1,0,0,0,3,15,1. domain expert,10,,,1,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1. Before the deployment (General),1,,
,,2022J066,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,5,2. domain user,5,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,1,0,0,0,0,4. After the deployment,0,,
539,194,2022J067,Incorporation of Human Knowledge into Data Embeddings to Improve Pattern Significance and Interpretability,"Li, Jie and Zhou, Chun-qi",2022,2023,Continents;Economic indicators;Data visualization;Knowledge engineering;Visual analytics;Mathematical models;Usability;Tabular Data;Multi-dimensional Exploration;Embedding Projection;Explicit Knowledge Generation;Visual Analytics,"Embedding is a common technique for analyzing multi-dimensional data. However, the embedding projection cannot always form significant and interpretable visual structures that foreshadow underlying data patterns. We propose an approach that incorporates human knowledge into data embeddings to improve pattern significance and interpretability. The core idea is (1) externalizing tacit human knowledge as explicit sample labels and (2) adding a classification loss in the embedding network to encode samples' classes. The approach pulls samples of the same class with similar data features closer in the projection, leading to more compact (significant) and class-consistent (interpretable) visual structures. We give an embedding network with a customized classification loss to implement the idea and integrate the network into a visualization system to form a workflow that supports flexible class creation and pattern exploration. Patterns found on open datasets in case studies, subjects' performance in a user study, and quantitative experiment results illustrate the general usability and effectiveness of the approach.",10.1109/TVCG.2022.3209382,,TRUE,TRUE,TRUE,,T,F,C1,DROP,0,,,,1,1,1,1,0,0,1,0,0,1,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2022J067,,,,,,,,,,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
540,195,2022J071,PromotionLens: Inspecting Promotion Strategies of Online E-commerce via Visual Analytics,"Zhang, Chenyang and Wang, Xiyuan and Zhao, Chuyi and Ren, Yijing and Zhang, Tianyu and Peng, Zhenhui and Fan, Xiaomeng and Ma, Xiaojuan and Li, Quan",2022,2023,Electronic commerce;Time series analysis;Predictive models;Data visualization;Analytical models;Visual analytics;Correlation;E-commerce;promotion strategy;time-series prediction;â€œwhat-ifâ€ analysis;visualization,"Promotions are commonly used by e-commerce merchants to boost sales. The efficacy of different promotion strategies can help sellers adapt their offering to customer demand in order to survive and thrive. Current approaches to designing promotion strategies are either based on econometrics, which may not scale to large amounts of sales data, or are spontaneous and provide little explanation of sales volume. Moreover, accurately measuring the effects of promotion designs and making bootstrappable adjustments accordingly remains a challenge due to the incompleteness and complexity of the information describing promotion strategies and their market environments. We present PromotionLens, a visual analytics system for exploring, comparing, and modeling the impact of various promotion strategies. Our approach combines representative multivariant time-series forecasting models and well-designed visualizations to demonstrate and explain the impact of sales and promotional factors, and to support â€œwhat-ifâ€ analysis of promotions. Two case studies, expert feedback, and a qualitative user study demonstrate the efficacy of PromotionLens.",10.1109/TVCG.2022.3209440,,TRUE,TRUE,TRUE,,T,F,C1,KEEP,1,12. Journalism and media,,e-commerce,0,1,1,1,1,1,1,1,0,0,0,3,17,1. domain expert,5,,,1,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,2. Before the deployment (Before or during design phase ONLY),0,,
,,2022J071,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,2. domain user,12,,,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,4. After the deployment,0,,
,,2022J071,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,5,,,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,0,0,1,0,0,0,0,0,4. After the deployment,0,,
541,196,2022J074,Visual Analysis and Detection of Contrails in Aircraft Engine Simulations,"Nipu, Nafiul and Floricel, Carla and Naghashzadeh, Negar and Paoli, Roberto and Marai, G. Elisabeta",2022,2023,Computational modeling;Atmospheric modeling;Data visualization;Data models;Visualization;Analytical models;Aircraft propulsion;Scalar Field Data;Physical & Environmental Sciences;Mathematics;Feature Detection;Tracking & Transformation,"Contrails are condensation trails generated from emitted particles by aircraft engines, which perturb Earth's radiation budget. Simulation modeling is used to interpret the formation and development of contrails. These simulations are computationally intensive and rely on high-performance computing solutions, and the contrail structures are not well defined. We propose a visual computing system to assist in defining contrails and their characteristics, as well as in the analysis of parameters for computer-generated aircraft engine simulations. The back-end of our system leverages a contrail-formation criterion and clustering methods to detect contrails' shape and evolution and identify similar simulation runs. The front-end system helps analyze contrails and their parameters across multiple simulation runs. The evaluation with domain experts shows this approach successfully aids in contrail data investigation.",10.1109/TVCG.2022.3209356,,TRUE,TRUE,TRUE,T,,F,C2,KEEP,1,8. Environmental sciences,,,0,1,1,1,1,1,1,1,0,0,0,2,2,1. domain expert,2,,,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,4. After the deployment,0,,
,,2022J075,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,4,,,0,1,0,0,0,1,0,0,0,0,0,0,0,1,1,0,0,1,0,0,1,0,0,0,0,0,4. After the deployment,0,,
544,197,2022J075,DPVisCreator: Incorporating Pattern Constraints to Privacy-preserving Visualizations via Differential Privacy,"Zhou, Jiehui and Wang, Xumeng and Wong, Jason K. and Wang, Huanliang and Wang, Zhongwei and Yang, Xiaoyu and Yan, Xiaoran and Feng, Haozhe and Qu, Huamin and Ying, Haochao and Chen, Wei",2022,2023,Data visualization;Privacy;Measurement;Visualization;Data models;Publishing;Syntactics;Privacy-preserving visualization;visual analytics;differential privacy;tabular data,"Data privacy is an essential issue in publishing data visualizations. However, it is challenging to represent multiple data patterns in privacy-preserving visualizations. The prior approaches target specific chart types or perform an anonymization model uniformly without considering the importance of data patterns in visualizations. In this paper, we propose a visual analytics approach that facilitates data custodians to generate multiple private charts while maintaining user-preferred patterns. To this end, we introduce pattern constraints to model users' preferences over data patterns in the dataset and incorporate them into the proposed Bayesian network-based Differential Privacy (DP) model PriVis. A prototype system, DPVisCreator, is developed to assist data custodians in implementing our approach. The effectiveness of our approach is demonstrated with quantitative evaluation of pattern utility under the different levels of privacy protection, case studies, and semi-structured expert interviews.",10.1109/TVCG.2022.3209391,,TRUE,TRUE,TRUE,T,T,F,C2,KEEP,1,,,data privacy-preserving,1,1,1,1,1,1,1,1,0,0,0,1,4,5. no participant,0,,,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,4. After the deployment,0,,
545,198,2022J077,ConceptExplainer: Interactive Explanation for Deep Neural Networks from a Concept Perspective,"Huang, Jinbin and Mishra, Aditi and Kwon, Bum Chul and Bryan, Chris",2022,2023,Behavioral sciences;Deep learning;Analytical models;Visual analytics;Navigation;Computational modeling;Task analysis;Explainable AI;Concept Activation Vectors;Interactive Visual Analytics,"Traditional deep learning interpretability methods which are suitable for model users cannot explain network behaviors at the global level and are inflexible at providing fine-grained explanations. As a solution, concept-based explanations are gaining attention due to their human intuitiveness and their flexibility to describe both global and local model behaviors. Concepts are groups of similarly meaningful pixels that express a notion, embedded within the network's latent space and have commonly been hand-generated, but have recently been discovered by automated approaches. Unfortunately, the magnitude and diversity of discovered concepts makes it difficult to navigate and make sense of the concept space. Visual analytics can serve a valuable role in bridging these gaps by enabling structured navigation and exploration of the concept space to provide concept-based insights of model behavior to users. To this end, we design, develop, and validate ConceptExplainer, a visual analytics system that enables people to interactively probe and explore the concept space to explain model behavior at the instance/class/global level. The system was developed via iterative prototyping to address a number of design challenges that model users face in interpreting the behavior of deep learning models. Via a rigorous user study, we validate how ConceptExplainer supports these challenges. Likewise, we conduct a series of usage scenarios to demonstrate how the system supports the interactive analysis of model behavior across a variety of tasks and explanation granularities, such as identifying concepts that are important to classification, identifying bias in training data, and understanding how concepts can be shared across diverse and seemingly dissimilar classes.",10.1109/TVCG.2022.3209384,,TRUE,TRUE,TRUE,,T,F,C2,KEEP,1,1. AI (Machine Learning/Deep Learning/Data Mining),,xai,0,1,1,1,1,0,1,1,1,0,0,1,10,2. domain user,10,,,0,1,0,0,0,1,0,0,0,0,0,0,0,1,0,1,1,1,1,1,0,0,0,0,0,0,4. After the deployment,0,,
548,199,2022J078,SliceTeller: A Data Slice-Driven Approach for Machine Learning Model Validation,"Zhang, Xiaoyu and Ono, Jorge Piazentin and Song, Huan and Gou, Liang and Ma, Kwan-Liu and Ren, Liu",2022,2023,Data models;Analytical models;Computational modeling;Training;Optimization;Adaptation models;Predictive models;Model Validation;Data Slicing;Data Validation;Model Evaluation;Data-Centric AI;Human-in-the-loop,"Real-world machine learning applications need to be thoroughly evaluated to meet critical product requirements for model release, to ensure fairness for different groups or individuals, and to achieve a consistent performance in various scenarios. For example, in autonomous driving, an object classification model should achieve high detection rates under different conditions of weather, distance, etc. Similarly, in the financial setting, credit-scoring models must not discriminate against minority groups. These conditions or groups are called as â€œData Slicesâ€. In product MLOps cycles, product developers must identify such critical data slices and adapt models to mitigate data slice problems. Discovering where models fail, understanding why they fail, and mitigating these problems, are therefore essential tasks in the MLOps life-cycle. In this paper, we present SliceTeller, a novel tool that allows users to debug, compare and improve machine learning models driven by critical data slices. SliceTeller automatically discovers problematic slices in the data, helps the user understand why models fail. More importantly, we present an efficient algorithm, SliceBoosting, to estimate trade-offs when prioritizing the optimization over certain slices. Furthermore, our system empowers model developers to compare and analyze different model versions during model iterations, allowing them to choose the model version best suitable for their applications. We evaluate our system with three use cases, including two real-world use cases of product development, to demonstrate the power of SliceTeller in the debugging and improvement of product-quality ML models.",10.1109/TVCG.2022.3209465,,TRUE,TRUE,TRUE,T,T,F,C2,KEEP,1,1. AI (Machine Learning/Deep Learning/Data Mining),,data-centric ai,0,1,1,1,1,1,1,1,1,0,0,1,3,1. domain expert,3,,,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,1,1,0,0,0,0,0,4. After the deployment,0,,
554,200,2022J081,MosaicSets: Embedding Set Systems into Grid Graphs,"Rottmann, Peter and Wallinger, Markus and Bonerath, Annika and Gedicke, Sven and NÃ¶llenburg, Martin and Haunert, Jan-Henrik",2022,2023,Data visualization;Visualization;Collaboration;Physiology;Economics;Crops;Bioinformatics;Set Visualization;Euler Diagram;Integer Linear Programming;Hypergraph,"Visualizing sets of elements and their relations is an important research area in information visualization. In this paper, we present MosaicSets: a novel approach to create Euler-like diagrams from non-spatial set systems such that each element occupies one cell of a regular hexagonal or square grid. The main challenge is to find an assignment of the elements to the grid cells such that each set constitutes a contiguous region. As use case, we consider the research groups of a university faculty as elements, and the departments and joint research projects as sets. We aim at finding a suitable mapping between the research groups and the grid cells such that the department structure forms a base map layout. Our objectives are to optimize both the compactness of the entirety of all cells and of each set by itself. We show that computing the mapping is NP-hard. However, using integer linear programming we can solve real-world instances optimally within a few seconds. Moreover, we propose a relaxation of the contiguity requirement to visualize otherwise non-embeddable set systems. We present and discuss different rendering styles for the set overlays. Based on a case study with real-world data, our evaluation comprises quantitative measures as well as expert interviews.",10.1109/TVCG.2022.3209485,,TRUE,TRUE,TRUE,T,T,F,C2,DROP,0,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2022J085,Sporthesia: Augmenting Sports Videos Using Natural Language,"Chen, Zhutian and Yang, Qisen and Xie, Xiao and Beyer, Johanna and Xia, Haijun and Wu, Yingcai and Pfister, Hanspeter",2022,2023,Videos;Sports;Data visualization;Visualization;Task analysis;Natural language processing;Electronic mail;Augmented Sports Videos;Language-driven Authoring Tool;Video-based Visualization;Sports Visualization,"Augmented sports videos, which combine visualizations and video effects to present data in actual scenes, can communicate insights engagingly and thus have been increasingly popular for sports enthusiasts around the world. Yet, creating augmented sports videos remains a challenging task, requiring considerable time and video editing skills. On the other hand, sports insights are often communicated using natural language, such as in commentaries, oral presentations, and articles, but usually lack visual cues. Thus, this work aims to facilitate the creation of augmented sports videos by enabling analysts to directly create visualizations embedded in videos using insights expressed in natural language. To achieve this goal, we propose a three-step approach â€“ 1) detecting visualizable entities in the text, 2) mapping these entities into visualizations, and 3) scheduling these visualizations to play with the video â€“ and analyzed 155 sports video clips and the accompanying commentaries for accomplishing these steps. Informed by our analysis, we have designed and implemented Sporthesia, a proof-of-concept system that takes racket-based sports videos and textual commentaries as the input and outputs augmented videos. We demonstrate Sporthesia's applicability in two exemplar scenarios, i.e., authoring augmented sports videos using text and augmenting historical sports videos based on auditory comments. A technical evaluation shows that Sporthesia achieves high accuracy (F1-score of 0.9) in detecting visualizable entities in the text. An expert evaluation with eight sports analysts suggests high utility, effectiveness, and satisfaction with our language-driven authoring method and provides insights for future improvement and opportunities.",10.1109/TVCG.2022.3209497,,TRUE,TRUE,TRUE,T,T,F,C2,KEEP,1,17. Sports and entertainment,,,0,1,1,1,1,0,1,1,0,0,0,2,8,1. domain expert,8,,,0,1,0,0,0,1,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,0,0,0,0,0,4. After the deployment,0,,
,,2022J085,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,5. no participant,0,,,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,4. After the deployment,0,,
555,201,2022J086,OBTracker: Visual Analytics of Off-ball Movements in Basketball,"Wu, Yihong and Deng, Dazhen and Xie, Xiao and He, Moqi and Xu, Jie and Zhang, Hongzeng and Zhang, Hui and Wu, Yingcai",2022,2023,Sports;Games;Tracking;Visual analytics;Interviews;Data visualization;Data models;Sports visualization;basketball tracking data;off-ball movement analysis,"In a basketball play, players who are not in possession of the ball (i.e., off-ball players) can still effectively contribute to the team's offense, such as making a sudden move to create scoring opportunities. Analyzing the movements of off-ball players can thus facilitate the development of effective strategies for coaches. However, common basketball statistics (e.g., points and assists) primarily focus on what happens around the ball and are mostly result-oriented, making it challenging to objectively assess and fully understand the contributions of off-ball movements. To address these challenges, we collaborate closely with domain experts and summarize the multi-level requirements for off-ball movement analysis in basketball. We first establish an assessment model to quantitatively evaluate the offensive contribution of an off-ball movement considering both the position of players and the team cooperation. Based on the model, we design and develop a visual analytics system called OBTracker to support the multifaceted analysis of off-ball movements. OBTracker enables users to identify the frequency and effectiveness of off-ball movement patterns and learn the performance of different off-ball players. A tailored visualization based on the Voronoi diagram is proposed to help users interpret the contribution of off-ball movements from a temporal perspective. We conduct two case studies based on the tracking data from NBA games and demonstrate the effectiveness and usability of OBTracker through expert feedback.",10.1109/TVCG.2022.3209373,,TRUE,TRUE,TRUE,T,T,F,C2,KEEP,1,17. Sports and entertainment,,,0,1,1,0,1,1,1,1,0,0,0,2,4,1. domain expert,4,,,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,2. Before the deployment (Before or during design phase ONLY),0,,
,,2022J086,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,4,,,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,0,1,1,0,0,0,0,0,4. After the deployment,0,,
558,202,2022J087,RASIPAM: Interactive Pattern Mining of Multivariate Event Sequences in Racket Sports,"Wu, Jiang and Liu, Dongyu and Guo, Ziyang and Wu, Yingcai",2022,2023,Sports;Data mining;Visual analytics;Games;Data visualization;Task analysis;Systems architecture;Sports Analytics;Multivariate Event Sequence;Interactive Pattern Mining;Comparative Visual Design,"Experts in racket sports like tennis and badminton use tactical analysis to gain insight into competitors' playing styles. Many data-driven methods apply pattern mining to racket sports data â€” which is often recorded as multivariate event sequences â€” to uncover sports tactics. However, tactics obtained in this way are often inconsistent with those deduced by experts through their domain knowledge, which can be confusing to those experts. This work introduces RASIPAM, a RAcket-Sports Interactive PAttern Mining system, which allows experts to incorporate their knowledge into data mining algorithms to discover meaningful tactics interactively. RASIPAM consists of a constraint-based pattern mining algorithm that responds to the analysis demands of experts: Experts provide suggestions for finding tactics in intuitive written language, and these suggestions are translated into constraints to run the algorithm. RASIPAM further introduces a tailored visual interface that allows experts to compare the new tactics with the original ones and decide whether to apply a given adjustment. This interactive workflow iteratively progresses until experts are satisfied with all tactics. We conduct a quantitative experiment to show that our algorithm supports real-time interaction. Two case studies in tennis and in badminton respectively, each involving two domain experts, are conducted to show the effectiveness and usefulness of the system.",10.1109/TVCG.2022.3209452,,TRUE,TRUE,TRUE,,T,F,C2,KEEP,1,17. Sports and entertainment,,,0,1,1,0,1,1,1,1,0,1,0,3,5,1. domain expert,5,,,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,2. Before the deployment (Before or during design phase ONLY),1,,
,,2022J087,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,4,,,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,4. After the deployment,0,,
565,203,2022J087,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,4,,,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,4. After the deployment,0,,
566,204,2022J089,The Quest for : Embedded Visualization for Augmenting Basketball Game Viewing Experiences,"Lin, Tica and Chen, Zhutian and Yang, Yalong and Chiappalupi, Daniele and Beyer, Johanna and Pfister, Hanspeter",2022,2023,Data visualization;Games;Sports;Fans;Videos;Data analysis;Visual analytics;Sports Analytics;Embedded Visualization;Data Visualization,"Sports game data is becoming increasingly complex, often consisting of multivariate data such as player performance stats, historical team records, and athletes' positional tracking information. While numerous visual analytics systems have been developed for sports analysts to derive insights, few tools target fans to improve their understanding and engagement of sports data during live games. By presenting extra data in the actual game views, embedded visualization has the potential to enhance fans' game-viewing experience. However, little is known about how to design such kinds of visualizations embedded into live games. In this work, we present a user-centered design study of developing interactive embedded visualizations for basketball fans to improve their live game-watching experiences. We first conducted a formative study to characterize basketball fans' in-game analysis behaviors and tasks. Based on our findings, we propose a design framework to inform the design of embedded visualizations based on specific data-seeking contexts. Following the design framework, we present five novel embedded visualization designs targeting five representative contexts identified by the fans, including shooting, offense, defense, player evaluation, and team comparison. We then developed Omnioculars, an interactive basketball game-viewing prototype that features the proposed embedded visualizations for fans' in-game data analysis. We evaluated Omnioculars in a simulated basketball game with basketball fans. The study results suggest that our design supports personalized in-game data analysis and enhances game understanding and engagement.",10.1109/TVCG.2022.3209353,,TRUE,TRUE,TRUE,T,,T,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2022J090,Breaking the Fourth Wall of Data Stories through Interaction,"Shi, Yang and Gao, Tian and Jiao, Xiaohan and Cao, Nan",2022,2023,Data visualization;Interviews;Visualization;Task analysis;Navigation;Taxonomy;TV;Interaction;data-driven storytelling;narrative devices,"Interaction is increasingly integrating into data stories to support data exploration and explanation. Interaction can also be combined with the narrative device, breaking the fourth wall (BTFW), to build a deeper connection between readers and data stories. BTFW interaction directly addresses readers by requiring their input. Such user input is then integrated into the narrative or visuals of data stories to encourage readers to inspect the stories more closely. In this work, we explore the design patterns of BTFW interaction commonly used in data stories. Six design patterns were identified through the analysis of 58 high-quality data stories collected from a range of online sources. Specifically, the data stories were categorized using a coding framework, including the input of BTFW interaction provided by readers and the output of BTFW interaction generated by data stories to respond to the input. To explore the benefits as well as concerns of using BTFW interaction, we conducted a three-session user study including the reading, interview, and recall sessions. The results of our user study suggested that BTFW interaction has a positive impact on self-story connection, user engagement, and information recall. We also discussed design implications to address the possible negative effects on the interactivity-comprehensibility balance, information privacy, and the learning curve of interaction brought by BTFW interaction.",10.1109/TVCG.2022.3209409,,TRUE,TRUE,TRUE,,T,F,C2,DROP,0,,,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2022J091,Erato: Cooperative Data Story Editing via Fact Interpolation,"Sun, Mengdi and Cai, Ligan and Cui, Weiwei and Wu, Yanqiu and Shi, Yang and Cao, Nan",2022,2023,Data visualization;Interpolation;Visualization;Man-machine systems;Authoring systems;Data mining;Task analysis;Interpolation;visual storytelling;human-machine cooperation,"As an effective form of narrative visualization, visual data stories are widely used in data-driven storytelling to communicate complex insights and support data understanding. Although important, they are difficult to create, as a variety of interdisciplinary skills, such as data analysis and design, are required. In this work, we introduce Erato, a human-machine cooperative data story editing system, which allows users to generate insightful and fluent data stories together with the computer. Specifically, Erato only requires a number of keyframes provided by the user to briefly describe the topic and structure of a data story. Meanwhile, our system leverages a novel interpolation algorithm to help users insert intermediate frames between the keyframes to smooth the transition. We evaluated the effectiveness and usefulness of the Erato system via a series of evaluations including a Turing test, a controlled user study, a performance validation, and interviews with three expert users. The evaluation results showed that the proposed interpolation technique was able to generate coherent story content and help users create data stories more efficiently.",10.1109/TVCG.2022.3209428,,TRUE,TRUE,TRUE,T,T,F,C2,KEEP,1,,,,1,1,1,1,1,1,0,1,0,0,0,3,158,2. domain user,125,,,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,2. Before the deployment (Before or during design phase ONLY),0,,
,,2022J091,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,2. domain user,30,,,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,4. After the deployment,0,,
567,205,2022J091,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,3,,,0,1,0,0,0,1,0,0,0,0,0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,0,4. After the deployment,0,,
,,2022J098,The State of the Art in BGP Visualization Tools: A Mapping of Visualization Techniques to Cyberattack Types,"Raynor, Justin and Crnovrsanin, Tarik and Di Bartolomeo, Sara and South, Laura and Saffo, David and Dunne, Cody",2022,2023,Visualization;Security;Routing;Systematics;Task analysis;Anomaly detection;Focusing;Visualization;Security;Routing;Systematics;Task analysis;Anomaly detection;Focusing,"Internet routing is largely dependent on Border Gateway Protocol (BGP). However, BGP does not have any inherent authentication or integrity mechanisms that help make it secure. Effective security is challenging or infeasible to implement due to high costs, policy employment in these distributed systems, and unique routing behavior. Visualization tools provide an attractive alternative in lieu of traditional security approaches. Several BGP security visualization tools have been developed as a stop-gap in the face of ever-present BGP attacks. Even though the target users, tasks, and domain remain largely consistent across such tools, many diverse visualization designs have been proposed. The purpose of this study is to provide an initial formalization of methods and visualization techniques for BGP cybersecurity analysis. Using PRISMA guidelines, we provide a systematic review and survey of 29 BGP visualization tools with their tasks, implementation techniques, and attacks and anomalies that they were intended for. We focused on BGP visualization tools as the main inclusion criteria to best capture the visualization techniques used in this domain while excluding solely algorithmic solutions and other detection tools that do not involve user interaction or interpretation. We take the unique approach of connecting (1) the actual BGP attacks and anomalies used to validate existing tools with (2) the techniques employed to detect them. In this way, we contribute an analysis of which techniques can be used for each attack type. Furthermore, we can see the evolution of visualization solutions in this domain as new attack types are discovered. This systematic review provides the groundwork for future designers and researchers building visualization tools for providing BGP cybersecurity, including an understanding of the state-of-the-art in this space and an analysis of what techniques are appropriate for each attack type. Our novel security visualization survey methodologyâ€”connecting visualization techniques with appropriate attack typesâ€”may also assist future researchers conducting systematic reviews of security visualizations. All supplemental materials are available at https://osf.io/tupz6/.",10.1109/TVCG.2022.3209412,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2022J099,RISeer: Inspecting the Status and Dynamics of Regional Industrial Structure via Visual Analytics,"Chen, Longfei and Ouyang, Yang and Zhang, Haipeng and Hong, Suting and Li, Quan",2022,2023,Data visualization;Economics;Industries;Biological system modeling;Business;Time series analysis;Forecasting;Spatiotemporal dynamics;multivariate time series;regional industrial structure;visualization,"Restructuring the regional industrial structure (RIS) has the potential to halt economic recession and achieve revitalization. Understanding the current status and dynamics of RIS will greatly assist in studying and evaluating the current industrial structure. Previous studies have focused on qualitative and quantitative research to rationalize RIS from a macroscopic perspective. Although recent studies have traced information at the industrial enterprise level to complement existing research from a micro perspective, the ambiguity of the underlying variables contributing to the industrial sector and its composition, the dynamic nature, and the large number of multivariant features of RIS records have obscured a deep and fine-grained understanding of RIS. To this end, we propose an interactive visualization system, RISeer, which is based on interpretable machine learning models and enhanced visualizations designed to identify the evolutionary patterns of the RIS and facilitate inter-regional inspection and comparison. Two case studies confirm the effectiveness of our approach, and feedback from experts indicates that RISeer helps them to gain a fine-grained understanding of the dynamics and evolution of the RIS.",10.1109/TVCG.2022.3209351,,TRUE,TRUE,TRUE,,T,F,C2,KEEP,1,9. Geosciences and geospatial data,,regional industrial structure,0,1,1,0,1,1,1,1,0,1,0,2,4,1. domain expert,4,,,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2. Before the deployment (Before or during design phase ONLY),0,,
,,2022J099,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,2,,,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,4. After the deployment,0,,
571,207,2022J101,ECoalVis: Visual Analysis of Control Strategies in Coal-fired Power Plants,"Liu, Shuhan and Weng, Di and Tian, Yuan and Deng, Zikun and Xu, Haoran and Zhu, Xiangyu and Yin, Honglei and Zhan, Xianyuan and Wu, Yingcai",2022,2023,Power generation;Sensors;Visual analytics;Time series analysis;Data visualization;Industries;Sensor systems;Power plant visual analytics;energy data visualization;spatiotemporal visualization;smart factory,"Improving the efficiency of coal-fired power plants has numerous benefits. The control strategy is one of the major factors affecting such efficiency. However, due to the complex and dynamic environment inside the power plants, it is hard to extract and evaluate control strategies and their cascading impact across massive sensors. Existing manual and data-driven approaches cannot well support the analysis of control strategies because these approaches are time-consuming and do not scale with the complexity of the power plant systems. Three challenges were identified: a) interactive extraction of control strategies from large-scale dynamic sensor data, b) intuitive visual representation of cascading impact among the sensors in a complex power plant system, and c) time-lag-aware analysis of the impact of control strategies on electricity generation efficiency. By collaborating with energy domain experts, we addressed these challenges with ECoalVis, a novel interactive system for experts to visually analyze the control strategies of coal-fired power plants extracted from historical sensor data. The effectiveness of the proposed system is evaluated with two usage scenarios on a real-world historical dataset and received positive feedback from experts.",10.1109/TVCG.2022.3209430,,TRUE,TRUE,TRUE,T,T,F,C2,KEEP,1,6. Energy and sustainability,,,0,1,1,1,1,1,1,1,0,0,0,1,4,1. domain expert,4,,,0,1,0,0,0,1,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,4. After the deployment,0,,
573,208,2022J102,A Visual Analytics System for Improving Attention-based Traffic Forecasting Models,"Jin, Seungmin and Lee, Hyunwook and Park, Cheonbok and Chu, Hyeshin and Tae, Yunwon and Choo, Jaegul and Ko, Sungahn",2022,2023,Predictive models;Analytical models;Roads;Task analysis;Computational modeling;Visual analytics;Deep learning;Traffic Visualization;Deep Learning;Attention Model;Speed Prediction;Explainable Artificial Intelligence,"With deep learning (DL) outperforming conventional methods for different tasks, much effort has been devoted to utilizing DL in various domains. Researchers and developers in the traffic domain have also designed and improved DL models for forecasting tasks such as estimation of traffic speed and time of arrival. However, there exist many challenges in analyzing DL models due to the black-box property of DL models and complexity of traffic data (i.e., spatio-temporal dependencies). Collaborating with domain experts, we design a visual analytics system, AttnAnalyzer, that enables users to explore how DL models make predictions by allowing effective spatio-temporal dependency analysis. The system incorporates dynamic time warping (DTW) and Granger causality tests for computational spatio-temporal dependency analysis while providing map, table, line chart, and pixel views to assist user to perform dependency and model behavior analysis. For the evaluation, we present three case studies showing how AttnAnalyzer can effectively explore model behaviors and improve model performance in two different road networks. We also provide domain expert feedback.",10.1109/TVCG.2022.3209462,,TRUE,TRUE,TRUE,T,T,F,C2,KEEP,1,18. Transportation and mobility,1. AI (Machine Learning/Deep Learning/Data Mining),xai,0,1,1,0,1,1,1,1,1,0,0,1,2,1. domain expert,2,,,0,1,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,1,0,1,1,0,0,0,0,0,3. Before the deployment (During the development and refinement phrase ONLY),0,,
574,209,2022J104,Lotse: A Practical Framework for Guidance in Visual Analytics,"Sperrle, Fabian and Ceneda, Davide and El-Assady, Mennatallah",2022,2023,Analytical models;Codes;Visual analytics;Collaboration;Libraries;Man-machine systems;Guidance Theory;Guidance Implementation,"Co-adaptive guidance aims to enable efficient human-machine collaboration in visual analytics, as proposed by multiple theoretical frameworks. This paper bridges the gap between such conceptual frameworks and practical implementation by introducing an accessible model of guidance and an accompanying guidance library, mapping theory into practice. We contribute a model of system-provided guidance based on design templates and derived strategies. We instantiate the model in a library called Lotse that allows specifying guidance strategies in definition files and generates running code from them. Lotse is the first guidance library using such an approach. It supports the creation of reusable guidance strategies to retrofit existing applications with guidance and fosters the creation of general guidance strategy patterns. We demonstrate its effectiveness through first-use case studies with VA researchers of varying guidance design expertise and find that they are able to effectively and quickly implement guidance with Lotse. Further, we analyze our framework's cognitive dimensions to evaluate its expressiveness and outline a summary of open research questions for aligning guidance practice with its intricate theory.",10.1109/TVCG.2022.3209393,,TRUE,TRUE,TRUE,T,T,F,C2,DROP,0,,,,,,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
575,210,2022J111,FlowNL: Asking the Flow Data in Natural Languages,"Huang, Jieying and Xi, Yang and Hu, Junnan and Tao, Jun",2022,2023,Natural languages;Data visualization;Semantics;Engines;Task analysis;Spirals;Visual analytics;Flow visualization;natural language interface;interactive exploration;declarative grammar,"Flow visualization is essentially a tool to answer domain experts' questions about flow fields using rendered images. Static flow visualization approaches require domain experts to raise their questions to visualization experts, who develop specific techniques to extract and visualize the flow structures of interest. Interactive visualization approaches allow domain experts to ask the system directly through the visual analytic interface, which provides flexibility to support various tasks. However, in practice, the visual analytic interface may require extra learning effort, which often discourages domain experts and limits its usage in real-world scenarios. In this paper, we propose FlowNL, a novel interactive system with a natural language interface. FlowNL allows users to manipulate the flow visualization system using plain English, which greatly reduces the learning effort. We develop a natural language parser to interpret user intention and translate textual input into a declarative language. We design the declarative language as an intermediate layer between the natural language and the programming language specifically for flow visualization. The declarative language provides selection and composition rules to derive relatively complicated flow structures from primitive objects that encode various kinds of information about scalar fields, flow patterns, regions of interest, connectivities, etc. We demonstrate the effectiveness of FlowNL using multiple usage scenarios and an empirical evaluation.",10.1109/TVCG.2022.3209453,,TRUE,TRUE,TRUE,T,T,F,C2,DROP,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2022J105,MEDLEY: Intent-based Recommendations to Support Dashboard Composition,"Pandey, Aditeya and Srinivasan, Arjun and Setlur, Vidya",2022,2023,Task analysis;Data visualization;Visualization;Recommender systems;Correlation;Medical services;Market research;Dashboards;intent;recommendations;direct manipulation;multi-view coordination,"Despite the ever-growing popularity of dashboards across a wide range of domains, their authoring still remains a tedious and complex process. Current tools offer considerable support for creating individual visualizations but provide limited support for discovering groups of visualizations that can be collectively useful for composing analytic dashboards. To address this problem, we present Medley, a mixed-initiative interface that assists in dashboard composition by recommending dashboard collections (i.e., a logically grouped set of views and filtering widgets) that map to specific analytical intents. Users can specify dashboard intents (namely, measure analysis, change analysis, category analysis, or distribution analysis) explicitly through an input panel in the interface or implicitly by selecting data attributes and views of interest. The system recommends collections based on these analytic intents, and views and widgets can be selected to compose a variety of dashboards. Medley also provides a lightweight direct manipulation interface to configure interactions between views in a dashboard. Based on a study with 13 participants performing both targeted and open-ended tasks, we discuss how Medley's recommendations guide dashboard composition and facilitate different user workflows. Observations from the study identify potential directions for future work, including combining manual view specification with dashboard recommendations and designing natural language interfaces for dashboard authoring.",10.1109/TVCG.2022.3209421,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2022J106,Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation with Large Language Models,"Strobelt, Hendrik and Webson, Albert and Sanh, Victor and Hoover, Benjamin and Beyer, Johanna and Pfister, Hanspeter and Rush, Alexander M.",2022,2023,Task analysis;Visualization;Analytical models;Training;Natural language processing;Transformers;Computational modeling;Natural language processing;language modeling;zero-shot models,"State-of-the-art neural language models can now be used to solve ad-hoc language tasks through zero-shot prompting without the need for supervised training. This approach has gained popularity in recent years, and researchers have demonstrated prompts that achieve strong accuracy on specific NLP tasks. However, finding a prompt for new tasks requires experimentation. Different prompt templates with different wording choices lead to significant accuracy differences. PromptIDE allows users to experiment with prompt variations, visualize prompt performance, and iteratively optimize prompts. We developed a workflow that allows users to first focus on model feedback using small data before moving on to a large data regime that allows empirical grounding of promising prompts using quantitative measures of the task. The tool then allows easy deployment of the newly created ad-hoc models. We demonstrate the utility of PromptIDE (demo: http://prompt.vizhub.ai) and our workflow using several real-world use cases.",10.1109/TVCG.2022.3209479,,TRUE,TRUE,FALSE,,,,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
576,211,2022J112,Comparison Conundrum and the Chamber of Visualizations: An Exploration of How Language Influences Visual Design,"Gaba, Aimen and Setlur, Vidya and Srinivasan, Arjun and Hoffswell, Jane and Xiong, Cindy",2022,2023,Data visualization;Visualization;Task analysis;Natural languages;Bars;Semantics;Computational linguistics;Comparative constructions;cardinality;explicit and implicit comparisons;natural language;intent;visual analysis,"The language for expressing comparisons is often complex and nuanced, making supporting natural language-based visual comparison a non-trivial task. To better understand how people reason about comparisons in natural language, we explore a design space of utterances for comparing data entities. We identified different parameters of comparison utterances that indicate what is being compared (i.e., data variables and attributes) as well as how these parameters are specified (i.e., explicitly or implicitly). We conducted a user study with sixteen data visualization experts and non-experts to investigate how they designed visualizations for comparisons in our design space. Based on the rich set of visualization techniques observed, we extracted key design features from the visualizations and synthesized them into a subset of sixteen representative visualization designs. We then conducted a follow-up study to validate user preferences for the sixteen representative visualizations corresponding to utterances in our design space. Findings from these studies suggest guidelines and future directions for designing natural language interfaces and recommendation tools to better support natural language comparisons in visual analytics.",10.1109/TVCG.2022.3209456,,TRUE,TRUE,TRUE,,T,F,C2,DROP,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
577,212,2022J113,Towards Natural Language-Based Visualization Authoring,"Wang, Yun and Hou, Zhitao and Shen, Leixian and Wu, Tongshuang and Wang, Jiaqi and Huang, He and Zhang, Haidong and Zhang, Dongmei",2022,2023,Data visualization;Natural languages;Authoring systems;Pipelines;Task analysis;Metadata;Visual analytics;Visualization authoring;Natural language interface;Natural language understanding,"A key challenge to visualization authoring is the process of getting familiar with the complex user interfaces of authoring tools. Natural Language Interface (NLI) presents promising benefits due to its learnability and usability. However, supporting NLIs for authoring tools requires expertise in natural language processing, while existing NLIs are mostly designed for visual analytic workflow. In this paper, we propose an authoring-oriented NLI pipeline by introducing a structured representation of users' visualization editing intents, called editing actions, based on a formative study and an extensive survey on visualization construction tools. The editing actions are executable, and thus decouple natural language interpretation and visualization applications as an intermediate layer. We implement a deep learning-based NL interpreter to translate NL utterances into editing actions. The interpreter is reusable and extensible across authoring tools. The authoring tools only need to map the editing actions into tool-specific operations. To illustrate the usages of the NL interpreter, we implement an Excel chart editor and a proof-of-concept authoring tool, VisTalk. We conduct a user study with VisTalk to understand the usage patterns of NL-based authoring systems. Finally, we discuss observations on how users author charts with natural language, as well as implications for future research.",10.1109/TVCG.2022.3209357,,TRUE,TRUE,TRUE,,T,F,C2,DROP,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2022J116,Development and Evaluation of Two Approaches of Visual Sensitivity Analysis to Support Epidemiological Modeling,"Rydow, Erik and Borgo, Rita and Fang, Hui and Torsney-Weir, Thomas and Swallow, Ben and Porphyre, Thibaud and Turkay, Cagatay and Chen, Min",2022,2023,Data visualization;Data models;Analytical models;Computational modeling;Uncertainty;Solid modeling;Numerical models;Sensitivity analysis;Ensemble visualization;COVID-19;Epidemiological Modeling;Epidemiology,"Computational modeling is a commonly used technology in many scientific disciplines and has played a noticeable role in combating the COVID-19 pandemic. Modeling scientists conduct sensitivity analysis frequently to observe and monitor the behavior of a model during its development and deployment. The traditional algorithmic ranking of sensitivity of different parameters usually does not provide modeling scientists with sufficient information to understand the interactions between different parameters and model outputs, while modeling scientists need to observe a large number of model runs in order to gain actionable information for parameter optimization. To address the above challenge, we developed and compared two visual analytics approaches, namely: algorithm-centric and visualization-assisted, and visualization-centric and algorithm-assisted. We evaluated the two approaches based on a structured analysis of different tasks in visual sensitivity analysis as well as the feedback of domain experts. While the work was carried out in the context of epidemiological modeling, the two approaches developed in this work are directly applicable to a variety of modeling processes featuring time series outputs, and can be extended to work with models with other types of outputs.",10.1109/TVCG.2022.3209464,,TRUE,TRUE,TRUE,T,,F,C2,KEEP,1,10. Healthcare and medical imaging,,Epidemiology,0,1,1,1,1,1,1,1,0,1,0,2,9,1. domain expert,9,,,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1. Before the deployment (General),1,,
,,2022J116,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,1. domain expert,9,,,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,0,1,1,0,0,1,0,0,0,0,0,4. After the deployment,0,,
578,213,2022J118,A Comparison of Spatiotemporal Visualizations for 3D Urban Analytics,"Mota, Roberta and Ferreira, Nivan and Silva, Julio Daniel and Horga, Marius and Lage, Marcos and Ceferino, Luis and Alim, Usman and Sharlin, Ehud and Miranda, Fabio",2022,2023,Data visualization;Three-dimensional displays;Urban areas;Spatiotemporal phenomena;Task analysis;Buildings;Spatial databases;Visualization;urban analytics;urban data;spatiotemporal data;empirical evaluation,"Recent technological innovations have led to an increase in the availability of 3D urban data, such as shadow, noise, solar potential, and earthquake simulations. These spatiotemporal datasets create opportunities for new visualizations to engage experts from different domains to study the dynamic behavior of urban spaces in this under explored dimension. However, designing 3D spatiotemporal urban visualizations is challenging, as it requires visual strategies to support analysis of time-varying data referent to the city geometry. Although different visual strategies have been used in 3D urban visual analytics, the question of how effective these visual designs are at supporting spatiotemporal analysis on building surfaces remains open. To investigate this, in this paper we first contribute a series of analytical tasks elicited after interviews with practitioners from three urban domains. We also contribute a quantitative user study comparing the effectiveness of four representative visual designs used to visualize 3D spatiotemporal urban data: spatial juxtaposition, temporal juxtaposition, linked view, and embedded view. Participants performed a series of tasks that required them to identify extreme values on building surfaces over time. Tasks varied in granularity for both space and time dimensions. Our results demonstrate that participants were more accurate using plot-based visualizations (linked view, embedded view) but faster using color-coded visualizations (spatial juxtaposition, temporal juxtaposition). Our results also show that, with increasing task complexity, plot-based visualizations perform better in preserving efficiency (time, accuracy) compared to color-coded visualizations. Based on our findings, we present a set of takeaways with design recommendations for 3D spatiotemporal urban visualizations for researchers and practitioners. Lastly, we report on a series of interviews with four practitioners, and their feedback and suggestions for further work on the visualizations to support 3D spatiotemporal urban data analysis.",10.1109/TVCG.2022.3209474,,TRUE,TRUE,TRUE,,T,F,C2,DROP,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
581,214,2022J117,Extending the Nested Model for User-Centric XAI: A Design Study on GNN-based Drug Repurposing,"Wang, Qianwen and Huang, Kexin and Chandak, Payal and Zitnik, Marinka and Gehlenborg, Nils",2022,2023,Artificial intelligence;Drugs;Visualization;Diseases;Guidelines;Data visualization;Task analysis;Visual Explanation;XAI;Graph Neural Network;Visualization Design Model;Drug Repurposing,"Whether AI explanations can help users achieve specific tasks efficiently (i.e., usable explanations) is significantly influenced by their visual presentation. While many techniques exist to generate explanations, it remains unclear how to select and visually present AI explanations based on the characteristics of domain users. This paper aims to understand this question through a multidisciplinary design study for a specific problem: explaining graph neural network (GNN) predictions to domain experts in drug repurposing, i.e., reuse of existing drugs for new diseases. Building on the nested design model of visualization, we incorporate XAI design considerations from a literature review and from our collaborators' feedback into the design process. Specifically, we discuss XAI-related design considerations for usable visual explanations at each design layer: target user, usage context, domain explanation, and XAI goal at the domain layer; format, granularity, and operation of explanations at the abstraction layer; encodings and interactions at the visualization layer; and XAI and rendering algorithm at the algorithm layer. We present how the extended nested model motivates and informs the design of DrugExplorer, an XAI tool for drug repurposing. Based on our domain characterization, DrugExplorer provides path-based explanations and presents them both as individual paths and meta-paths for two key XAI operations, why and what else. DrugExplorer offers a novel visualization design called MetaMatrix with a set of interactions to help domain users organize and compare explanation paths at different levels of granularity to generate domain-meaningful insights. We demonstrate the effectiveness of the selected visual presentation and DrugExplorer as a whole via a usage scenario, a user study, and expert interviews. From these evaluations, we derive insightful observations and reflections that can inform the design of XAI visualizations for other scientific applications.",10.1109/TVCG.2022.3209435,,TRUE,TRUE,TRUE,T,T,T,,,999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
585,215,2022J120,PSEUDo: Interactive Pattern Search in Multivariate Time Series with Locality-Sensitive Hashing and Relevance Feedback,"Yu, Yuncong and Kruyff, Dylan and Jiao, Jiao and Becker, Tim and Behrisch, Michael",2022,2023,Time series analysis;Hash functions;Data models;Electronic mail;Visualization;Task analysis;Compounds;time series;pattern search;locality-sensitive hashing;relevance feedback,"We present PSEUDo, a visual pattern retrieval tool for multivariate time series. It aims to overcome the uneconomic (re-)training problem accompanying deep learning-based methods. Very high-dimensional time series emerge on an unprecedented scale due to increasing sensor usage and data storage. Visual pattern search is one of the most frequent tasks on time series. Automatic pattern retrieval methods often suffer from inefficient training data, a lack of ground truth labels, and a discrepancy between the similarity perceived by the algorithm and required by the user or the task. Our proposal is based on the query-aware locality-sensitive hashing technique to create a representation of multivariate time series windows. It features sub-linear training and inference time with respect to data dimensions. This performance gain allows an instantaneous relevance-feedback-driven adaption to converge to users' similarity notion. We demonstrate PSEUDo's performance in terms of accuracy, speed, steerability, and usability through quantitative benchmarks with representative time series retrieval methods and a case study. We find that PSEUDo detects patterns in high-dimensional time series efficiently, improves the result with relevance feedback through feature selection, and allows an understandable as well as user-friendly retrieval process.",10.1109/TVCG.2022.3209431,,TRUE,TRUE,TRUE,,T,F,C2,KEEP,1,,,,1,1,1,1,1,1,1,1,1,0,0,2,1,1. domain expert,1,,,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,4. After the deployment,0,,
586,216,2022J120,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,5. no participant,0,,,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,4. After the deployment,0,,
